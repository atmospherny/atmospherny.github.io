<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>Atmospherny feed</title>
<style type="text/css">
@font-face {
    font-family: 'PT Serif';
    src: url(PT_Serif-Web-Regular.ttf);
    font-style: normal;
}

body {
	margin: 0;
}

#container {
	width: 100%;
	max-width: 860px;
	color: #333;
	margin: auto;
	background-color: #eee;
	border-style: solid;
	border-width: 2px;
	border-color: #009;
	padding: 1em;
}

button {
	width: 100%;
	margin: 0;
	background-color: #fff;
	border-style: dashed;
	border-color: #333;
	border-width: 1px;
	font-size: 48pt;
	padding: 0.5em;
	color: #222;
	font-family: Monospace;
	outline: none;
	-webkit-transition: background-color 2s;
	-moz-transition: background-color 2s;
	-o-transition: background-color 2s;
	transition: background-color 2s;
}

button:hover {
	background-color: #aaa;
	-webkit-transition: background-color 0.2s;
	-moz-transition: background-color 0.2s;
	-o-transition: background-color 0.2s;
	transition: background-color 0.2s;
}

table {
	width: 100%;
}

#current {
	font-size: 32px;
	font-family: 'PT Serif';
	padding: 0.3em;
}

#current * {
	font-size: 32px;	
}

summary {
	background-color: #ddd;
	border-style: dotted;
	border-width: 1px;
	padding: 0.3em;
	outline: none;
	cursor: pointer;
}

#progress {
	text-align: center;
}

#weekday {
	text-align: center;
}

a {
	color: #333;
}

a:visited {
	color: #888;
}

</style>

<script type="text/javascript">
var currentIndex = 0;
var myChoice = new Object();

var days = ['Sunday','Monday','Tuesday','Wednesday','Thursday','Friday','Saturday'];

function o(s) {
	return document.getElementById(s);
}

function next() {
	currentIndex++;
	if (currentIndex == o("titles").innerHTML.split("{{{{ARTICLE_PARSER}}}}").length) currentIndex=0;
	update();
	updateIndex();
}

function prev() {
	currentIndex--;
	if (currentIndex < 0) currentIndex = o("titles").innerHTML.split("{{{{ARTICLE_PARSER}}}}").length - 1;
	update();
	updateIndex();
}

function choose() {
	myChoice["a"+currentIndex] = "tr";
	update()
}

function clubs() {
	myChoice["a"+currentIndex] = "bl";
	update()
}

function spades() {
	myChoice["a"+currentIndex] = "br";
	update()	
}

function unchoose() {
	myChoice["a"+currentIndex] = "tl";
	update()
}

function ifchosen() {
	switch(myChoice["a"+currentIndex]) {
		case "tr":
			o("current-title").innerHTML = "&hearts; " + o("current-title").innerHTML
			break;
		case "br":
			o("current-title").innerHTML = "&spades; " + o("current-title").innerHTML
			break;
		case "bl":
			o("current-title").innerHTML = "&clubs; " + o("current-title").innerHTML
			break;
		default:
			o("current-title").innerHTML = "&diams; " + o("current-title").innerHTML		
	}
}

function update() {
	o("current-title").innerHTML = o("titles").innerHTML.split("{{{{ARTICLE_PARSER}}}}")[currentIndex];
	o("current-abstract").innerHTML = o("abstracts").innerHTML.split("{{{{ARTICLE_PARSER}}}}")[currentIndex] + "<br>" + "<a href='" + o("links").innerHTML.split("{{{{ARTICLE_PARSER}}}}")[currentIndex] + "' target='_blank'>download pdf</a>";
	ifchosen();
	updateStorage();
	o("progress").innerHTML = "#" + (currentIndex + 1);
}

function updateStorage() {
	localStorage["myChoice"] = JSON.stringify(myChoice)
}

function updateIndex() {
	localStorage["currentIndex"] = currentIndex;
}

function updateChoice() {
	try {
		myChoice = JSON.parse(localStorage["myChoice"]);
		currentIndex = parseInt(localStorage["currentIndex"]);
		if (typeof(currentIndex)!= "number") {
			localStorage["currentIndex"] = 0;
			currentIndex = 0;
		}
	} catch(e) {
		localStorage["currentIndex"] = 0;
		localStorage["myChoice"] = JSON.stringify("{}");
		currentIndex = 0;
		myChoice = {};
	} 
}

function listA() {
	buf = ""
	for(var i in myChoice) {
		if ((myChoice[i] == "tr") || (myChoice[i] == "bl")) buf += "#" + (parseInt(i.split("a")[1]) + 1) + " "
	}
	window.prompt("Share your choice:", buf);
}

function listB() {
	buf = ""
	for(var i in myChoice) {
		if ((myChoice[i] == "tr") || (myChoice[i] == "br")) buf += "#" + (parseInt(i.split("a")[1]) + 1) + " "
	}
	window.prompt("Share your choice:", buf);
}

function setWeekday() {
	var d = new Date();
	var n = d.getUTCHours();
	if (o("weekday").innerHTML != days[now.getDay()]) {
		if((days[now.getDay()] != "Saturday") && (days[now.getDay()] != "Sunday")) {
			if(n>3) {
				localStorage["myChoice"] = JSON.stringify({});
				localStorage["currentIndex"] = 0;
			}
		}
	}
}

</script>
</head>
<body onload="updateChoice();update()">

<div id="container">
<div id="current">

<div id="weekday">Monday</div>
<div id="progress"></div>

<p id="current-title">

</p>

<details>
<summary>abstract & pdf</summary>
<p id="current-abstract">

</p>
</details>

</div>
<table>
<tr>
<td><button onclick="prev()">
<
</button></td><td><button onclick="next()">
>
</button></td>
</tr>
<tr>
<td><button onclick="unchoose()">
&diams;
</button></td><td><button onclick="choose()">
&hearts;
</button></td>
</tr>
<tr>
<td><button onclick="clubs()">
&clubs;
</button></td><td><button onclick="spades()">
&spades;
</button></td>
</tr>

<tr><td><button onclick="listA()">{&clubs;,&hearts;}</button></td><td><button onclick="listB()">{&spades;,&hearts;}</button></td></tr>

</table>

</div>

<div id="viewer">

</div>

<div style="visibility:hidden; display: none;" id="titles">Thermal Dark Matter From A Highly Decoupled Sector.{{{{ARTICLE_PARSER}}}}Black hole formation in a contracting universe.{{{{ARTICLE_PARSER}}}}Staying away from the bar: the local dynamical signature of slow and fast bars in the Milky Way.{{{{ARTICLE_PARSER}}}}Imaging protoplanets: observing transition disks with non-redundant masking.{{{{ARTICLE_PARSER}}}}On the Formation of Molecular Clumps in QSO Outflows.{{{{ARTICLE_PARSER}}}}Mass and eccentricity constraints on the planetary debris orbiting the white dwarf WD 1145+017.{{{{ARTICLE_PARSER}}}}Modelling Mechanical Heating in Star-Forming Galaxies: CO and 13CO Line Ratios as Sensitive Probes.{{{{ARTICLE_PARSER}}}}Constraining cloud parameters using high density gas tracers in galaxies.{{{{ARTICLE_PARSER}}}}Evidence from SOFIA Imaging of Polycyclic Aromatic Hydrocarbon Formation along a Recent Outflow in NGC 7027.{{{{ARTICLE_PARSER}}}}Non-Detection of HC$_{11}$N toward TMC-1: Constraining the Chemistry of Large Carbon-Chain Molecules.{{{{ARTICLE_PARSER}}}}Tracing Primordial Black Holes in Nonsingular Bouncing Cosmology.{{{{ARTICLE_PARSER}}}}MagAO Imaging of Long-period Objects (MILO). II. A Puzzling White Dwarf around the Sun-like Star HD 11112.{{{{ARTICLE_PARSER}}}}Eclipsing Binary Stars as Benchmarks for Trigonometric Parallaxes in the Gaia Era.{{{{ARTICLE_PARSER}}}}The Role of Angular Momentum Transport in Establishing the Accretion Rate--Protostellar Mass Correlation.{{{{ARTICLE_PARSER}}}}On gravitational waves from classical three body problem.{{{{ARTICLE_PARSER}}}}[Fe II] jets from intermediate-mass protostars in Carina.{{{{ARTICLE_PARSER}}}}The evolution of the Milky Way: New insights from open clusters.{{{{ARTICLE_PARSER}}}}Multifractal Solar EUV Intensity Fluctuations and their Implications for Coronal Heating Models.{{{{ARTICLE_PARSER}}}}Orbital classification in an N-body bar.{{{{ARTICLE_PARSER}}}}The SAMI Galaxy Survey: Spatially resolving the environmental quenching of star formation in GAMA galaxies.{{{{ARTICLE_PARSER}}}}Peculiar Transverse Velocities of Galaxies from Quasar Microlensing. Tentative Estimate of the Peculiar Velocity Dispersion at $z\sim 0.5$.{{{{ARTICLE_PARSER}}}}Quasi-periodic pulsations in solar and stellar flares: an overview of recent results.{{{{ARTICLE_PARSER}}}}The effect of magnetic field on mean flow generation by rotating two-dimensional convection.{{{{ARTICLE_PARSER}}}}Modeling of deep gaps created by giant planets in protoplanetary discs.{{{{ARTICLE_PARSER}}}}A brief history of the solar diameter measurements: a critical quality assessment of the existing data.{{{{ARTICLE_PARSER}}}}Investigating Energetic X-Shaped Flares on the Outskirts of A Solar Active Region.{{{{ARTICLE_PARSER}}}}Influence of departures from LTE on calcium, titanium, and iron abundance determinations in cool giants of different metallicities.{{{{ARTICLE_PARSER}}}}Apsidal motion in the massive binary HD152218.{{{{ARTICLE_PARSER}}}}Degeneracy breakdown as a source of supernovae Ia.{{{{ARTICLE_PARSER}}}}Uninterrupted optical light curves of main-belt asteroids from the K2 Mission.{{{{ARTICLE_PARSER}}}}The heart of the swarm: K2 photometry and rotational characteristics of 56 Jovian Trojan asteroids.{{{{ARTICLE_PARSER}}}}HAT-P-65b and HAT-P-66b: Two Transiting Inflated Hot Jupiters and Observational Evidence for the Re-Inflation of Close-In Giant Planets.{{{{ARTICLE_PARSER}}}}Heat transport in Rayleigh-Benard convection and angular momentum transport in Taylor-Couette flow: a comparative study.{{{{ARTICLE_PARSER}}}}Probing pre-inflationary anisotropy with directional variations in the gravitational wave background.{{{{ARTICLE_PARSER}}}}High proper motion objects towards the inner Milky Way: characterisation of newly identified nearby stars from the VISTA Variables in the Via Lactea Survey.{{{{ARTICLE_PARSER}}}}Mass extinctions and supernova explosions.{{{{ARTICLE_PARSER}}}}The GALAH Survey: Observational Overview and Gaia DR1 companion.{{{{ARTICLE_PARSER}}}}Earliest stages of the non-equilibrium in axially symmetric, self-gravitating, dissipative fluids.{{{{ARTICLE_PARSER}}}}Spectral energy distribution simulations of a possible ring structure around the young, red brown dwarf G196-3B.{{{{ARTICLE_PARSER}}}}Asteroseismology of hybrid $\delta$ Scuti--$\gamma$ Doradus pulsating stars.{{{{ARTICLE_PARSER}}}}Latest Results from VERITAS: Gamma 2016.{{{{ARTICLE_PARSER}}}}The connection between supernova remnants and the Galactic magnetic field: An analysis of quasi-parallel and quasi-perpendicular cosmic ray acceleration for the axisymmetric sample.{{{{ARTICLE_PARSER}}}}The Gaussian streaming model and Lagrangian effective field theory.{{{{ARTICLE_PARSER}}}}Quantum Loops in Non-Local Gravity.{{{{ARTICLE_PARSER}}}}Rapid modelling of the redshift-space power spectrum multipoles for a masked density field.{{{{ARTICLE_PARSER}}}}On improving analytical models of cosmic reionization for matching numerical simulation.{{{{ARTICLE_PARSER}}}}On Past Singularities in $k=0$ FLRW Cosmologies.{{{{ARTICLE_PARSER}}}}Theoretical Physics Implications of the Binary Black-Hole Mergers GW150914 and GW151226.{{{{ARTICLE_PARSER}}}}On the 4D generalized Proca action for an Abelian vector field.{{{{ARTICLE_PARSER}}}}Constraining the production of cosmic rays by pulsars.{{{{ARTICLE_PARSER}}}}Is there evidence for anomalous dipole anisotropy in the large-scale structure?.{{{{ARTICLE_PARSER}}}}Approximate Bayesian Computation in Large Scale Structure: constraining the galaxy-halo connection.{{{{ARTICLE_PARSER}}}}Carbon-oxygen-neon mass nuclei in superstrong magnetic fields.{{{{ARTICLE_PARSER}}}}Resistive Tearing Instability in Electron-MHD: Application to Neutron Star Crusts.{{{{ARTICLE_PARSER}}}}LBCS: the LOFAR Long-Baseline Calibrator Survey.{{{{ARTICLE_PARSER}}}}Speckle lifetime in XAO coronagraphic images: temporal evolution of SPHERE coronagraphic images.{{{{ARTICLE_PARSER}}}}Superluminous supernova 2015bn in the nebular phase: evidence for the engine-powered explosion of a stripped massive star.{{{{ARTICLE_PARSER}}}}Ejector and propeller spin-down: How might a superluminous supernova millisecond magnetar become the 6.67 hr pulsar in RCW103.{{{{ARTICLE_PARSER}}}}Observational Evidence of Dynamic Star Formation Rate in Milky Way Giant Molecular Clouds.{{{{ARTICLE_PARSER}}}}Optimal fitting of gaussian-apodized or under-resolved emission lines in Fourier Transform spectra providing new insights on the velocity structure of NGC 6720.{{{{ARTICLE_PARSER}}}}An equation of state for purely kinetic k-essence inspired by cosmic topological defects.{{{{ARTICLE_PARSER}}}}Evolution of Protoplanetary Discs with Magnetically Driven Disc Winds.{{{{ARTICLE_PARSER}}}}Gravitational smoothing of kinks on cosmic string loops.{{{{ARTICLE_PARSER}}}}Study of Parametric Instability of gravitational wave detectors using silicon test masses.{{{{ARTICLE_PARSER}}}}Behaviour of elements from lithium to europium in stars with and without planets.{{{{ARTICLE_PARSER}}}}The Making of FR Is I. Numerical Hydrodynamic 3D Simulations of Low Power Jets.{{{{ARTICLE_PARSER}}}}The nearby interstellar medium towards alpha Leo -- UV observations and modeling of a warm cloud within hot gas.{{{{ARTICLE_PARSER}}}}Cosmic Acceleration From Matter-Curvature Coupling.{{{{ARTICLE_PARSER}}}}Dark Matter From f(R,T) Gravity.{{{{ARTICLE_PARSER}}}}Cosmological Constant Implementing Mach Principle in General Relativity.{{{{ARTICLE_PARSER}}}}Natural constraints on the gluon-quark vertex.{{{{ARTICLE_PARSER}}}}Magnetic catalysis of a finite size pion condensate.{{{{ARTICLE_PARSER}}}}Monte Carlo Particle Lists: MCPL.{{{{ARTICLE_PARSER}}}}Do nuclear collisions create a locally equilibrated quark-gluon plasma?.{{{{ARTICLE_PARSER}}}}Measurements of open heavy-flavour production with ALICE at the LHC.{{{{ARTICLE_PARSER}}}}Measurement of long-range angular correlations and azimuthal anisotropies in high-multiplicity $p$$+$Au collisions at $\sqrt{s_{_{NN}}}=200$ GeV.{{{{ARTICLE_PARSER}}}}Beam energy dependence of Hanbury-Brown-Twiss radii from a blast-wave model.{{{{ARTICLE_PARSER}}}}Strangeness in nuclear physics.{{{{ARTICLE_PARSER}}}}Natural constraints on the gluon-quark vertex.{{{{ARTICLE_PARSER}}}}Baryons and Chiral Symmetry.{{{{ARTICLE_PARSER}}}}The thermalization of soft modes in non-expanding isotropic quark gluon plasmas.{{{{ARTICLE_PARSER}}}}Collectivity and electromagnetic radiation in small systems.{{{{ARTICLE_PARSER}}}}Magnetic catalysis of a finite size pion condensate.{{{{ARTICLE_PARSER}}}}Testing of coalescence mechanism in high energy heavy ion collisions using two-particle correlations with identified particle trigger.{{{{ARTICLE_PARSER}}}}Investigating the correlations of flow harmonics in 2.76A TeV Pb--Pb collisions.{{{{ARTICLE_PARSER}}}}Brueckner-Hartree-Fock and its renormalized calculations for finite nuclei.{{{{ARTICLE_PARSER}}}}Hyperon star in a modified quark meson coupling model.{{{{ARTICLE_PARSER}}}}Isomerism in the \"south-east\" of $^{132}$Sn and a predicted neutron-decaying isomer in $^{129}$Pd.{{{{ARTICLE_PARSER}}}}$K^{*}$ vector meson resonances dynamics in heavy-ion collisions.{{{{ARTICLE_PARSER}}}}Complex Geometry of Nuclei and Atoms.{{{{ARTICLE_PARSER}}}}Do nuclear collisions create a locally equilibrated quark-gluon plasma?.{{{{ARTICLE_PARSER}}}}Beam energy dependence of Hanbury-Brown-Twiss radii from a blast-wave model.{{{{ARTICLE_PARSER}}}}Strangeness in nuclear physics.{{{{ARTICLE_PARSER}}}}Carbon-oxygen-neon mass nuclei in superstrong magnetic fields.{{{{ARTICLE_PARSER}}}}Thermal chiral vortical and magnetic waves: new excitation modes in chiral fluids.{{{{ARTICLE_PARSER}}}}Heavy-Meson Decay Constants: QCD Sum-Rule Glance at Isospin Breaking.{{{{ARTICLE_PARSER}}}}Advances in solving the two-fermion homogeneous Bethe-Salpeter equation in Minkowski space.{{{{ARTICLE_PARSER}}}}Fermionic topological quantum states as tensor networks.{{{{ARTICLE_PARSER}}}}Lectures on the Strominger system.{{{{ARTICLE_PARSER}}}}The weak coupling limit for the random Schr\\"odinger equation: The average wave function.{{{{ARTICLE_PARSER}}}}Chaoticons described by nonlocal nonlinear Schrodinger equation.{{{{ARTICLE_PARSER}}}}A Time scales Noether's theorem.{{{{ARTICLE_PARSER}}}}An analogue of the Coleman-Mandula theorem for quantum field theory in curved spacetimes.{{{{ARTICLE_PARSER}}}}Enumerating meandric systems with large number of components.{{{{ARTICLE_PARSER}}}}Multiscale spacetimes from first principles.{{{{ARTICLE_PARSER}}}}Pfaffian Correlation Functions of Planar Dimer Covers.{{{{ARTICLE_PARSER}}}}Informing the structure of complex Hadamard matrix spaces using a flow.{{{{ARTICLE_PARSER}}}}Eigenvalue inequalities for the Laplacian with mixed boundary conditions.{{{{ARTICLE_PARSER}}}}Trimodal steady water waves.{{{{ARTICLE_PARSER}}}}A dimension-breaking phenomenon for water waves with weak surface tension.{{{{ARTICLE_PARSER}}}}Emergent Spacetime and Cosmic Inflation I.{{{{ARTICLE_PARSER}}}}Periodic solitons for the elliptic-elliptic focussing Davey-Stewartson equations.{{{{ARTICLE_PARSER}}}}On Past Singularities in $k=0$ FLRW Cosmologies.{{{{ARTICLE_PARSER}}}}Four-dimensional unsubtraction from the loop-tree duality.{{{{ARTICLE_PARSER}}}}Construction of Energy Consistent Shallow Water Equations.{{{{ARTICLE_PARSER}}}}The Fermionic Signature Operator and Quantum States in Rindler Space-Time.{{{{ARTICLE_PARSER}}}}Decoupling of the re-parametrization degree of freedom and a generalized probability in quantum cosmology.{{{{ARTICLE_PARSER}}}}On Factorization of Generalized Macdonald Polynomials.{{{{ARTICLE_PARSER}}}}The full Ward-Takahashi Identity for colored tensor models.{{{{ARTICLE_PARSER}}}}Fermionic topological quantum states as tensor networks.{{{{ARTICLE_PARSER}}}}How many bits specify a quantum state?.{{{{ARTICLE_PARSER}}}}Measuring Multi-Configurational Character by Orbital Entanglement.{{{{ARTICLE_PARSER}}}}Experimental asymmetric Plug-and-Play Measurement-device-independent quantum key distribution.{{{{ARTICLE_PARSER}}}}Experimental Demonstration of Passive-Decoy-State Quantum-Key-Distribution with Two Independent Lasers.{{{{ARTICLE_PARSER}}}}The extended Bloch Representation of Entanglement and Measurement in Quantum Mechanics.{{{{ARTICLE_PARSER}}}}Mutually unbiased maximally entangled bases in $\mathbb{C}^d\otimes\mathbb{C}^d$.{{{{ARTICLE_PARSER}}}}Characterization of optical quantum circuits using resonant phase shifts.{{{{ARTICLE_PARSER}}}}A 5.4 Gbps real time quantum random number generator with compact implementation.{{{{ARTICLE_PARSER}}}}A nonorthogonal state-interaction approach for matrix product state wave functions.{{{{ARTICLE_PARSER}}}}Energy localization and ground-state cooling of mechanical resonator from room temperature in optomechanics using a gain cavity.{{{{ARTICLE_PARSER}}}}Single atom edge-like states via quantum interference.{{{{ARTICLE_PARSER}}}}Energy-Efficient Quantum Computing.{{{{ARTICLE_PARSER}}}}Topological spin models in Rydberg lattices.{{{{ARTICLE_PARSER}}}}Time-bin Entanglement from Quantum Dots.{{{{ARTICLE_PARSER}}}}Quantum phases and entanglement properties of an extended Dicke model.{{{{ARTICLE_PARSER}}}}Enhanced Thermal Object Imaging by Photon Addition or Subtraction.{{{{ARTICLE_PARSER}}}}Staking out the physical sectors of Hilbert spaces.{{{{ARTICLE_PARSER}}}}Security against jamming and noise exclusion in imaging.{{{{ARTICLE_PARSER}}}}Coherent destruction of tunneling in graphene irradiated by elliptically polarized lasers.{{{{ARTICLE_PARSER}}}}Critical behavior of dissipative two-dimensional spin lattices.{{{{ARTICLE_PARSER}}}}Logarithmic Black Hole Entropy Corrections and Holographic R\'enyi Entropy.{{{{ARTICLE_PARSER}}}}Efficient deterministic giant photon phase shift from a single charged quantum dot.{{{{ARTICLE_PARSER}}}}Collective excitations using a room-temperature gas of 3-level atoms in a cavity.{{{{ARTICLE_PARSER}}}}Quantum phase gate Based on Electromagnetically Induced Transparency in Optical Cavities.{{{{ARTICLE_PARSER}}}}Hydrogen atom wave function and eigen energy in the Rindler space.{{{{ARTICLE_PARSER}}}}Fermionic Matrix Product Operators and Topological Phases of Matter.{{{{ARTICLE_PARSER}}}}Strong parameter renormalization from optimum lattice model orbitals.{{{{ARTICLE_PARSER}}}}Orthogonality Catastrophes in Quantum Electrodynamics.{{{{ARTICLE_PARSER}}}}Dirac open quantum system dynamics: formulations and simulations.{{{{ARTICLE_PARSER}}}}Negative Refraction Induced by M\\"obius Topology.{{{{ARTICLE_PARSER}}}}Quantum-proof multi-source randomness extractors in the Markov model.{{{{ARTICLE_PARSER}}}}Exact algebraic separability criterion for two-qubit systems.{{{{ARTICLE_PARSER}}}}Exponential Communication Complexity Advantage from Quantum Superposition of the Direction of Communication.{{{{ARTICLE_PARSER}}}}Quantum state-independent contextuality requires 13 rays.{{{{ARTICLE_PARSER}}}}Quantum Hysteresis in Coupled Light-Matter Systems.{{{{ARTICLE_PARSER}}}}The Effects of the modified scalar product on the properties of the one-dimensional harmonic oscillator with energy-dependent potential.{{{{ARTICLE_PARSER}}}}Quantum walk on a cylinder.{{{{ARTICLE_PARSER}}}}Exact propagation of open quantum systems in a system-reservoir context.{{{{ARTICLE_PARSER}}}}Quantum Soliton Evaporation.{{{{ARTICLE_PARSER}}}}NbN superconducting nanowire single photon detector with efficiency over 90% at 1550 nm wavelength operational at compact cryocooler temperature.{{{{ARTICLE_PARSER}}}}Nodal Variational Principle for Excited States.{{{{ARTICLE_PARSER}}}}Controllable optical response by modifying the gain and loss of a mechanical resonator and cavity mode in an optomechanical system.{{{{ARTICLE_PARSER}}}}Complexity Classes and Completeness in Algebraic Geometry.{{{{ARTICLE_PARSER}}}}Bottom-up Instance Segmentation using Deep Higher-Order CRFs.{{{{ARTICLE_PARSER}}}}Towards Better Response Times and Higher-Quality Queries in Interactive Knowledge Base Debugging.{{{{ARTICLE_PARSER}}}}Multiple predator based capture process on complex networks.{{{{ARTICLE_PARSER}}}}A Stackelberg Game for Incentive Proactive Caching Mechanisms in Wireless Networks.{{{{ARTICLE_PARSER}}}}Disintermediation of Inter-Blockchain Transactions.{{{{ARTICLE_PARSER}}}}Cutting down energy usage in wireless sensor networks using Duty Cycle technique and multi-hop routing.{{{{ARTICLE_PARSER}}}}On Sequential Elimination Algorithms for Best-Arm Identification in Multi-Armed Bandits.{{{{ARTICLE_PARSER}}}}Generating Videos with Scene Dynamics.{{{{ARTICLE_PARSER}}}}Why is Differential Evolution Better than Grid Search for Tuning Defect Predictors?.{{{{ARTICLE_PARSER}}}}Soap-bubble Optimization of Gaits.{{{{ARTICLE_PARSER}}}}Memory Remains: Understanding Collective Memory in the Digital Age.{{{{ARTICLE_PARSER}}}}Identifying Community Structures in Dynamic Networks.{{{{ARTICLE_PARSER}}}}Distributed Processing of Biosignal-Database for Emotion Recognition with Mahout.{{{{ARTICLE_PARSER}}}}Robust Structure from Motion in the Presence of Outliers and Missing Data.{{{{ARTICLE_PARSER}}}}O(f) Bi-Approximation for Capacitated Covering with Hard Capacities.{{{{ARTICLE_PARSER}}}}Some Advances in Role Discovery in Graphs.{{{{ARTICLE_PARSER}}}}Decentralized Observability with Limited Communication between Sensors.{{{{ARTICLE_PARSER}}}}Convex Independence in Permutation Graphs.{{{{ARTICLE_PARSER}}}}RACE: A Rate Adaptive Channel Estimation Approach for Millimeter Wave MIMO Systems.{{{{ARTICLE_PARSER}}}}Efficient Byzantine Sequential Change Detection.{{{{ARTICLE_PARSER}}}}Machine Learning with Guarantees using Descriptive Complexity and SMT Solvers.{{{{ARTICLE_PARSER}}}}SIGDROP: Signature-based ROP Detection using Hardware Performance Counters.{{{{ARTICLE_PARSER}}}}Optimal Speed Scaling with a Solar Cell.{{{{ARTICLE_PARSER}}}}Correlation between social proximity and mobility similarity.{{{{ARTICLE_PARSER}}}}Measuring Player's Behaviour Change over Time in Public Goods Game.{{{{ARTICLE_PARSER}}}}Identifying Topology of Power Distribution Networks Based on Smart Meter Data.{{{{ARTICLE_PARSER}}}}Increasing Wireless Sensor Networks Lifetime with New Method.{{{{ARTICLE_PARSER}}}}Extraction of Layout Entities and Sub-layout Query-based Retrieval of Document Images.{{{{ARTICLE_PARSER}}}}Self-Stabilizing Mobile Byzantine-Tolerant Regular Register with bounded timestamp.{{{{ARTICLE_PARSER}}}}Automatic Selection of Stochastic Watershed Hierarchies.{{{{ARTICLE_PARSER}}}}Sum Coloring : New upper bounds for the chromatic strength.{{{{ARTICLE_PARSER}}}}Detecting Singleton Review Spammers Using Semantic Similarity.{{{{ARTICLE_PARSER}}}}Predicting the future relevance of research institutions - The winning solution of the KDD Cup 2016.{{{{ARTICLE_PARSER}}}}An Interactive Segmentation Tool for Quantifying Fat in Lumbar Muscles using Axial Lumbar-Spine MRI.{{{{ARTICLE_PARSER}}}}A Hierarchical Model of Reviews for Aspect-based Sentiment Analysis.{{{{ARTICLE_PARSER}}}}INSIGHT-1 at SemEval-2016 Task 4: Convolutional Neural Networks for Sentiment Classification and Quantification.{{{{ARTICLE_PARSER}}}}NSIGHT-1 at SemEval-2016 Task 5: Deep Learning for Multilingual Aspect-based Sentiment Analysis.{{{{ARTICLE_PARSER}}}}No Free Charge Theorem: a Covert Channel via USB Charging Cable on Mobile Devices.{{{{ARTICLE_PARSER}}}}Typing weak MSOL properties.{{{{ARTICLE_PARSER}}}}DELTA: Data Extraction and Logging Tool for Android.{{{{ARTICLE_PARSER}}}}Image and Video Mining through Online Learning.{{{{ARTICLE_PARSER}}}}An empirical study on the effects of different types of noise in image classification tasks.{{{{ARTICLE_PARSER}}}}ADMM for Distributed Dynamic Beamforming.{{{{ARTICLE_PARSER}}}}Arachneum: Blockchain meets Distributed Web.{{{{ARTICLE_PARSER}}}}Online Charging Scheduling Algorithms of Electric Vehicles in Smart Grid: An Overview.{{{{ARTICLE_PARSER}}}}Pareto Optimal Allocation under Uncertain Preferences.{{{{ARTICLE_PARSER}}}}Automated detection of smuggled high-risk security threats using Deep Learning.{{{{ARTICLE_PARSER}}}}Harassment detection: a benchmark on the #HackHarassment dataset.{{{{ARTICLE_PARSER}}}}By-passing the Kohn-Sham equations with machine learning.{{{{ARTICLE_PARSER}}}}Track Facial Points in Unconstrained Videos.{{{{ARTICLE_PARSER}}}}Nanosurveyor: a framework for real-time data processing.{{{{ARTICLE_PARSER}}}}Joint Optimization of Energy Efficiency and Data Compression in TDMA-Based Medium Access Control for the IoT - Extended Version.{{{{ARTICLE_PARSER}}}}Where is the Goldmine? Finding Promising Business Locations through Facebook Data Analytics.{{{{ARTICLE_PARSER}}}}Undersampled Phase Retrieval via Majorization-Minimization.{{{{ARTICLE_PARSER}}}}Distributed Online Optimization in Dynamic Environments Using Mirror Descent.{{{{ARTICLE_PARSER}}}}Dialogue manager domain adaptation using Gaussian process reinforcement learning.{{{{ARTICLE_PARSER}}}}Elementary recursive quantifier elimination based on Thom encoding and sign determination.{{{{ARTICLE_PARSER}}}}On SZK and PP.{{{{ARTICLE_PARSER}}}}A Linear-Time Variational Integrator for Multibody Systems.{{{{ARTICLE_PARSER}}}}Rapid Mixing of Geodesic Walks on Manifolds with Positive Curvature.{{{{ARTICLE_PARSER}}}}Robust Spectral Detection of Global Structures in the Data by Learning a Regularization.{{{{ARTICLE_PARSER}}}}Semi-Supervised Classification with Graph Convolutional Networks.{{{{ARTICLE_PARSER}}}}Entropy of the Sum of Two Independent, Non-Identically-Distributed Exponential Random Variables.{{{{ARTICLE_PARSER}}}}A Bitcoin system with no mining and no history transactions: Build a compact Bitcoin system.{{{{ARTICLE_PARSER}}}}The length of a minimal synchronizing word and the \v{C}erny conjecture.{{{{ARTICLE_PARSER}}}}Unperturbed Schelling segregation in two or three dimensions.{{{{ARTICLE_PARSER}}}}On k-Submodular Relaxation.{{{{ARTICLE_PARSER}}}}Dynamic Relative Compression, Dynamic Partial Sums, and Substring Concatenation.{{{{ARTICLE_PARSER}}}}Novel Multidimensional Models of Opinion Dynamics in Social Networks.{{{{ARTICLE_PARSER}}}}High-Dimensional Continuous Control Using Generalized Advantage Estimation.{{{{ARTICLE_PARSER}}}}Mutual Information Bounds via Adjacency Events.{{{{ARTICLE_PARSER}}}}Quantum-proof multi-source randomness extractors in the Markov model.{{{{ARTICLE_PARSER}}}}Closing the Gap Between Short and Long XORs for Model Counting.{{{{ARTICLE_PARSER}}}}A Mathematical Formalization of Hierarchical Temporal Memory's Spatial Pooler.{{{{ARTICLE_PARSER}}}}Equivalence of additive-combinatorial linear inequalities for Shannon entropy and differential entropy.{{{{ARTICLE_PARSER}}}}Performance of 1-D and 2-D Lattice Boltzmann (LB) in Solution of the Shock Tube Problem.{{{{ARTICLE_PARSER}}}}Numerical Solution of Cylindrically Converging Shock Waves.{{{{ARTICLE_PARSER}}}}How Deep Neural Networks Can Improve Emotion Recognition on Video Data.{{{{ARTICLE_PARSER}}}}Non-additive Security Game.{{{{ARTICLE_PARSER}}}}Summaries for Context-Free Games.{{{{ARTICLE_PARSER}}}}Max-Information, Differential Privacy, and Post-Selection Hypothesis Testing.{{{{ARTICLE_PARSER}}}}Learning Covariant Feature Detectors.{{{{ARTICLE_PARSER}}}}Adaptive ADMM with Spectral Penalty Parameter Selection.{{{{ARTICLE_PARSER}}}}Intention from Motion.{{{{ARTICLE_PARSER}}}}Beyond Counting: New Perspectives on the Active IPv4 Address Space.{{{{ARTICLE_PARSER}}}}Supervised Syntax-based Alignment between English Sentences and Abstract Meaning Representation Graphs.{{{{ARTICLE_PARSER}}}}A Proof Strategy Language and Proof Script Generation for Isabelle.{{{{ARTICLE_PARSER}}}}DDoS Attacks with Randomized Traffic Innovation: Botnet Identification Challenges and Strategies.{{{{ARTICLE_PARSER}}}}Detection of concealed cars in complex cargo X-ray imagery using Deep Learning.{{{{ARTICLE_PARSER}}}}Detailed Garment Recovery from a Single-View Image.{{{{ARTICLE_PARSER}}}}Polynomial Kernels and Wideness Properties of Nowhere Dense Graph Classes.{{{{ARTICLE_PARSER}}}}A Non-convex One-Pass Framework for Generalized Factorization Machines and Rank-One Matrix Sensing.{{{{ARTICLE_PARSER}}}}Segmenting a Surface Mesh into Pants Using Morse Theory.{{{{ARTICLE_PARSER}}}}Tracking Completion.{{{{ARTICLE_PARSER}}}}Real-Time Visual Tracking: Promoting the Robustness of Correlation Filter Learning.{{{{ARTICLE_PARSER}}}}Computing NodeTrix Representations of Clustered Graphs.{{{{ARTICLE_PARSER}}}}Towards Transparent AI Systems: Interpreting Visual Question Answering Models.{{{{ARTICLE_PARSER}}}}Verifier Theory and Unverifiability.{{{{ARTICLE_PARSER}}}}Linear Game Theory : Reduction of complexity by decomposing large games into partial games.{{{{ARTICLE_PARSER}}}}On AWGN Channels and Gaussian MACs with Variable-Length Feedback.{{{{ARTICLE_PARSER}}}}Multivariate Dependence Beyond Shannon Information.{{{{ARTICLE_PARSER}}}}Reconstructing Articulated Rigged Models from RGB-D Videos.{{{{ARTICLE_PARSER}}}}Distributed Compressive Sensing: Performance Analysis with Diverse Signal Ensembles.{{{{ARTICLE_PARSER}}}}Component-Based Distributed Framework for Coherent and Real-Time Video Dehazing.{{{{ARTICLE_PARSER}}}}Ask the GRU: Multi-Task Learning for Deep Text Recommendations.{{{{ARTICLE_PARSER}}}}DoF Analysis in a Two-Layered Heterogeneous Wireless Interference Network.{{{{ARTICLE_PARSER}}}}Ashwin: Plug-and-Play System for Machine-Human Image Annotation.{{{{ARTICLE_PARSER}}}}Learning Lexical Entries for Robotic Commands using Crowdsourcing.{{{{ARTICLE_PARSER}}}}Distributed sampled-data control of nonholonomic multi-robot systems with proximity networks.{{{{ARTICLE_PARSER}}}}</div>
<div style="visibility:hidden; display: none;" id="abstracts"><p>It has recently been shown that if the dark matter is in thermal equilibrium
with a sector that is highly decoupled from the Standard Model, it can
freeze-out with an acceptable relic abundance, even if the dark matter is as
heavy as ~1-100 PeV. In such scenarios, both the dark and visible sectors are
populated after inflation, but with independent temperatures. The lightest
particle in the dark sector will be generically long-lived, and can come to
dominate the energy density of the universe. Upon decaying, these particles can
significantly reheat the visible sector, diluting the abundance of dark matter
and thus allowing for dark matter particles that are much heavier than
conventional WIMPs. In this paper, we present a systematic and pedagogical
treatment of the cosmological history in this class of models, emphasizing the
simplest scenarios in which a dark matter candidate annihilates into hidden
sector particles which then decay into visible matter through the vector,
Higgs, or lepton portals. In each case, we find ample parameter space in which
very heavy dark matter particles can provide an acceptable thermal relic
abundance. We also discuss possible extensions of models featuring these
dynamics.
</p>
{{{{ARTICLE_PARSER}}}}<p>We study the evolution of cosmological perturbations in a contracting
universe. We aim to determine under which conditions density perturbations grow
to form large inhomogeneities and collapse into black holes. Our method
consists in solving the cosmological perturbation equations in complete
generality for a hydrodynamical fluid. We then describe the evolution of the
fluctuations over the different length scales of interest and as a function of
the equation of state for the fluid, and we explore two different types of
initial conditions: quantum vacuum and thermal fluctuations. We also derive a
general requirement for black hole collapse on sub-Hubble scales, and we use
the Press-Schechter formalism to describe the black hole formation probability.
For a fluid with a small sound speed (e.g., dust), we find that both quantum
and thermal initial fluctuations grow in a contracting universe, and the
largest inhomogeneities that first collapse into black holes are of Hubble size
and the collapse occurs well before reaching the Planck scale. For a
radiation-dominated fluid, we find that no black hole can form before reaching
the Planck scale. In the context of matter bounce cosmology, it thus appears
that only models in which a radiation-dominated era begins early in the
cosmological evolution are robust against the formation of black holes. Yet,
the formation of black holes might be an interesting feature for other models.
We comment on a number of possible alternative early universe scenarios that
could take advantage of this feature.
</p>
{{{{ARTICLE_PARSER}}}}<p>Both the three-dimensional density of red clump giants and the gas kinematics
in the inner Galaxy indicate that the pattern speed of the Galactic bar could
be much lower than previously estimated. Here, we show that such slow bar
models are unable to reproduce the bimodality observed in local stellar
velocity space. We do so by computing the response of stars in the Solar
neighbourhood to the gravitational potential of slow and fast bars, in terms of
their perturbed distribution function in action-angle space up to second order,
as well as by identifying resonantly trapped orbits. We also check that the
bimodality is unlikely to be produced through perturbations from spiral arms,
and conclude that, contrary to gas kinematics, local stellar kinematics still
favour a fast bar in the Milky Way, with a pattern speed of the order of almost
twice (and no less than 1.8 times) the circular frequency at the Sun's
position. This leaves open the question of the nature of the secondary long bar
in the Milky Way.
</p>
{{{{ARTICLE_PARSER}}}}<p>Transition disks, protoplanetary disks with inner clearings, are promising
objects in which to directly image forming planets. The high contrast imaging
technique of non-redundant masking is well posed to detect planetary mass
companions at several to tens of AU in nearby transition disks. We present
non-redundant masking observations of the T Cha and LkCa 15 transition disks,
both of which host posited sub-stellar mass companions. However, due to a loss
of information intrinsic to the technique, observations of extended sources
(e.g. scattered light from disks) can be misinterpreted as moving companions.
We discuss tests to distinguish between these two scenarios, with applications
to the T Cha and LkCa 15 observations. We argue that a static,
forward-scattering disk can explain the T Cha data, while LkCa 15 is best
explained by multiple orbiting companions.
</p>
{{{{ARTICLE_PARSER}}}}<p>We study the origin of the cold molecular clumps in quasar outflows, recently
detected in CO and HCN emission. We first describe the physical properties of
such radiation-driven outflows and show that a transition from a momentum- to
an energy-driven flow must occur at a radial distance of R ~ 0.25 kpc. During
this transition, the shell of swept up material fragments due to
Rayleigh-Taylor instabilities, but these clumps contain little mass and are
likely to be rapidly ablated by the hot gas in which they are immersed. We then
explore an alternative scenario in which clumps form from thermal instabilities
at R &gt;~ 1 kpc, possibly containing enough dust to catalyze molecule formation.
We investigate this processes with 3D two-fluid (gas+dust) numerical
simulations of a kpc^3 patch of the outflow, including atomic and dust cooling,
thermal conduction, dust sputtering, and photoionization from the QSO radiation
field. In all cases, dust grains are rapidly destroyed in ~10,000 years; and
while some cold clumps form at later times, they are present only as transient
features, which disappear as cooling becomes more widespread. In fact, we only
find a stable two-phase medium with dense clumps if we artificially enhance the
QSO radiation field by a factor 100. This result, together with the complete
destruction of dust grains, renders the interpretation of molecular outflows a
very challenging problem.
</p>
{{{{ARTICLE_PARSER}}}}<p>Being the first of its kind, the white dwarf WD 1145+017 exhibits a complex
system of disintegrating debris which offers a unique opportunity to study its
disruption process in real time. Even with plenty of transit observations there
are no clear constraints on the masses or eccentricities of such debris. Using
$N$-body simulations we show that masses greater than approximately $10^{20}$
kg (a tenth of the mass of Ceres) or orbits that are not nearly circular
($\mathrm{eccentricity}&gt;10^{-3}$) dramatically increase the chances of the
system becoming unstable within two years, which would contrast with the
observational data over this timespan. We also provide a direct comparison
between transit phase shifts detected in the observations and by our numerical
simulations.
</p>
{{{{ARTICLE_PARSER}}}}<p>We apply photo-dissociation region (PDR) molecular line emission models, that
have varying degrees of enhanced mechanical heating rates, to the gaseous
component of simulations of star-forming galaxies taken from the literature.
Snapshots of these simulations are used to produce line emission maps for the
rotational transitions of the CO molecule and its 13CO isotope up to J = 4-3.
</p>
<p>We consider two galaxy models: a small disk galaxy of solar metallicity and a
lighter dwarf galaxy with 0.2 \zsun metallicity. Elevated excitation
temperatures for CO(1 - 0) correlate positively with mechanical feedback, that
is enhanced towards the central region of both model galaxies. The emission
maps of these model galaxies are used to compute line ratios of CO and 13CO
transitions. These line ratios are used as diagnostics where we attempt to
match them These line ratios are used as diagnostics where we attempt to match
them to mechanically heated single component (i.e. uniform density, Far-UV
flux, visual extinction and velocity gradient) equilibrium PDR models.
</p>
<p>We find that PDRs ignoring mechanical feedback in the heating budget
over-estimate the gas density by a factor of 100 and the far-UV flux by factors
of ~10 - 1000. In contrast, PDRs that take mechanical feedback into account are
able to fit all the line ratios for the central &lt; 2 kpc of the fiducial disk
galaxy quite well. The mean mechanical heating rate per H atom that we recover
from the line ratio fits of this region varies between $10^{-27}$ --
$10^{-26}$~erg s$^{-1}$.
</p>
{{{{ARTICLE_PARSER}}}}<p>Far-infrared molecular emission is an important tool used to understand the
excitation mechanisms of the gas in the inter-stellar medium of star-forming
galaxies. In the present work, we model the emission from rotational
transitions with critical densities n &gt;~ 10^4 cm-3. We include 4-3 &lt; J &lt;= 15-14
transitions of CO and 13CO, in addition to J &lt;= 7-6 transitions of HCN, HNC,
and HCO+ on galactic scales. We do this by re-sampling high density gas in a
hydrodynamic model of a gas-rich disk galaxy, assuming that the density field
of the interstellar medium of the model galaxy follows the probability density
function (PDF) inferred from the resolved low density scales. We find that in a
narrow gas density PDF, with a mean density of ~10 cm-3 and a dispersion \sigma
= 2.1 in the log of the density, most of the emission of molecular lines,
emanates from the 10-1000 cm-3 part of the PDF. We construct synthetic emission
maps for the central 2 kpc of the galaxy and fit the line ratios of CO and 13CO
up to J = 15-14, as well as HCN, HNC, and HCO+ up to J = 7-6, using one
photo-dissociation region (PDR) model. We attribute the goodness of the one
component fits for our model galaxy to the fact that the distribution of the
luminosity, as a function of density, is peaked at gas densities between 10 and
1000 cm-3.
</p>
<p>We explore the impact of different log-normal density PDFs on the
distribution of the line-luminosity as a function of density, and we show that
it is necessary to have a broad dispersion, corresponding to Mach numbers &gt;~ 30
in order to obtain significant emission from n &gt; 10^4 cm-3 gas. Such Mach
numbers are expected in star-forming galaxies, LIRGS, and ULIRGS. By fitting
line ratios of HCN(1-0), HNC(1-0), and HCO+(1-0) for a sample of LIRGS and
ULIRGS using mechanically heated PDRs, we constrain the Mach number of these
galaxies to 29 &lt; M &lt; 77.
</p>
{{{{ARTICLE_PARSER}}}}<p>We report spatially resolved (FWHM$\sim3.8-4.6\"$) mid-IR imaging observations
of the planetary nebula (PN) NGC 7027 taken with the 2.5-m telescope aboard the
Stratospheric Observatory for Infrared Astronomy (SOFIA). Images of NGC 7027
were acquired at 6.3, 6.6, 11.1, 19.7, 24.2, 33.6, and 37.1 $\mu\mathrm{m}$
using the Faint Object Infrared Camera for the SOFIA Telescope (FORCAST).The
observations reveal emission from Polycyclic Aromatic Hydrocarbon (PAH) and
warm dust ($T_D\sim90$ K) from the illuminated inner edge of the molecular
envelope surrounding the ionized gas and central star. The DustEM code was used
to fit the spectral energy distribution of fluxes obtained by FORCAST and the
archival infrared spectrum of NGC 7027 acquired by the Short Wavelength
Spectrometer (SWS) on the Infrared Space Observatory (ISO). Best-fit dust
models provide a total dust mass of $5.8^{+2.3}_{-2.6}\times10^{-3}$
$\mathrm{M}_\odot$, where carbonaceous large ($a=1.5$ $\mu$m) and very small
($a \sim12\AA$) grains, and PAHs ($3.1\AA&lt;a&lt;12\AA$) compose 96.5, 2.2, and 1.3
$\%$ of the dust by mass, respectively. The 37 $\mu$m optical depth map shows
minima in the dust column density at regions in the envelope that are
coincident with a previously identified collimated outflow from the central
star. The optical depth minima are also spatially coincident with enhancements
in the 6.2 $\mu$m PAH feature, which is derived from the 6.3 and 6.6 $\mu$m
maps. We interpret the spatial anti-correlation of the dust optical depth and
PAH 6.2 $\mu$m feature strength and their alignment with the outflow from the
central star as evidence of dust processing and rapid PAH formation via
grain-grain collisions in the post-shock environment of the dense
($n_H\sim10^5\,\mathrm{cm}^{-3}$) photo-dissociation region (PDR) and molecular
envelope.
</p>
{{{{ARTICLE_PARSER}}}}<p>Bell et al. (1997) reported the first detection of the cyanopolyyne
HC$_{11}$N toward the cold dark cloud TMC-1; no subsequent detections have been
reported toward any source. Additional observations of cyanopolyynes and other
carbon-chain molecules toward TMC-1 have shown a log-linear trend between
molecule size and column density, and in an effort to further explore the
underlying chemical processes driving this trend, we have analyzed GBT
observations of HC$_9$N and HC$_{11}$N toward TMC-1. Although we find an
HC$_9$N column density consistent with previous values, HC$_{11}$N is not
detected and we derive an upper limit column density significantly below that
reported in Bell et al. Using a state-of-the-art chemical model, we have
investigated possible explanations of non-linearity in the column density
trend. Despite updating the chemical model to better account for ion-dipole
interactions, we are not able to explain the non-detection of HC$_{11}$N, and
we interpret this as evidence of previously unknown carbon-chain chemistry. We
propose that cyclization reactions may be responsible for the depleted
HC$_{11}$N abundance, and that products of these cyclization reactions should
be investigated as candidate interstellar molecules.
</p>
{{{{ARTICLE_PARSER}}}}<p>We, in the present paper, investigate the formation and evolution of
primordial black hole (PBH) within the scenario of nonsingular bouncing
cosmology. We first analyze the PBH formation during the phase of matter
contraction, which is different from that in an expanding background, and then
evaluate the PBH abundance at the end of the contracting phase. Our result
shows that it is generally small unless the energy scale parameter associated
with the bouncing phase is as high as the Planck scale, i.e., $|H_{-}|\gtrsim
M_p$, or the sound speed parameter of cosmological perturbations is
sufficiently small, which implies, $c_s \ll 1$. Afterwards, we study the
subsequent evolution of generating PBHs during the bouncing phase. For the PBH
growth ignoring the Hawking radiation, a relation upon model parameters of the
bouncing phase $\Upsilon \geq c_s^2 \pi^2 H^2_{-}$ is expected to be satisfied,
in case that PBHs would grow to infinity before the bouncing point. We also
calculate the back-reaction of PBHs in order to theoretically constrain bounce
cosmologies by considering the effects of both PBH growth and the associated
Hawking radiation. The constraint is in accordance to the relation $\Upsilon
\geq c_s^2 \pi^2 H^2_{-}$ for the bounce cosmology with a relatively low energy
scale $H_{-}^2 \ll 10^9 c_s^5 M_p^2$.
</p>
{{{{ARTICLE_PARSER}}}}<p>HD 11112 is an old, Sun-like star that has a long-term radial velocity (RV)
trend indicative of a massive companion on a wide orbit. Here we present direct
images of the source responsible for the trend using the Magellan Adaptive
Optics system. We detect the object (HD 11112B) at a separation of 2\fasec 2
(100 AU) at multiple wavelengths spanning 0.6-4 \microns ~and show that it is
most likely a gravitationally-bound cool white dwarf. Modeling its spectral
energy distribution (SED) suggests that its mass is 0.9-1.1 \msun, which
corresponds to very high-eccentricity, near edge-on orbits from Markov chain
Monte Carlo analysis of the RV and imaging data together. The total age of the
white dwarf is $&gt;2\sigma$ discrepant with that of the primary star under most
assumptions. The problem can be resolved if the white dwarf progenitor was
initially a double white dwarf binary that then merged into the observed
high-mass white dwarf. HD 11112B is a unique and intriguing benchmark object
that can be used to calibrate atmospheric and evolutionary models of cool white
dwarfs and should thus continue to be monitored by RV and direct imaging over
the coming years.
</p>
{{{{ARTICLE_PARSER}}}}<p>We present fits to the broadband photometric spectral energy distributions
(SEDs) of 158 eclipsing binaries (EBs) in the Tycho-2 catalog. These EBs were
selected because they have highly precise stellar radii, effective
temperatures, and in many cases metallicities previously determined in the
literature, and thus have bolometric luminosities that are typically good to
$\lesssim$ 10%. In most cases the available broadband photometry spans a
wavelength range 0.4-10 $\mu$m, and in many cases spans 0.15-22 $\mu$m. The
resulting SED fits, which have only extinction as a free parameter, provide a
virtually model-independent measure of the bolometric flux at Earth. The SED
fits are satisfactory for 156 of the EBs, for which we achieve typical
precisions in the bolometric flux of $\approx$ 3%. Combined with the accurately
known bolometric luminosity, the result for each EB is a predicted parallax
that is typically precise to $\lesssim$ 5%. These predicted parallaxes---with
typical uncertainties of 200 $\mu$as---are 4-5 times more precise than those
determined by Hipparcos for 99 of the EBs in our sample, with which we find
excellent agreement. There is no evidence among this sample for significant
systematics in the Hipparcos parallaxes of the sort that notoriously afflicted
the Pleiades measurement. The EBs are distributed over the entire sky, span
more than 10 mag in brightness, reach distances of more than 5 kpc, and in many
cases our predicted parallaxes should also be more precise than those expected
from the Gaia first data release. The EBs studied here can thus serve as
empirical, independent benchmarks for these upcoming fundamental parallax
measurements.
</p>
{{{{ARTICLE_PARSER}}}}<p>We model the mass accretion rate $\dot{M}$ to stellar mass $M_*$ correlation
that has been inferred from observations of intermediate to upper mass T Tauri
stars---that is $\dot{M} \propto M_*^{1.3 \pm 0.3}$. We explain this
correlation within the framework of quiescent disk evolution, in which
accretion is driven largely by gravitational torques acting in the bulk of the
mass and volume of the disk. Stresses within the disk arise from the action of
gravitationally driven torques parameterized in our 1D model in terms of
Toomre's $Q$ criterion. We do not model the hot inner sub-AU scale region of
the disk that is likely stable according to this criterion, and appeal to other
mechanisms to remove or redistribute angular momentum and allow accretion onto
the star. Our model has the advantage of agreeing with large-scale
angle-averaged values from more complex nonaxisymmetric calculations. The model
disk transitions from an early phase (dominated by initial conditions inherited
from the burst mode of accretion) into a later self-similar mode characterized
by a steeper temporal decline in $\dot{M}$. The models effectively reproduce
the spread in mass accretion rates that have been observed for protostellar
objects of $0.2\,\mbox{M}_\odot \le M_* \le 3.0\,\mbox{M}_\odot$, such as those
found in the $\rho$ Ophiuchus and Taurus star forming regions. We then compare
realistically sampled populations of young stellar objects produced by our
model to their observational counterparts. We find these populations to be
statistically coincident, which we argue is evidence for the role of
gravitational torques in the late time evolution of quiescent protostellar
disks.
</p>
{{{{ARTICLE_PARSER}}}}<p>Using an effective one body approach we describe in detail gravitational
waves from classical three body problem on a non-rotating straight line and
derive their basic physical characteristics. Special attention is paid to the
irregular motions of such systems and to the significance of double and triple
collisions. The conclusive role of the collinear solutions is also discussed in
short.
</p>
{{{{ARTICLE_PARSER}}}}<p>We present new HST/WFC3-IR narrowband [Fe II] images of protostellar jets in
the Carina Nebula. Combined with 5 previously published sources, we have a
sample of 18 jets and 2 HH objects. All of the jets we targeted with WFC3 show
bright infrared [Fe II] emission, and a few H$\alpha$ candidate jets are
confirmed as collimated outflows based on the morphology of their [Fe II]
emission. Continuum-subtracted images clearly separate jet emission from the
adjacent ionization front, providing a better tracer of the collimated jet than
H$\alpha$ and allowing us to connect these jets with their embedded driving
sources. The [Fe II] 1.64 $\mu$m/H$\alpha$ flux ratio measured in the jets is
$\gtrsim 5$ times larger than in the adjacent ionization fronts. The
low-ionization jet core requires high densities to shield Fe$^+$ against
further ionization by the FUV radiation from O-type stars in the H II region.
High jet densities imply high mass-loss rates, consistent with the
intermediate-mass driving sources we identify for 13 jets. The remaining jets
emerge from opaque globules that obscure emission from the protostar. In many
respects, the HH jets in Carina look like a scaled-up version of the jets
driven by low-mass protostars. Altogether, these observations suggest that [Fe
II] emission is a reliable tracer of dense, irradiated jets driven by
intermediate-mass protostars. We argue that highly collimated outflows are
common to more massive protostars, and that they suggest the outflow physics
inferred for low-mass stars formation scales up to at least $\sim8$
M$_{\odot}$.
</p>
{{{{ARTICLE_PARSER}}}}<p>We have collected high-dispersion echelle spectra of red giant members in the
twelve open clusters (OCs) and derived stellar parameters and chemical
abundances for 26 species by either line equivalent widths or synthetic
spectrum analyses. We confirm the lack of an age-metallicity relation for OCs
but argue that such a lack of trend for OCs arise from the limited coverage in
metallicity compared to that of field stars which span a wide range in
metallicity and age. We confirm that the radial metallicity gradient of OCs is
steeper (flatter) for Rgc &lt; 12 kpc (&gt; 12 kpc). We demonstrate that the sample
of clusters constituting a steep radial metallicity gradient of slope
$-$0.052$\pm$0.011 dex kpc$^{-1}$ at Rgc &lt; 12 kpc are younger than 1.5 Gyr and
located close to the Galactic midplane (|z| &lt; 0.5 kpc) with kinematics typical
of the thin disc. Whereas the clusters describing a shallow slope of
$-$0.015$\pm$0.007 dex kpc$^{-1}$ at Rgc &gt; 12 kpc are relatively old, thick
disc members with a striking spread in age and height above the midplane (0.5 &lt;
|z| &lt; 2.5 kpc). Our investigation reveals that the OCs and field stars yield
consistent radial metallicity gradients if the comparison is limited to samples
drawn from the similar vertical heights. We argue via the computation of
Galactic orbits that all the outer disc clusters were actually born inward of
12 kpc but the orbital eccentricity has taken them to present locations very
far from their birthplaces.
</p>
{{{{ARTICLE_PARSER}}}}<p>We investigate the scaling properties of the long-range temporal evolution
and intermittency of SDO/AIA intensity observations in four solar environments:
active region core, a weak emission region, and two core loops. We use two
approaches: the probability distribution function (PDF) of time series
increments, and multifractal detrended fluctuation analysis (MF-DFA). Noise
taints the results, so we focus on the 171 Angstrom waveband , which has the
highest signal-to-noise ratio. The lags between pairs of wavebands distinguish
between coronal versus transition region (TR) emission. In all physical regions
studied, scaling in the range 15-45 min is multifractal, and the time series
are anti-persistent on the average. The degree of anti-correlation in the TR
time series is greater than for coronal emission. The multifractality stems
from long term correlations in the data rather than the wide distribution of
intensities. Observations in the 335 Angstrom waveband can be described in
terms of a multifractal with added noise. The multiscaling of the EUV data
agrees qualitatively with the radiance from a phenomenological model of
impulsive bursts plus noise, and also from ohmic dissipation in a Reduced
Magnetohydrodynamics (RMHD) model for coronal loop heating. The parameter space
must be further explored to seek quantitative agreement. Thus, the
observational signatures obtained by the combined tests of the PDF of
increments and the MF-DFA offer strong constraints which can systematically
discriminate among models for coronal heating.
</p>
{{{{ARTICLE_PARSER}}}}<p>The dynamics and evolution of any galactic structure are strongly influenced
by the properties of the orbits that constitute it. In this paper, we compare
two orbit classification schemes, one by Laskar (NAFF) , and the other by
Carpintero and Aguilar (CA), by applying both of them to orbits obtained by
following individual particles in a numerical simulation of a barred galaxy. We
find that, at least for our case and some provisos, the main frequencies
calculated by the two methods are in good agreement: for $80\%$ of the orbits
the difference between the results of the two methods is less than $5\%$ for
all three main frequencies. However, it is difficult to evaluate the amount of
regular or chaotic bar orbits in a given system. The fraction of regular orbits
obtained by the NAFF method strongly depends on the critical frequency drift
parameter, while in the CA method the number of fundamental frequencies
strongly depends on the frequency difference parameter $L_{\rm r}$ and the
maximum integer used for searching the linear independence of the fundamental
frequencies. We also find that, for a given particle, in general the projection
of its motion along the bar minor axis is more regular than the other two
projections, while the projection along the intermediate axis is the least
regular.
</p>
{{{{ARTICLE_PARSER}}}}<p>We use data from the Sydney-AAO Multi-Object Integral Field Spectrograph
(SAMI) Galaxy Survey and the Galaxy And Mass Assembly (GAMA) survey to
investigate the spatially-resolved signatures of the environmental quenching of
star formation in galaxies. Using dust-corrected measurements of the
distribution of H$\alpha$ emission we measure the radial profiles of star
formation in a sample of 201 star-forming galaxies covering three orders of
magnitude in stellar mass (M$_{*}$; $10^{8.1}$-$10^{10.95}\, $M$_{\odot}$) and
in $5^{th}$ nearest neighbour local environment density ($\Sigma_{5}$;
$10^{-1.3}$-$10^{2.1}\,$Mpc$^{-2}$). We show that star formation rate gradients
in galaxies are steeper in dense ($\log_{10}(\Sigma_{5}/$Mpc$^{2})&gt;0.5$)
environments by $0.58\pm 0.29\, dex\, $r$_{e}^{-1}$ in galaxies with stellar
masses in the range $10^{10}&lt;$M$_{*}/$M$_{\odot}&lt;10^{11}$ and that this
steepening is accompanied by a reduction in the integrated star formation rate.
However, for any given stellar mass or environment density the star-formation
morphology of galaxies shows large scatter. We also measure the degree to which
the star formation is centrally concentrated using the unitless scale-radius
ratio ($r_{50,H\alpha}/r_{50,cont}$), which compares the extent of ongoing star
formation to previous star formation. With this metric we find that the
fraction of galaxies with centrally concentrated star formation increases with
environment density, from $\sim 5\pm 4\%$ in low-density environments
($\log_{10}(\Sigma_{5}/$Mpc$^{2})&lt;0.0$) to $30\pm 15\%$ in the highest density
environments ($\log_{10}(\Sigma_{5}/$Mpc$^{2})&gt;1.0$). These lines of evidence
strongly suggest that with increasing local environment density the star
formation in galaxies is suppressed, and that this starts in their outskirts
such that quenching occurs in an outside-in fashion in dense environments and
is not instantaneous.
</p>
{{{{ARTICLE_PARSER}}}}<p>We propose to use the flux variability of lensed quasar images induced by
gravitational microlensing to measure the transverse peculiar velocity of lens
galaxies over a wide range of redshift. Microlensing variability is caused by
the motions of the observer, the lens galaxy (including the motion of the stars
within the galaxy), and the source; hence, its frequency is directly related to
the galaxy's transverse peculiar velocity. The idea is to count time-event
rates (e.g., peak or caustic crossing rates) in the observed microlensing light
curves of lensed quasars that can be compared with model predictions for
different values of the transverse peculiar velocity. To compensate for the
large time-scale of microlensing variability we propose to count and model the
number of events in an ensemble of gravitational lenses. We develop the
methodology to achieve this goal and apply it to an ensemble of 17 lensed
quasar systems. In spite of the shortcomings of the available data, we have
obtained tentative estimates of the peculiar velocity dispersion of lens
galaxies at $z\sim 0.5$, $\sigma_{\rm
pec}(0.53\pm0.18)\simeq(638\pm213)\sqrt{\langle m \rangle/0.3 M_\odot} \, \rm
km\, s^{-1}$. Scaling at zero redshift we derive, $\sigma_{\rm
pec}(0)\simeq(491\pm164) \sqrt{\langle m \rangle/0.3 M_\odot} \, \rm km\,
s^{-1}$, consistent with peculiar motions of nearby galaxies and with recent
$N$-body nonlinear reconstructions of the Local Universe based on $\Lambda$CDM.
We analyze the different sources of uncertainty of the method and find that for
the present ensemble of 17 lensed systems the error is dominated by Poissonian
noise, but that for larger ensembles the impact of the uncertainty on the
average stellar mass may be significant.
</p>
{{{{ARTICLE_PARSER}}}}<p>Quasi-periodic pulsations (or QPPs) are periodic intensity variations in the
flare emission, across all wavelength bands. In this paper, we review the
observational and modelling achievements since the previous review on this
topic by Nakariakov &amp; Melnikov (2009). In recent years, it has become clear
that QPPs are an inherent feature of solar flares, because almost all flares
exhibit QPPs. Moreover, it is now firmly established that QPPs often show
multiple periods. We also review possible mechanisms for generating QPPs. Up to
now, it has not been possible to conclusively identify the triggering mechanism
or cause of QPPs. The lack of this identification currently hampers possible
seismological inferences of flare plasma parameters. QPPs in stellar flares
have been detected for a long time, and the high quality data of the Kepler
mission allows to study the QPP more systematically. However, it has not been
conclusively shown whether the time scales of stellar QPPs are different or the
same as those in solar flares.
</p>
{{{{ARTICLE_PARSER}}}}<p>Motivated by the significant interaction of convection, rotation and magnetic
field in many astrophysical objects, we investigate the interplay between
large-scale flows driven by rotating convection and an imposed magnetic field.
We utilise a simple model in two dimensions comprised of a plane layer that is
rotating about an axis inclined to gravity. It is known that this setup can
result in strong mean flows; we numerically examine the effect of an imposed
horizontal magnetic field on such flows. We show that increasing the field
strength in general suppresses the time-dependent mean flows, but in some cases
it organises them leading to stronger time-averaged flows. Further, we discuss
the effect of the field on the correlations responsible for driving the flows
and the competition between Reynolds and Maxwell stresses. A change in
behaviour is observed when the (fluid and magnetic) Prandtl numbers are
decreased. In the smaller Prandtl number regime, it is shown that significant
mean flows can persist even when the quenching of the overall flow velocity by
the field is relatively strong.
</p>
{{{{ARTICLE_PARSER}}}}<p>A giant planet embedded in a protoplanetary disc creates a gap. This process
is important for both theory and observations. Gap openings are intimately
connected with orbital migration and the mass growth of a planet. It has
recently been observed that discs around young stars are rich in structure, and
the interaction between a planet and a disc is considered to be one possible
origin of this structure. We performed two-dimensional hydrodynamic
simulations, varying the planet mass, disc aspect ratio, and viscosity in a
wide range of parameters. This relationship enables us to judge whether an
observed gap is likely to have been caused by an embedded planet. It is also
possible to predict the planet mass from observations of the gap shape. Based
on the results of hydrodynamic simulations, we present an empirical model of
wave excitation and damping with deep gaps. Using this model of wave excitation
and damping, we constructed a semianalytical model of the gap surface density
distribution, and it reproduces the gap radial profile obtained from the
two-dimensional hydrodynamic simulations.
</p>
{{{{ARTICLE_PARSER}}}}<p>The size of the diameter of the Sun has been debated for a very long time.
First tackled by the Greek astronomers from a geometric point of view, an
estimate, although incorrect, has been determined, not truly called into
question for several centuries. The French school of astronomy, under the
impetus of Mouton and Picard in the XVIIth century can be considered as a
pioneer in this issue. It was followed by the German school at the end of the
XIXth century whose works led to a canonical value established at 959\".63
(second of arc). A number of ground-based observations has been made in the
second half of the XIXth century leading to controversial results mainly due to
the difficulty to disentangle between the solar and atmospheric effects.
Dedicated space measurements yield to a very faint dependence of the solar
diameter with time. New studies over the entire radiation spectrum lead to a
clear relationship between the solar diameter and the wavelength, reflecting
the height at which the lines are formed. Thus the absolute value of the solar
diameter, which is a reference for many astrophysical applications, must be
stated according to the wavelength. Furthermore, notable features of the Near
Sub-Surface Layer (NSSL), called the leptocline, can be established in relation
to the solar limb variations, mainly through the shape asphericities
coefficients. The exact relationship has not been established yet, but recent
studies encourage further in-depth investigations of the solar subsurface
dynamics, both observationally and by numerical MHD simulations.
</p>
{{{{ARTICLE_PARSER}}}}<p>Typical solar flares display two quasi-parallel, bright ribbons on the
chromosphere. In between is the polarity inversion line (PIL) separating
concentrated magnetic fluxes of opposite polarity in active regions (ARs).
Intriguingly a series of flares exhibiting X-shaped ribbons occurred at the
similar location on the outskirts of NOAA AR 11967, where magnetic fluxes were
scattered, yet three of them were alarmingly energetic. The X shape, whose
center coincided with hard X-ray emission, was similar in UV/EUV, which cannot
be accommodated in the standard flare model. Mapping out magnetic
connectivities in potential fields, we found that the X morphology was dictated
by the intersection of two quasi-separatrix layers, i.e., a hyperbolic flux
tube (HFT), within which a separator connecting a double null was embedded.
This topology was not purely local but regulated by fluxes and flows over the
whole AR. The nonlinear force-free field model suggested the formation of a
current layer at the HFT, where the current dissipation can be mapped to the
X-shaped ribbons via field-aligned heat conduction. These results highlight the
critical role of HFTs in 3D magnetic reconnection and have important
implications for astrophysical and laboratory plasmas.
</p>
{{{{ARTICLE_PARSER}}}}<p>Non-local thermodynamic equilibrium (non-LTE) line formation for Ca I-Ca II,
Ti I-Ti II, and Fe I-Fe II is considered in model atmospheres of giant stars
with an effective temperature of 4000 K $\le$ Teff $\le$ 5000 K and a metal
abundance of -4 $\le$ [Fe/H] $\le$ 0. The departures from LTE are analyzed
depending on atmospheric parameters. We present the non-LTE abundance
corrections for 28 lines of Ca I, 42 lines of Ti I, 54 lines of Ti II, and 262
lines of Fe I and a three-dimensional interpolation code to obtain the non-LTE
correction online (<a href=\"http://spectrum.inasan.ru/nLTE/\">this http URL</a>) for an individual spectral
line and given atmospheric parameters.
</p>
{{{{ARTICLE_PARSER}}}}<p>Massive binary systems are important laboratories in which to probe the
properties of massive stars and stellar physics in general. In this context, we
analysed optical spectroscopy and photometry of the eccentric short-period
early-type binary HD 152218 in the young open cluster NGC 6231. We
reconstructed the spectra of the individual stars using a separating code. The
individual spectra were then compared with synthetic spectra obtained with the
CMFGEN model atmosphere code. We furthermore analysed the light curve of the
binary and used it to constrain the orbital inclination and to derive absolute
masses of 19.8 +/- 1.5 and 15.0 +/- 1.1 solar masses. Combining radial velocity
measurements from over 60 years, we show that the system displays apsidal
motion at a rate of (2.04^{+.23}_{-.24}) degree/year. Solving the
Clairaut-Radau equation, we used stellar evolution models, obtained with the
CLES code, to compute the internal structure constants and to evaluate the
theoretically predicted rate of apsidal motion as a function of stellar age and
primary mass. In this way, we determine an age of 5.8 +/- 0.6 Myr for HD
152218, which is towards the higher end of, but compatible with, the range of
ages of the massive star population of NGC 6231 as determined from isochrone
fitting.
</p>
{{{{ARTICLE_PARSER}}}}<p>We pursue the investigation of a model for sub-Chandrasekhar supernovae Ia
explosions (SNIa) in which the energy stored in the Pauli tower is released to
trigger a nuclear deflagration. The simplest physical model for such a
degeneracy breakdown is a phase transition to an exactly supersymmetric state
in which the scalar partners of protons, neutrons, and leptons become
degenerate with the familiar fermions of our world as in the supersymmetric
standard model with susy breaking parameters relaxed to zero. We focus on the
ability of the susy phase transition model to fit the total SNIa rate as well
as the delay time distribution of SNIa after the birth of a progenitor white
dwarf. We also study the ejected mass distribution and its correlation with
delay time. Finally, we discuss the expected SNIa remnant in the form of a
black hole of Jupiter mass or lower and the prospects for detecting such
remnants.
</p>
{{{{ARTICLE_PARSER}}}}<p>Due to the failure of the second reaction wheel, a new mission was conceived
for the otherwise healthy Kepler space telescope. In the course of the K2
Mission, the telescope is staring at the plane of the Ecliptic, hence thousands
of Solar System bodies cross the K2 fields, usually causing extra noise in the
highly accurate photometric data. In this paper we follow the someone's noise
is another one's signal principle and investigate the possibility of deriving
continuous asteroid light curves, that has been unprecedented to date. In
general, we are interested in the photometric precision that the K2 Mission can
deliver on moving Solar System bodies. In particular, we investigate space
photometric optical light curves of main-belt asteroids. We study the K2
superstamps covering the M35 and Neptune/Nereid fields observed in the long
cadence (29.4-min sampling) mode. Asteroid light curves are generated by
applying elongated apertures. We use the Lomb-Scargle method to find
periodicities due to rotation. We derived K2 light curves of 924 main-belt
asteroids in the M35 field, and 96 in the path of Neptune and Nereid. The light
curves are quasi-continuous and several days long. K2 observations are
sensitive to longer rotational periods than usual ground-based surveys.
Rotational periods are derived for 26 main-belt asteroids for the first time.
The asteroid sample is dominated by faint (&gt;20 mag) objects. Due to the
faintness of the asteroids and the high density of stars in the M35 field, only
4.0% of the asteroids with at least 12 data points show clear periodicities or
trend signalling a long rotational period, as opposed to 15.9% in the less
crowded Neptune field. We found that the duty cycle of the observations had to
reach ~60% in order to successfully recover rotational periods.
</p>
{{{{ARTICLE_PARSER}}}}<p>We present fully covered phased light curves for 56 Jovian Trojan asteroids
as acquired by the K2 mission of the Kepler space telescope. This set of
objects has been monitored during Campaign 6 and represents a nearly unbiased
subsample of the population of small Solar System bodies. We derived precise
periods and amplitudes for all Trojans, and found their distributions to be
compatible with the previous statistics. We point out, however, that
ground-based rotation periods are often unreliable above 20h, and we find an
overabundance of rotation periods above 60h compared with other minor planet
populations. From amplitude analysis we derive a rate of binarity of 20$\pm$
5%. Our spin rate distribution confirms the previously obtained spin barrier of
~5h and the corresponding ~0.5 g cm$^{-3}$ cometary-like density limit, also
suggesting a high internal porosity for Jovian Trojans. One of our targets,
asteroid 65227 exhibits a double rotation period, which can either be due to
binarity or the outcome of a recent collision.
</p>
{{{{ARTICLE_PARSER}}}}<p>We present the discovery of the transiting exoplanets HAT-P-65b and
HAT-P-66b, with orbital periods of 2.6055 d and 2.9721 d, masses of $0.527 \pm
0.083$ M$_{J}$ and $0.783 \pm 0.057$ M$_{J}$ and inflated radii of $1.89 \pm
0.13$ R$_{J}$ and $1.59^{+0.16}_{-0.10}$ R$_{J}$, respectively. They orbit
moderately bright ($V=13.145 \pm 0.029$, and $V=12.993 \pm 0.052$) stars of
mass $1.212 \pm 0.050$ M$_{\odot}$ and $1.255^{+0.107}_{-0.054}$ M$_{\odot}$.
The stars are at the main sequence turnoff. While it is well known that the
radii of close-in giant planets are correlated with their equilibrium
temperatures, whether or not the radii of planets increase in time as their
hosts evolve and become more luminous is an open question. Looking at the
broader sample of well-characterized close-in transiting giant planets, we find
that there is a statistically significant correlation between planetary radii
and the fractional ages of their host stars, with a false alarm probability of
only 0.0041%. We find that the correlation between the radii of planets and the
fractional ages of their hosts is fully explained by the known correlation
between planetary radii and their present day equilibrium temperatures, however
if the zero-age main sequence equilibrium temperature is used in place of the
present day equilibrium temperature then a correlation with age must also be
included to explain the planetary radii. This suggests that, after contracting
during the pre-main-sequence, close-in giant planets are re-inflated over time
due to the increasing level of irradiation received from their host stars.
Prior theoretical work indicates that such a dynamic response to irradiation
requires a significant fraction of the incident energy to be deposited deep
within the planetary interiors.
</p>
{{{{ARTICLE_PARSER}}}}<p>Rayleigh-Benard convection and Taylor-Couette flow are two canonical flows
that have many properties in common. We here compare the two flows in detail
for parameter values where the Nusselt numbers, i.e. the thermal transport and
the angular momentum transport normalized by the corresponding laminar values,
coincide. We study turbulent Rayleigh-Benard convection in air at Rayleigh
number Ra=1e7 and Taylor-Couette flow at shear Reynolds number Re_S=2e4 for two
different mean rotation rates but the same Nusselt numbers. For individual
pairwise related fields and convective currents, we compare the probability
density functions normalized by the corresponding root mean square values and
taken at different distances from the wall. We find one rotation number for
which there is very good agreement between the mean profiles of the two
corresponding quantities temperature and angular momentum. Similarly, there is
good agreement between the fluctuations in temperature and velocity components.
For the heat and angular momentum currents, there are differences in the
fluctuations outside the boundary layers that increase with overall rotation
and can be related to differences in the flow structures in the boundary layer
and in the bulk. The study extends the similarities between the two flows from
global quantities to local quantities and reveals the effects of rotation on
the transport.
</p>
{{{{ARTICLE_PARSER}}}}<p>We perform a detailed analysis on a primordial gravitational-wave background
amplified during a Kasner-like pre-inflationary phase allowing for general
triaxial anisotropies. It is found that the predicted angular distribution map
of gravitational-wave intensity on large scales exhibits topologically
distinctive patterns according to the degree of the pre-inflationary
anisotropy, thereby serving as a potential probe for the pre-inflationary early
universe with future all-sky observations of gravitational waves. We also
derive an observational limit on the amplitude of such anisotropic
gravitational waves from the B-mode polarisation of the cosmic microwave
background.
</p>
{{{{ARTICLE_PARSER}}}}<p>The census of the Solar neighbourhood is still incomplete, as demonstrated by
recent discoveries of many objects within 5-10 pc from the Sun. The area around
the mid-plane and bulge of the Milky Way presents the most difficulties in
searches for such nearby objects, and is therefore deficient in the known
population. This is largely due to high stellar densities encountered.
Spectroscopic, photometric and kinematic characterization of these objects
allows better understand the local mass function, the binary fraction, and
provides new interesting targets for more detailed studies. We report the
spectroscopic follow-up and characterisation of 12 bright high PM objects,
identified from the VISTA Variables in Via Lactea survey (VVV). We used the
1.9-m telescope of the South African Astronomical Observatory (SAAO) for
low-resolution optical spectroscopy and spectral classification, and the
MPG/ESP 2.2m telescope Fiber-fed Extended Range Optical Spectrograph (FEROS)
high-resolution optical spectroscopy to obtain the radial and space velocities
for three of them. Six of our objects have co-moving companions. We derived
optical spectral types and photometric distances, and classified all of them as
K and M dwarfs within 27-264 pc of the Sun. Finally, we found that one of the
sources, VVV J141421.23-602326.1 (a co-moving companion of VVV
J141420.55-602337.1), appears to be a rare massive white dwarf that maybe close
to the ZZ Ceti instability strip. Many of the objects in our list are
interesting targets for exoplanet searches.
</p>
{{{{ARTICLE_PARSER}}}}<p>A nearby supernova (SN) explosion could have negatively influenced life on
Earth, maybe even been responsible for mass extinctions. Mass extinction poses
a significant extinction of numerous species on Earth, as recorded in the
paleontologic, paleoclimatic, and geological record of our planet. Depending on
the distance between the Sun and the SN, different types of threats have to be
considered, such as ozone depletion on Earth, causing increased exposure to the
Sun's ultraviolet radiation, or the direct exposure of lethal x-rays. Another
indirect effect is cloud formation, induced by cosmic rays in the atmosphere
which result in a drop in the Earth's temperature, causing major glaciations of
the Earth. The discovery of highly intensive gamma ray bursts (GRBs), which
could be connected to SNe, initiated further discussions on possible
life-threatening events in Earth's history. The probability that GRBs hit the
Earth is very low. Nevertheless, a past interaction of Earth with GRBs and/or
SNe cannot be excluded and might even have been responsible for past extinction
events.
</p>
{{{{ARTICLE_PARSER}}}}<p>The Galactic Archaeology with HERMES (GALAH) Survey is a massive
observational project to trace the Milky Way's history of star formation,
chemical enrichment, stellar migration and minor mergers. Using high-resolution
(R$\simeq$28,000) spectra taken with the High Efficiency and Resolution
Multi-Element Spectrograph (HERMES) instrument at the Anglo-Australian
Telescope (AAT), GALAH will determine stellar parameters and abundances of up
to 29 elements for up to one million stars. Selecting targets from a
colour-unbiased catalogue built from 2MASS, APASS and UCAC4 data, we expect to
observe dwarfs at 0.3 to 3 kpc and giants at 1 to 10 kpc. This enables a
thorough local chemical inventory of the Galactic thin and thick disks, and
also captures smaller samples of the bulge and halo. In this paper we present
the plan, process and progress as of early 2016 for GALAH survey observations.
In our first two years of survey observing we have accumulated the largest
high-quality spectroscopic data set at this resolution, over 200,000 stars. We
also present the first public GALAH data catalogue: stellar parameters (Teff,
log(g), [Fe/H], [alpha/Fe]), radial velocity, distance modulus and reddening
for 10680 observations of 9860 Tycho-2 stars that may be included in the first
Gaia data release.
</p>
{{{{ARTICLE_PARSER}}}}<p>We report a study on axially and reflection symmetric dissipative fluids,
just after its departure from hydrostatic and thermal equilibrium, at the
smallest time scale at which the first signs of dynamic evolution appear. Such
a time scale is smaller than the thermal relaxation time, the thermal
adjustment time and the hydrostatic time. It is obtained that the onset of
non--equilibrium will critically depend on a single function directly related
to the time derivative of the vorticity. Among all fluid variables (at the time
scale under consideration), only the tetrad component of the anisotropic tensor
in the subspace orthogonal to the four--velocity and the Killing vector of
axial symmetry, shows signs of dynamic evolution. Also, the first step towards
a dissipative regime begins with a non--vanishing time derivative of the heat
flux component along the meridional direction. The magnetic part of the Weyl
tensor vanishes (not so its time derivative), indicating that the emission of
gravitational radiation will occur at later times. Finally, the decreasing of
the effective inertial mass density, associated to thermal effects, is clearly
illustrated.
</p>
{{{{ARTICLE_PARSER}}}}<p>The origin of the very red optical and infrared colours of intermediate-age
($\sim$10 - 500 Myr) L-type dwarfs remains unknown. It has been suggested that
low-gravity atmospheres containing large amounts of dust may account for the
observed reddish nature. We explored an alternative scenario by simulating
protoplanetary and debris discs around G196-3B, which is an L3 young brown
dwarf with a mass of $\sim 15$ $M_{\rm Jup}$ and an age in the interval 20 -
300 Myr. The best-fit solution to G196-3B's photometric spectral energy
distribution from optical wavelengths through 24 $\mu$m corresponds to the
combination of an unreddened L3 atmosphere ($T_{\rm eff} \approx 1870$~K) and a
warm ($\approx$ 1280 K), narrow ($\approx$ 0.07 - 0.11 R$_{\odot}$) debris disc
located at very close distances ($\approx$ 0.12 - 0.20 R$_{\odot}$) from the
central brown dwarf. This putative, optically thick, dusty belt, whose presence
is compatible with the relatively young system age, would have a mass $\ge
7\times 10^{-10}$ M$_{\oplus}$ comprised of sub-micron/micron characteristic
dusty particles with temperatures close to the sublimation threshold of
silicates. Considering the derived global properties of the belt and the
disc-to-brown dwarf mass ratio, the dusty ring around G196-3B may resemble the
rings of Neptune and Jupiter, except for its high temperature and thick
vertical height ($\approx 6 \times 10^3$ km). Our inferred debris disc model is
able to reproduce G196-3B's spectral energy distribution to a satisfactory
level of achievement.
</p>
{{{{ARTICLE_PARSER}}}}<p>Hybrid $\delta$ Scuti-$\gamma$ Doradus pulsating stars show acoustic ($p$)
oscillation modes typical of $\delta$ Scuti variable stars, and gravity ($g$)
pulsation modes characteristic of $\gamma$ Doradus variable stars
simultaneously excited. Observations from space missions like MOST, CoRoT, and
\emph{Kepler} have revealed a large number of hybrid $\delta$ Scuti-$\gamma$
Doradus pulsators, thus paving the way for a exciting new channel for
asteroseismic studies. We perform a detailed asteroseismological modeling of
five hybrid $\delta$ Scuti-$\gamma$ Doradus stars. We employ a grid-based
modeling approach to sound the internal structure of the target stars by
employing a huge grid of stellar models from the zero-age main sequence to the
terminal-age main sequence, varying parameters like stellar mass, effective
temperature, metallicity and core overshooting. We compute their adiabatic
radial ($\ell= 0$) and non-radial ($\ell= 1, 2, 3$) $p$ and $g$ mode periods.
We employ two model-fitting procedures to searching for the models that best
reproduce the observed pulsation spectra of each target star, that is, the
asteroseismological models. We derive the fundamental parameters and the
evolutionary status of five hybrid $\delta$ Scuti-$\gamma$ Doradus variable
stars recently observed with the CoRoT and \emph{Kepler} space missions: CoRoT
105733033, CoRoT 100866999, KIC 11145123, KIC 9244992, and HD 49434. The
asteroseismological model for each star results from different criteria of
model selection, in which we take full advantage of the richness of periods
that characterizes the pulsation spectra of this kind of stars.
</p>
{{{{ARTICLE_PARSER}}}}<p>The VERITAS imaging atmospheric Cherenkov telescope array has been observing
the northern TeV sky with four telescopes since summer 2007. Over 50 gamma-ray
sources have been studied, including active and starburst galaxies, pulsars and
their nebulae, supernova remnants and Galactic binary systems. We review here
some of the most recent VERITAS results, and discuss the status and prospects
for collaborative work with other gamma-ray instruments, and with
multimessenger observatories.
</p>
{{{{ARTICLE_PARSER}}}}<p>The mechanism for acceleration of cosmic rays in supernova remnants (SNRs) is
an outstanding question in the field. We model a sample of 32 axisymmetric SNRs
using the quasi-perpendicular and quasi-parallel cosmic-ray-electron (CRE)
acceleration cases. The axisymmetric sample is defined to include SNRs with a
double-sided, bilateral morphology, and also those with a one-sided morphology
where one limb is much brighter than the other. Using a coordinate
transformation technique, we insert a bubble-like model SNR into a model of the
Galactic magnetic field. Since radio emission of SNRs is dominated by
synchrotron emission and since this emission depends on the magnetic field and
CRE distribution, we are able to simulate the SNRs emission and compare this to
data. We find that the quasi-perpendicular CRE acceleration case is much more
consistent with the data than the quasi-parallel CRE acceleration case, with
G327.6+14.6 (SN1006) being a notable exception. We propose that SN1006 may be a
case where both quasi-parallel and quasi-perpendicular acceleration are
simultaneously at play in a single SNR.
</p>
{{{{ARTICLE_PARSER}}}}<p>We update the ingredients of the Gaussian streaming model (GSM) for the
redshift-space clustering of biased tracers using the techniques of Lagrangian
perturbation theory, effective field theory (EFT) and a generalized Lagrangian
bias expansion. After relating the GSM to the cumulant expansion, we present
new results for the real-space correlation function, mean pairwise velocity and
pairwise velocity dispersion including counter terms from EFT and bias terms
through third order in the linear density, its leading derivatives and its
shear up to second order. We discuss the connection to the Gaussian peaks
formalism. We compare the ingredients of the GSM to a suite of large N-body
simulations, and show the performance of the theory on the low order multipoles
of the redshift-space correlation function and power spectrum. We highlight the
importance of a general biasing scheme, which we find to be as important as
higher-order corrections due to non-linear evolution for the halos we consider
on the scales of interest to us.
</p>
{{{{ARTICLE_PARSER}}}}<p>In this proceedings, I will consider quantum aspects of a non-local,
infinite-derivative scalar field theory - a ${\it toy \, model}$ depiction of a
covariant infinite-derivative, non-local extension of Einstein's general
relativity which has previously been shown to be free from ghosts around the
Minkowski background. The graviton propagator in this theory gets an
exponential suppression making it ${\it asymptotically \, free}$, thus
providing strong prospects of resolving various classical and quantum
divergences. In particular, I will find that at $1$-loop, the $2$-point
function is still divergent, but once this amplitude is renormalized by adding
appropriate counter terms, the ultraviolet (UV) behavior of all other $1$-loop
diagrams as well as the $2$-loop, $2$-point function remains well under
control. I will go on to discuss how one may be able to generalize our
computations and arguments to arbitrary loops.
</p>
{{{{ARTICLE_PARSER}}}}<p>In this work we reformulate the forward modelling of the redshift-space power
spectrum multipole moments for a masked density field, as encountered in galaxy
redshift surveys. Exploiting the symmetries of the redshift-space correlation
function, we provide a masked-field generalisation of the Hankel transform
relation between the multipole moments in real and Fourier space. Using this
result, we detail how a likelihood analysis requiring computation for a broad
range of desired $P(k)$ models may be executed $10^3-10^4$ times faster than
with other common approaches, together with significant gains in spectral
resolution. We present a concrete application to the complex angular geometry
of the VIPERS PDR-1 release and discuss the validity of this technique for
finite-angle surveys.
</p>
{{{{ARTICLE_PARSER}}}}<p>The methods for studying the epoch of cosmic reionization vary from full
radiative transfer simulations to purely analytical models. While numerical
approaches are computationally expensive and are not suitable for generating
many mock catalogs, analytical methods are based on assumptions and
approximations. We explore the interconnection between both methods. First, we
ask how the analytical framework of excursion set formalism can be used for
statistical analysis of numerical simulations and visual representation of the
morphology of ionization fronts. Second, we explore the methods of training the
analytical model on a given numerical simulation. We present a new code which
emerged from this study. Its main application is to match the analytical model
with a numerical simulation. Then, it allows one to generate mock reionization
catalogs with volumes exceeding the original simulation quickly and
computationally inexpensively, meanwhile reproducing large scale statistical
properties. These mock catalogs are particularly useful for CMB polarization
and 21cm experiments, where large volumes are required to simulate the observed
signal.
</p>
{{{{ARTICLE_PARSER}}}}<p>The fundamental singularity theorem of FLRW cosmologies assumes that the
matter content in the cosmological model obeys the strong energy condition
along with a nonpositive cosmological constant which gives rise to an
irrotational geodesic singularity. In this paper, we show that the important
case of a spatially flat Friedmann-Lema\^{i}tre-Robertson-Walker universe with
barotropic matter obeying only the \emph{weak} energy condition with a
nonnegative cosmological constant also contains a past singularity. We
accomplish this using topological methods from dynamical systems theory. The
methods employed in this paper are sufficiently general that they could be
extended to other models to study the existence of past singularities.
</p>
{{{{ARTICLE_PARSER}}}}<p>The gravitational wave observations GW150914 and GW151226 by Advanced LIGO
provide the first opportunity to learn about physics in the extreme gravity
environment of coalescing binary black holes. The LIGO Scientific Collaboration
and the Virgo Collaboration have verified that this observation is consistent
with General Relativity. This paper expands their analysis to a larger class of
anomalies, highlighting the inferences that can be drawn on non-standard
theoretical physics mechanisms. We find that these events constrain a plethora
of mechanisms associated with the generation and propagation of gravitational
waves, including the activation of scalar fields, gravitational leakage into
large extra dimensions, the variability of Newton's constant, a modified
dispersion relation, gravitational Lorentz violation and the strong equivalence
principle. Though other observations limit many of these mechanisms already,
GW150914 and GW151226 are unique in that they are direct probes of dynamical
strong-field gravity and of gravitational wave propagation. We also show that
GW150914 constrains inferred properties of exotic compact object alternatives
to Kerr black holes. We argue, however, that the true potential for GW150914 to
both rule out exotic objects and constrain physics beyond General Relativity is
severely limited by the lack of understanding of the merger regime in almost
all relevant modified gravity theories. This event thus significantly raises
the bar that these theories have to pass, both in terms of having a sound
theoretical underpinning, and being able to solve the equations of motion for
binary merger events. We conclude with a discussion of the additional
inferences that can be drawn if the lower-confidence observation of an
electromagnetic counterpart to GW150914 holds true; this would provide dramatic
constraints on the speed of gravity and gravitational Lorentz violation.
</p>
{{{{ARTICLE_PARSER}}}}<p>We summarize previous results on the most general Proca theory in 4
dimensions containing only first-order derivatives in the vector field
(second-order at most in the associated St\\"uckelberg scalar) and having only
three propagating degrees of freedom with dynamics controlled by second-order
equations of motion. Discussing the Hessian condition used in previous works,
we conjecture that, as in the scalar galileon case, the most complete action
contains only a finite number of terms with second-order derivatives of the
St\\"uckelberg field describing the longitudinal mode, which is in agreement
with the results of JCAP 1405, 015 (2014) and Phys. Lett. B 757, 405 (2016) and
complements those of JCAP 1602, 004 (2016). We also correct and complete the
parity violating sector, obtaining an extra term on top of the arbitrary
function of the field $A_\mu$, the Faraday tensor $F_{\mu \nu}$ and its Hodge
dual $\tilde{F}_{\mu \nu}$.
</p>
{{{{ARTICLE_PARSER}}}}<p>One of the possible sources of hadronic cosmic rays (CRs) are newborn
pulsars. If this is indeed the case, they should feature diffusive gamma-ray
halos produced by interactions of CRs with interstellar gas. In this paper we
try to identify extended gamma-ray emission around young pulsars, making use of
the 7-year Fermi-LAT data. For this purpose we select and analyze a set of
eight pulsars that are most likely to possess detectable gamma-ray halos. We
find extended emission that might be interpreted as a gamma-ray halo only in
the case of PSR J0007+7303. Its luminosity accords with the total energy of
injected cosmic rays $\sim 10^{50}$ erg, although other interpretations of this
source are possible. Irrespectively of the nature of this source we put bounds
on the luminosity of gamma-ray halos which suggest that pulsars' contribution
to the overall energy budget of galactic CRs is subdominant in the GeV-TeV
range.
</p>
{{{{ARTICLE_PARSER}}}}<p>We probe the anisotropy of the large-scale structure (LSS) with the
WISE-2MASS catalogue. This analysis is performed by a directional comparison of
the galaxy number counts through the entire celestial sphere once systematic
effects, such as star-galaxy separation and foregrounds contamination, are
properly taken into account. We find a maximal hemispherical asymmetry whose
dipolar component is $A = 0.0507 \pm 0.0014$ toward the $(l,b) =
(323^{\circ},-5^{\circ})$ direction, whose result is consistent with previous
estimations of our proper motion in low and intermediate redshifts, as those
carried out with Type Ia Supernovae and similar LSS catalogues. Furthermore,
this dipole amplitude is statistically consistent ($p$-value = $0.061$) with
mock catalogues simulated according to the expected $\Lambda$CDM matter density
fluctuations, in addition to observational biases such as the incomplete
celestial coverage and anisotropic sky exposure. Our results suggest,
therefore, that there is no strong evidence for anomalous anisotropy in the
LSS, given the limitations and systematics of current data, in the concordance
model scenario.
</p>
{{{{ARTICLE_PARSER}}}}<p>The standard approaches to Bayesian parameter inference in large scale
structure (LSS) assume a Gaussian functional form (chi-squared form) for the
likelihood. They are also typically restricted to measurements such as the two
point correlation function. Likelihood free inferences such as Approximate
Bayesian Computation (ABC) make inference possible without assuming any
functional form for the likelihood, thereby relaxing the assumptions and
restrictions of the standard approach. Instead it relies on a forward
generative model of the data and a metric for measuring the distance between
the model and data. In this work, we demonstrate that ABC is feasible for LSS
parameter inference by using it to constrain parameters of the halo occupation
distribution (HOD) model for populating dark matter halos with galaxies.
</p>
<p>Using specific implementation of ABC supplemented with Population Monte Carlo
importance sampling, a generative forward model using HOD, and a distance
metric based on galaxy number density, two-point correlation function, and
galaxy group multiplicity function, we constrain the HOD parameters of mock
observation generated from selected \"true\" HOD parameters. The parameter
constraints we obtain from ABC are consistent with the \"true\" HOD parameters,
demonstrating that ABC can be reliably used for parameter inference in LSS.
Furthermore, we compare our ABC constraints to constraints we obtain using a
pseudo-likelihood function of Gaussian form with MCMC and find consistent HOD
parameter constraints. Ultimately our results suggest that ABC can and should
be applied in parameter inference for LSS analyses.
</p>
{{{{ARTICLE_PARSER}}}}<p>The properties of $\isotope[12]{C}$, $\isotope[16]{O}$, and
$\isotope[20]{Ne}$ nuclei in strong magnetic fields $B\simeq 10^{17}\,$G are
studied in the context of strongly magnetized neutron stars and white dwarfs.
The SKY3D code is extended to incorporate the interaction of nucleons with the
magnetic field and is utilized to solve the time-independent Hartree-Fock
equations with a Skyrme interaction on a Cartesian three-dimensional grid. The
numerical solutions demonstrate a number of phenomena, which include a
splitting of the energy levels of spin-up and -down nucleons, spontaneous
rearrangment of energy levels in $\isotope[16]{O}$ at a critical field, which
leads to jump-like increases of magnetization and proton current in this
nucleus, and evolution of the intrinsically deformed $\isotope[20]{Ne}$ nucleus
towards a more spherical shape under increasing field strength. Many of the
numerical features can be understood within a simple analytical model based on
the occupation by the nucleons of the lowest states of the harmonic oscillator
in a magnetic field.
</p>
{{{{ARTICLE_PARSER}}}}<p>We study a resistive tearing instability developing in a system evolving
through the combined effect of Hall drift in the Electron-MHD limit and Ohmic
dissipation. We explore first the exponential growth of the instability in the
linear case and we find the fastest growing mode, the corresponding eigenvalues
and dispersion relation. The instability growth rate scales as $\gamma \propto
B^{2/3} \sigma^{-1/3}$ where $B$ is the magnetic field and $\sigma$ the
electrical conductivity. We confirm the development of the tearing resistive
instability in the fully non-linear case, in a plane parallel configuration
where the magnetic field polarity reverses, through simulations of systems
initiating in Hall equilibrium with some superimposed perturbation. Following a
transient phase, during which there is some minor rearrangement of the magnetic
field, the perturbation grows exponentially. Once the instability is fully
developed the magnetic field forms the characteristic islands and X-type
reconnection points, where Ohmic decay is enhanced. We discuss the implications
of this instability for the local magnetic field evolution in neutron stars'
crusts, proposing that it can contribute to heating near the surface of the
star, as suggested by models of magnetar post-burst cooling. In particular, we
find that a current sheet a few meters thick, covering as little as $1\%$ of
the total surface can provide $10^{42}~$erg in thermal energy within a few
days. We briefly discuss applications of this instability in other systems
where the Hall effect operates such as protoplanetary discs and space plasmas.
</p>
{{{{ARTICLE_PARSER}}}}<p>(abridged). We outline LBCS (the LOFAR Long-Baseline Calibrator Survey),
whose aim is to identify sources suitable for calibrating the
highest-resolution observations made with the International LOFAR Telescope,
which include baselines &gt;1000 km. Suitable sources must contain significant
correlated flux density (50-100mJy) at frequencies around 110--190~MHz on
scales of a few hundred mas. At least for the 200--300-km international
baselines, we find around 1 suitable calibrator source per square degree over a
large part of the northern sky, in agreement with previous work. This should
allow a randomly selected target to be successfully phase calibrated on the
international baselines in over 50% of cases. Products of the survey include
calibrator source lists and fringe-rate and delay maps of wide areas --
typically a few degrees -- around each source. The density of sources with
significant correlated flux declines noticeably with baseline length over the
range 200--600~km, with good calibrators on the longest baselines appearing
only at the rate of 0.5 per square degree. Coherence times decrease from 1--3
minutes on 200-km baselines to about 1 minute on 600-km baselines, suggesting
that ionospheric phase variations contain components with scales of a few
hundred kilometres. The longest median coherence time, at just over 3 minutes,
is seen on the DE609 baseline, which at 227km is close to being the shortest.
We see median coherence times of between 80 and 110 seconds on the four longest
baselines (580--600~km), and about 2 minutes for the other baselines. The
success of phase transfer from calibrator to target is shown to be influenced
by distance, in a manner that suggests a coherence patch at 150-MHz of the
order of 1 degree.
</p>
{{{{ARTICLE_PARSER}}}}<p>The major source of noise in high-contrast imaging is the presence of slowly
evolving speckles that do not average with time. The temporal stability of the
point-spread-function (PSF) is therefore critical to reach a high contrast with
extreme adaptive optics (xAO) instruments. Understanding on which timescales
the PSF evolves and what are the critical parameters driving the speckle
variability allow to design an optimal observing strategy and data reduction
technique to calibrate instrumental aberrations and reveal faint astrophysical
sources. We have obtained a series of 52 min, AO-corrected, coronagraphically
occulted, high-cadence (1.6Hz), H-band images of the star HR 3484 with the
SPHERE (Spectro-Polarimeter High-contrast Exoplanet REsearch instrument on the
VLT. This is a unique data set from an xAO instrument to study its stability on
timescales as short as one second and as long as several tens of minutes. We
find different temporal regimes of decorrelation. We show that residuals from
the atmospheric turbulence induce a fast, partial decorrelation of the PSF over
a few seconds, before a transition to a regime with a linear decorrelation with
time, at a rate of several tens parts per million per second (ppm/s). We
analyze the spatial dependence of this decorrelation, within the well-corrected
radius of the adaptive optics system and show that the linear decorrelation is
faster at short separations. Last, we investigate the influence of the distance
to the meridian on the decorrelation.
</p>
{{{{ARTICLE_PARSER}}}}<p>We present nebular-phase imaging and spectroscopy for the hydrogen-poor
superluminous supernova SN 2015bn, at redshift z=0.1136, spanning +250-400 d
after maximum light. The light curve exhibits a steepening in the decline rate
from 1.4 mag/(100 d) to 1.7 mag/(100 d), suggestive of a significant decrease
in the opacity. This change is accompanied by a transition from a blue
continuum superposed with photospheric absorption lines to a nebular spectrum
dominated by emission lines of oxygen, calcium and magnesium. There are no
obvious signatures of circumstellar interaction or large nickel mass. We show
that the spectrum at +400 d is virtually identical to a number of energetic
Type Ic supernovae such as SN 1997dq, SN 2012au, and SN 1998bw, indicating
similar core conditions and strengthening the link between `hypernovae'/long
gamma-ray bursts and superluminous supernovae. A single explosion mechanism may
unify these events that span absolute magnitudes of -22 &lt; M_B &lt; -17. Both the
light curve and spectrum of SN 2015bn are consistent with an engine-driven
explosion ejecting 7-30 M$_\odot$ of oxygen-dominated ejecta (for reasonable
choices in temperature and opacity). A strong and relatively narrow O II
$\lambda$7774 line, seen in a number of these energetic events but not in
normal supernovae, may point to an inner shell that is the signature of a
central engine.
</p>
{{{{ARTICLE_PARSER}}}}<p>The X-ray source 1E 161348-5055 in the supernova remnant RCW 103 recently
exhibited X-ray activity typical of magnetars, i.e. neutron stars with magnetic
fields &gt; 10^14-10^15 G. However, 1E 161348-5055 has an observed period of 6.67
hr, in contrast to magnetars which have a spin period of seconds. Here we
describe a simple model which can explain the spin evolution of 1E 161348-5055,
as well as other magnetars, from an initial period of milliseconds that would
be required for dynamo generation of magnetar-strength magnetic fields. We
propose that the key difference between 1E 161348-5055 and other magnetars is
the persistence of a remnant disk of small total mass. This disk caused 1E
161348-5055 to undergo ejector and propeller phases in its life, during which
strong torques caused a rapid increase of its spin period. By matching its
observed spin period and ~1-3 kyr age, we find that 1E 161348-5055 has the
(slightly) highest magnetic field of all known magnetars, with B~5x10^15 G, and
that its disk had a mass of ~10^24 g, comparable to that of the asteroid Ceres.
</p>
{{{{ARTICLE_PARSER}}}}<p>Star formation on galactic scales is known to be a slow process, but whether
it is slow on smaller scales is uncertain. We cross-correlate 5469 giant
molecular clouds (GMCs) from a new all-sky catalog with 256 star forming
complexes (SFCs) to build a sample of 191 SFC-GMC complexes---collections of
multiple clouds each matched to 191 SFCs. The total mass in stars harbored by
these clouds is inferred from WMAP free-free fluxes. We measure the GMC mass,
the virial parameter, the star formation efficiency $\epsilon$ and the star
formation rate per free-fall time $\epsilon_{\rm ff}$. Both $\epsilon$ and
$\epsilon_{\rm ff}$ range over 3--4 orders of magnitude. We find that 68.3% of
the clouds fall within $\sigma_{\log\epsilon}=0.79\pm0.22\,{\rm dex}$ and
$\sigma_{\log\epsilon_{\rm ff}}=0.91\pm0.22\,{\rm dex}$ about the median.
Compared to these observed scatters, a simple model with a time independent
$\epsilon_{\rm ff}$ that depends on the host GMC properties predicts
$\sigma_{\log\epsilon_{\rm ff}}=$0.12-0.24. Allowing for a time-variable
$\epsilon_{\rm ff}$, we can recover the large dispersion in the rate of star
formation. This strongly suggests that star formation in the Milky Way is a
dynamic process on GMC scales. We also show that the surface star formation
rate profile of the Milky Way correlates well with the molecular gas surface
density profile.
</p>
{{{{ARTICLE_PARSER}}}}<p>An analysis of the kinematics of NGC 6720 is performed on the commissioning
data obtained with SITELLE, the Canada-France-Hawaii Telescope's new imaging
Fourier transform spectrometer. In order to measure carefully the small
broadening effect of a shell expansion on an unresolved emission line, we have
determined a computationally robust implementation of the convolution of a
Gaussian with a sinc instrumental line shape which avoids arithmetic overflows.
This model can be used to measure line broadening of typically a few km/s even
at low spectral resolution (R less than 5000). We have also designed the
corresponding set of Gaussian apodizing functions that are now used by ORBS,
the SITELLE's reduction pipeline. We have implemented this model in ORCS, a
fitting engine for SITELLE's data, and used it to derive the [SII] density map
of the central part of the nebula. The study of the broadening of the [NII]
lines shows that the Main Ring and the Central Lobe are two different shells
with different expansion velocities. We have also derived deep and spatially
resolved velocity maps of the Halo in [NII] and Halpha and found that the
brightest bubbles are originating from two bipolar structures with a velocity
difference of more than 35 km/s lying at the poles of a possibly unique Halo
shell expanding at a velocity of more than 15 km/s.
</p>
{{{{ARTICLE_PARSER}}}}<p>We investigate the physical properties of a purely kinetic k-essence model
with an equation of state motivated in superconducting membranes. We compute
the equation of state parameter $w$ and discuss its physical evolution via a
nonlinear equation of state. Using the adiabatic speed of sound and energy
density, we restrict the range of parameters of the model in order to have an
acceptable physical behavior. Furthermore, we analyze the evolution of the
luminosity distance $d_{L}$ with redshift $z$ by comparing (normalizing) it
with the $\Lambda$CDM model. Since the equation of state parameter is
$z$-dependent the evolution of the luminosity distance is also analyzed using
the Alcock-Paczy\'{n}ski test.
</p>
{{{{ARTICLE_PARSER}}}}<p>Aims: We investigate the evolution of protoplanetary discs (PPDs hereafter)
with magnetically driven disc winds and viscous heating. Methods: We consider
an initially massive disc with ~0.1 Msun to track the evolution from the early
stage of PPDs. We solve the time evolution of surface density and temperature
by taking into account viscous heating and the loss of the mass and the angular
momentum by the disc winds within the framework of a standard alpha model for
accretion discs. Our model parameters, turbulent viscosity, disc wind mass
loss, and disc wind torque, which are adopted from local magnetohydrodynamical
simulations and constrained by the global energetics of the gravitational
accretion, largely depends on the physical condition of PPDs, particularly on
the evolution of the vertical magnetic flux in weakly ionized PPDs. Results:
Although there are still uncertainties concerning the evolution of the vertical
magnetic flux remaining, surface densities show a large variety, depending on
the combination of these three parameters, some of which are very different
from the surface density expected from the standard accretion. When a PPD is in
a \"wind-driven accretion\" state with the preserved vertical magnetic field, the
radial dependence of the surface density can be positive in the inner region
&lt;1-10 au. The mass accretion rates are consistent with observations, even in
the very low level of magnetohydrodynamical turbulence. Such a positive radial
slope of the surface density gives a great impact on planet formation because
(i)it inhibits the inward drift or even results in the outward drift of
pebble/boulder-sized solid bodies, and (ii) it also makes the inward type-I
migration of proto-planets slower or even reversed. Conclusions: The variety of
our calculated PPDs should yield a wide variety of exoplanet systems.
</p>
{{{{ARTICLE_PARSER}}}}<p>We analyze the effect of gravitational back reaction on cosmic string loops
with kinks, which is an important determinant of the shape, and thus the
potential observability, of string loops which may exist in the universe today.
Kinks are not rounded off, but may be straightened out. In some loops,
symmetries prevent even this process, so that the loop evaporates in a
self-similar fashion and the kinks are unchanged. As an example, we give
results for the rectangular Garfinkle-Vachaspati loop.
</p>
{{{{ARTICLE_PARSER}}}}<p>Parametric instability is an intrinsic risk in high power laser
interferometer gravitational wave detectors, in which the optical cavity modes
interact with the acoustic modes of the mirrors leading to exponential growth
of the acoustic vibration. In this paper, we investigate the potential
parametric instability for a proposed next generation gravitational wave
detector based on cooled silicon test masses. It is shown that there would be
about 2 unstable modes per test mass, with the highest parametric gain of ~76.
The importance of developing suitable instability suppression schemes is
emphasized.
</p>
{{{{ARTICLE_PARSER}}}}<p>We conducted an analysis of the distribution of elements from lithium to
europium in 200 dwarfs in the solar neighbourhood ~20 pc with temperatures in
the range 4800-6200 K and metallicities [Fe/H] higher than -0.5 dex.
Determinations of atmospheric parameters and the chemical composition of the
dwarfs were taken from our previous studies. We found that the lithium
abundances in the planet-hosting solar-analog stars of our sample were lower
than those in the stars without planetary systems. Our results reveal no
significant differences exceeding the determination errors for the abundances
of investigated elements, except for aluminium and barium, which are more and
less abundant in the planet-hosting stars, respectively. We did not find
confident dependences of the lithium, aluminium and barium abundances on the
ages of our target stars (which is probable because of the small number of
stars). Furthermore, we found no correlation between the abundance differences
in [El/Fe] and the condensation temperature (Tcond) for stars in the 16 Cyg
binary system, unlike the case for 51 Peg (HD 217014), for which a slight
excess of volatile elements and a deficit of refractories were obtained
relative to those of solar twins. We found that one of the components of 16 Cyg
exhibits a slightly higher average abundance than its counterpart
(&lt;[El/H](A-B)&gt; = 0.08+/-0.02 dex); however, no significant abundance trend
versus Tcond was observed. Owing to the relatively large errors, we cannot
provide further constraints for this system.
</p>
{{{{ARTICLE_PARSER}}}}<p>Extragalactic radiosources have been classified in two classes,
Fanaroff-Riley I and II, which differ in morphology and radio power. Strongly
emitting sources belong to the edge brightened FR II class while the weak ones
to the edge darkened FR I class. The origin of this dichotomy is not yet fully
understood. Numerical simulations are successful in generating FR~II
morphologies but they fail to reproduce the diffuse structure of FR Is.
</p>
<p>By means of hydro-dynamical 3D simulations of supersonic jets, we investigate
how the displayed morphologies depend on the jet parameters. Bow shocks and
Mach disks at the jet's head, likely responsible for the presence of hot spots
in the FR II sources, disappear for a jet kinetic power less than 10^43 erg/s.
This threshold compares favorably with the luminosity at which the FR~I/FR~II
transition is observed.
</p>
<p>The problem is addressed by numerical means carrying out three-dimensional HD
simulations of supersonic jets that propagate in a non homogeneous medium with
the ambient temperature that increases with distance from the jet origin,
maintaining pressure constant.
</p>
<p>In the lower power sources, the jet energy, instead of being deposited at the
terminal shock, is gradually dissipated by the turbulence. The jets spreads out
while propagating, it smoothly decelerates while mixing with the ambient medium
and produces the plumes characteristic of FR I objects.
</p>
<p>Three-dimensionality is an essential ingredient to explore the FR I
evolution, because the properties of turbulence in two and three dimensions are
very different, since in two dimensions there is no energy cascade to small
scales and two-dimensional simulations with the same parameters, lead to FRII
like behavior.
</p>
{{{{ARTICLE_PARSER}}}}<p>We analyze interstellar absorption features in the full UV spectrum of the
nearby (d = 24 pc) B8 IVn star alpha Leo (Regulus) obtained at high resolution
and high S/N by the HST ASTRAL Treasury program. We derive column densities for
many key atomic species and interpret their partial ionizations. The gas in
front of alpha Leo exhibits two absorption components, one of which coincides
in velocity with the local interstellar cloud (LIC) that surrounds the Sun. The
second, smaller, component is shifted by +5.6 km/s relative to the main
component, in agreement with results for other lines of sight in this region of
the sky. The excitation of the C II fine-structure levels and the ratio of Mg I
to Mg II reveal a temperature T = 6500 (+750,-600)K and electron density n(e) =
0.11 (+0.025,-0.03) cm^-3. Our investigation of the ionization balance of all
the available species indicates that about 1/3 of the hydrogen atoms are
ionized and that metals are significantly depleted onto grains. We infer that
N(H I) = 1.9 (+0.9,-0.6) X 10^{18} cm^-2, which indicates that this partly
neutral gas occupies only 2 to 8 pc (about 13%) of the space toward the star,
with the remaining volume presumably being filled with a hot gas that emits
soft X-rays. We do not detect any absorption features from the highly ionized
species that could be produced in an interface between the warm medium and the
surrounding hot gas. Finally, the radial velocity of the LIC agrees with that
of the Local Leo Cold Cloud, indicating that they may be physically related.
</p>
{{{{ARTICLE_PARSER}}}}<p>We consider f(R,T) modified theory of gravity in which, in general, the
gravitational Lagrangian is given by an arbitrary function of the Ricci scalar
and the trace of the energy-momentum tensor. We indicate that in this type of
the theory, the coupling energy-momentum tensor is~not conserved. However, we
mainly focus on a particular model that matter is minimally coupled to the
geometry in the metric formalism and wherein, its coupling energy--momentum
tensor is also conserved. We obtain the corresponding Raychaudhuri dynamical
equation that presents the evolution of the kinematic quantities. Then for the
chosen model, we derive the behavior of the deceleration parameter, and show
that the coupling term can lead to an acceleration phase after the matter
dominated phase. On the other hand, the curvature of the universe corresponds
with the deviation from parallelism in the geodesic motion. Thus, we also
scrutinize the motion of the free test particles on their geodesics, and derive
the geodesic deviation equation in this modified theory to study the
accelerating universe within the spatially flat FLRW background. Actually, this
equation gives the relative accelerations of adjacent particles as a measurable
physical quantity, and provides an elegant tool to investigate the timelike and
the null structures of spacetime geometries. Then, through the null deviation
vector, we find the observer area-distance as a function of the redshift for
the chosen model, and compare the results with the corresponding results
obtained in the literature.
</p>
{{{{ARTICLE_PARSER}}}}<p>We consider f(R,T) modified theory of gravity, in which the gravitational
Lagrangian is given by an arbitrary function of the Ricci scalar and the trace
of the energy-momentum tensor of the matter, in order to investigate the dark
matter effects on the galaxy scale. We obtain the metric components for a
spherically symmetric and static spacetime in the vicinity of general
relativity solutions. However, we concentrate on a specific model of the theory
where the matter is minimally coupled to the geometry, and derive the metric
components in the galactic halo. Then, we fix the components by the rotational
velocities of galaxies for the model, and show that the mass corresponding to
the interaction term (which appears in the Einstein modified field equation)
leads to a flat rotation curve in the halo of galaxies. Also for the proposed
model, the light deflection angle has been derived, and then, been drawn while
using some observed data.
</p>
{{{{ARTICLE_PARSER}}}}<p>We consider the fact that noticing on the operational meaning of the physical
concepts played an impetus role in the appearance of general relativity (GR).
Thus, we have paid more attention to the operational definition of the
gravitational coupling constant in this theory as a dimensional constant which
is gained through an experiment. However, as all available experiments just
provide the value of this constant locally, this coupling constant can
operationally be meaningful only in a local area. Regarding this point, to
obtain an extension of GR for the large scale, we replace it by a conformal
invariant model and then, reduce this model to a theory for the cosmological
scale via breaking down the conformal symmetry through singling out a specific
conformal frame which is characterized by the large scale characteristics of
the universe. Finally, we come to the same field equations that historically
were proposed by Einstein for the cosmological scale (GR plus the cosmological
constant) as the result of his endeavor for making GR consistent with the Mach
principle. However, we declare that the obtained field equations in this
alternative approach do~not carry the problem of the field equations proposed
by Einstein for being consistent with Mach's principle (i.e., the existence of
de Sitter solution), and can also be considered compatible with this principle
in the Sciama view.
</p>
{{{{ARTICLE_PARSER}}}}<p>In principle, the strong-interaction sector of the Standard Model is
characterised by a unique renormalisation-group-invariant (RGI) running
interaction and a unique form for the dressed--gluon-quark vertex,
$\Gamma_\mu$; but, whilst much has been learnt about the former, the latter is
still obscure. In order to improve this situation, we use a RGI
running-interaction that reconciles both top-down and bottom-up analyses of the
gauge sector in quantum chromodynamics (QCD) to compute dressed-quark gap
equation solutions with 1,660,000 distinct Ansaetze for $\Gamma_\mu$. Each one
of the solutions is then tested for compatibility with three physical criteria
and, remarkably, we find that merely 0.55% of the solutions survive the test.
Plainly, therefore, even a small selection of observables places extremely
tight bounds on the domain of realistic vertex Ansaetze. This analysis and its
results should prove useful in constraining insightful contemporary studies of
QCD and hadronic phenomena.
</p>
{{{{ARTICLE_PARSER}}}}<p>We study the Bose-Einstein condensation of a finite size pion gas subject to
the influence of a magnetic field. We find the expressions for the critical
chemical potential and temperature for the onset of condensation. We show that
for values of the external magnetic flux larger than the elemental flux, the
critical temperature is larger than the one obtained by considering only finite
size effects. We use experimentally reported values of pion source sizes and
multiplicities at LHC energies to show that if the magnetic flux, produced
initially in peripheral heavy-ion collision, is at least partially preserved up
to the hadronic phase, the combined finite size and magnetic field effects give
rise to a critical temperature above the kinetic freeze-out temperature. We
discuss the implications for the evolution of the pion system created in
relativistic heavy-ion collisions.
</p>
{{{{ARTICLE_PARSER}}}}<p>A binary format with lists of particle state information, for interchanging
particles between various Monte Carlo simulation applications, is presented.
Portable C code for file manipulation is made available to the scientific
community, along with converters and plugins for several popular simulation
packages.
</p>
{{{{ARTICLE_PARSER}}}}<p>Experimental results on azimuthal correlations in high energy nuclear
collisions (nucleus-nucleus, proton-nucleus and proton-proton) seem to be well
described by viscous hydrodynamics. It is often argued that this agreement
implies either local thermal equilibrium or at least local isotropy. In this
note, I present arguments why this is not the case. Neither local
near-equilibrium nor near-isotropy are required in order for hydrodynamics to
offer a successful and accurate description of experimental results. However, I
predict the breakdown of hydrodynamics at momenta of order twenty times the
temperature, corresponding to a smallest possible QCD liquid drop size of 0.05
fm.
</p>
{{{{ARTICLE_PARSER}}}}<p>In ALICE, open heavy-flavour production is studied through the measurements
of the leptons (electrons and muons) from heavy-flavour hadron decays at
central and forward rapidity and via the reconstruction of D-meson hadronic
decays at mid-rapidity. An overview of the open heavy-flavour production with
ALICE in pp ($\sqrt{s}$ = 2.76 TeV and 7 TeV), p--Pb ($\sqrt {s_{\rm NN}}$ =
5.02 TeV) and Pb--Pb ($\sqrt {s_{\rm NN}}$ = 2.76 TeV) collisions will be
presented. We will discuss the production cross sections, modifications of the
transverse momentum distributions, azimuthal anisotropic emissions and
correlations with hadrons in comparison with various theoretical predictions.
</p>
{{{{ARTICLE_PARSER}}}}<p>We present the first measurements of long-range angular correlations and the
transverse momentum dependence of elliptic flow $v_2$ in high-multiplicity
$p$$+$Au collisions at $\sqrt{s_{_{NN}}}=200$ GeV. A comparison of these
results with previous measurements in high-multiplicity $d$$+$Au and $^3{\rm
He}$$+$Au collisions demonstrates a relation between $v_2$ and the initial
collision eccentricity $\varepsilon_2$, suggesting that the observed
momentum-space azimuthal anisotropies in these small systems have a collective
origin and reflect the initial geometry. Good agreement is observed between the
measured $v_2$ and hydrodynamic calculations for all systems, and an argument
disfavoring theoretical explanations based on momentum-space domain
correlations is presented. The set of measurements presented here allows us to
leverage the distinct intrinsic geometry of each of these systems to
distinguish between different theoretical descriptions of the long-range
correlations observed in small collision systems.
</p>
{{{{ARTICLE_PARSER}}}}<p>The beam energy dependence of correlation lengths (the Hanbury-Brown-Twiss
radii) is calculated by using a blast-wave model and the results are comparable
with those from RHIC-STAR beam energy scan data as well as the LHC-ALICE
measurements. A set of parameter for the blast-wave model as a function of beam
energy under study are obtained by fit to the HBT radii at each energy point.
The transverse momentum dependence of HBT radii is presented with the extracted
parameters for Au + Au collision at $\sqrt{s_{NN}} = $ 200 GeV and for Pb+Pb
collisions at 2.76 TeV. From our study one can learn that particle emission
duration can not be ignored while calculating the HBT radii with the same
parameters. And tuning kinetic freeze-out temperature in a range will result in
system lifetime changing in the reverse direction as it is found in RHIC-STAR
experiment measurements.
</p>
{{{{ARTICLE_PARSER}}}}<p>Extensions of nuclear physics to the strange sector are reviewed, covering
data and models of Lambda and other hypernuclei, multi-strange matter, and
anti-kaon bound states and condensation. Past achievements are highlighted,
present unresolved problems discussed, and future directions outlined.
</p>
{{{{ARTICLE_PARSER}}}}<p>In principle, the strong-interaction sector of the Standard Model is
characterised by a unique renormalisation-group-invariant (RGI) running
interaction and a unique form for the dressed--gluon-quark vertex,
$\Gamma_\mu$; but, whilst much has been learnt about the former, the latter is
still obscure. In order to improve this situation, we use a RGI
running-interaction that reconciles both top-down and bottom-up analyses of the
gauge sector in quantum chromodynamics (QCD) to compute dressed-quark gap
equation solutions with 1,660,000 distinct Ansaetze for $\Gamma_\mu$. Each one
of the solutions is then tested for compatibility with three physical criteria
and, remarkably, we find that merely 0.55% of the solutions survive the test.
Plainly, therefore, even a small selection of observables places extremely
tight bounds on the domain of realistic vertex Ansaetze. This analysis and its
results should prove useful in constraining insightful contemporary studies of
QCD and hadronic phenomena.
</p>
{{{{ARTICLE_PARSER}}}}<p>The relevance of chiral symmetry in baryons is highlighted in three examples
in the nucleon spectroscopy and structure. The first one is the importance of
chiral dynamics in understanding the Roper resonance. The second one is the
role of chiral symmetry in the lattice calculation of $\pi N \sigma$ term and
strangeness. The third one is the role of chiral $U(1)$ anomaly in the
anomalous Ward identity in evaluating the quark spin and the quark orbital
angular momentum. Finally, the chiral effective theory for baryons is
discussed.
</p>
{{{{ARTICLE_PARSER}}}}<p>We discuss the role of elastic and inelastic collisions and their interplay
in the thermalization of the quark-gluon plasma. We consider a simplified
situation of a static plasma, spatially uniform and isotropic in momentum
space. We focus on the small momentum region, which equilibrates first, and on
a short time scale. We obtain a simple kinetic equation that allows for an
analytic description of the most important regimes. The present analysis
suggests that the formation of a Bose condensate, expected when only elastic
collisions are present, is strongly hindered by the inelastic, radiative,
processes.
</p>
{{{{ARTICLE_PARSER}}}}<p>Collective behaviour has been observed in hadronic measurements of high
multiplicity proton+lead collisions at the Large Hadron Collider (LHC), as well
as in (proton, deuteron, helium-3)+gold collisions at the Relativistic
Heavy-Ion Collider (RHIC). To better understand the evolution dynamics and the
properties of the matter created in these small systems, a systematic study of
the soft hadronic observables together with electromagnetic radiation from
these collisions is performed, using a hydrodynamic framework. Quantitative
agreement is found between theoretical calculations and existing experimental
hadronic observables. The validity of the fluid dynamical description is
estimated by calculating Knudsen and inverse Reynolds numbers. Sizeable thermal
yields are predicted for low $p_T$ photons. Further predictions of higher order
charged hadron anisotropic flow coefficients and of thermal photon enhancement
are proposed.
</p>
{{{{ARTICLE_PARSER}}}}<p>We study the Bose-Einstein condensation of a finite size pion gas subject to
the influence of a magnetic field. We find the expressions for the critical
chemical potential and temperature for the onset of condensation. We show that
for values of the external magnetic flux larger than the elemental flux, the
critical temperature is larger than the one obtained by considering only finite
size effects. We use experimentally reported values of pion source sizes and
multiplicities at LHC energies to show that if the magnetic flux, produced
initially in peripheral heavy-ion collision, is at least partially preserved up
to the hadronic phase, the combined finite size and magnetic field effects give
rise to a critical temperature above the kinetic freeze-out temperature. We
discuss the implications for the evolution of the pion system created in
relativistic heavy-ion collisions.
</p>
{{{{ARTICLE_PARSER}}}}<p>In central Au-Au collisions at top RHIC energy, two particle correlation
measurements with identified hadron trigger have shown attenuation of near side
proton triggered jet-like yield at intermediate transverse momentum ($p{_T}$),
2$&lt; p{_T} &lt;$ 6 GeV/$\it{c}$. The attenuation has been attributed to the
anomalous baryon enhancement observed in the single inclusive measurements at
the same $p{_T}$ range. The enhancement has been found to be in agreement with
the models invoking coalescence of quarks as a mechanism of hadronization.
Baryon enhancement has also been observed at LHC in the single inclusive
spectra. We study the consequence of such an enhancement on two particle
correlations at LHC energy within the framework of A Multi Phase Transport
(AMPT) model that implements quark coalescence as a mode of hadronization. In
this paper we have calculated the proton over pion ratio and the near side per
trigger yield associated to pion and proton triggers at intermediate $p{_T}$
from String Melting (SM) version of AMPT. Results obtained are contrasted with
the AMPT Default (Def.) which does not include coalescence. Baryon enhancement
has been observed in AMPT SM at intermediate $p{_T}$. Near side jet-like
correlated yield associated to baryon (proton) trigger in the momentum region
where baryon generation is enhanced is found to be suppressed as compared to
the corresponding yields for the meson (pion) trigger in most central Pb-Pb
events. No such effect has been found in the Default version of AMPT.
</p>
{{{{ARTICLE_PARSER}}}}<p>This proceeding briefly summarizes our recent investigations on the
correlations of flow harmonics in 2.76A TeV Pb--Pb collisions with viscous
hydrodynamics {\tt VISH2+1}. We calculated both the symmetric cumulants
$SC^{v}(m, n)$ and the normalized symmetric cumulants $NSC^{v}(m, n)$, and
found $v_{2}$ and $v_{4}$, $v_{2}$ and $v_{5}$, $v_{3}$ and $v_{5}$ are
correlated, $v_{2}$ and $v_{3}$, $v_{3}$ and $v_{4}$ are anti-correlated. We
also found $NSC^{v}(3, 2)$ are insensitive to the QGP viscosity, which are
mainly determined by the initial conditions.
</p>
{{{{ARTICLE_PARSER}}}}<p>We have performed self-consistent Brueckner-Hartree-Fock (BHF) and its
renormalized theory to the structure calculations of finite nuclei. The
$G$-matrix is calculated within the BHF basis, and the exact Pauli exclusion
operator is determined by the BHF spectrum. Self-consistent occupation
probabilities are included in the renormalized Brueckner-Hartree-Fock (RBHF).
Various systematics and convergences are studies. Good results are obtained for
the ground-state energy and radius. RBHF can give a more reasonable
single-particle spectrum and radius. We present a first benchmark calculation
with other {\it ab initio} methods using the same effective Hamiltonian. We
find that the BHF and RBHF results are in good agreement with other $\it{ab}$
$\it{initio}$ methods.
</p>
{{{{ARTICLE_PARSER}}}}<p>We determine the equation of state (EOS) of nuclear matter with the inclusion
of hyperons in a self-consistent manner by using a Modified Quark Meson
Coupling Model (MQMC) where the confining interaction for quarks inside a
baryon is represented by a phenomenological average potential in an equally
mixed scalar-vector harmonic form. The hadron-hadron interaction in nuclear
matter is then realized by introducing additional quark couplings to $\sigma$,
$\omega$, and $\rho$ mesons through mean-field approximations. The effect of a
nonlinear $\omega$-$\rho$ term on the equation of state is studied. The hyperon
couplings are fixed from the optical potential values and the mass-radius curve
is determined satisfying the maximum mass constraint of $2$~M$_{\odot}$ for
neutron stars, as determined in recent measurements of the pulsar PSR
J0348+0432. We also observe that there is no significant advantage of
introducing the nonlinear $\omega$-$\rho$ term in the context of obtaining the
star mass constraint in the present set of parametrizations.
</p>
{{{{ARTICLE_PARSER}}}}<p>Excited states in neutron-rich nuclei located south-east of $^{132}$Sn are
investigated by shell-model calculations. A new shell-model Hamiltonian is
constructed for the present study. The proton-proton and neutron-neutron
interactions of the Hamiltonian are obtained through the existing CD-Bonn $G$
matrix results, while the proton-neutron interaction across two major shells is
derived from the monopole based universal interaction plus the M3Y spin-orbit
force. The present Hamiltonian can reproduce well the experimental data
available in this region, including one-neutron separation energies, level
energies and the experimental $B(E2)$ values of isomers in $^{134,136,138}$Sn,
$^{130}$Cd, and $^{128}$Pd. New isomers are predicted in this region, $e.g.$ in
$^{135}$Sn, $^{131}$Cd, $^{129}$Pd, $^{132,134}$In and $^{130}$Ag, in which
almost no excited states are known experimentally yet. In the odd-odd
$^{132,134}$In and $^{130}$Ag, the predicted very long $E2$ life-times of the
low-lying $5^{-}$ states are discussed, demanding more information on the
related proton-neutron interaction. The low-lying states of $^{132}$In are
discussed in connection with the recently observed $\gamma$ rays. The predicted
$19/2^{-}$ isomer in $^{129}$Pd could decay by both electromagnetic transitions
and neutron emission with comparable partial life-times, making it a good
candidate for neutron radioactivity, a decay mode which is yet to be
discovered.
</p>
{{{{ARTICLE_PARSER}}}}<p>We study the strange vector meson ($K^*, \bar K^*$) dynamics in relativistic
heavy-ion collisions based on the microscopic Parton-Hadron-String Dynamics
(PHSD) transport approach which incorporates partonic and hadronic
degrees-of-freedom, a phase transition from hadronic to partonic matter -
Quark-Gluon-Plasma (QGP) - and a dynamical hadronization of quarks and
antiquarks as well as final hadronic interactions. We investigate the role of
in-medium effects on the $K^*, \bar K^*$ meson dynamics by employing
Breit-Wigner spectral functions for the $K^*$'s with self-energies obtained
from a self-consistent coupled-channel G-matrix approach. Furthermore, we
confront the PHSD calculations with experimental data for p+p, Cu+Cu and Au+Au
collisions at energies up to $\sqrt{{s}_{NN}} = 200$~GeV. Our analysis shows
that at relativistic energies most of the final $K^*$s (observed
experimentally) are produced during the late hadronic phase, dominantly by the
$K+ \pi \to K^*$ channel, such that the fraction of the $K^*$s from the QGP is
small and can hardly be reconstructed from the final observables. The influence
of the in-medium effects on the $K^*$ dynamics at RHIC energies is rather
modest due to their dominant production at low baryon densities (but high meson
densities), however, it increases with decreasing beam energy. Moreover, we
find that the additional cut on the invariant mass region of the $K^*$ further
influences the shape and the height of the final spectra. This imposes severe
constraints on the interpretation of the experimental results.
</p>
{{{{ARTICLE_PARSER}}}}<p>We propose a new geometrical model of matter, in which neutral atoms are
modelled by compact, complex algebraic surfaces. Proton and neutron numbers are
determined by a surface's Chern numbers. Equivalently, they are determined by
combinations of the Hodge numbers, or the Betti numbers. Geometrical
constraints on algebraic surfaces allow just a finite range of neutron numbers
for a given proton number. This range encompasses the known isotopes.
</p>
{{{{ARTICLE_PARSER}}}}<p>Experimental results on azimuthal correlations in high energy nuclear
collisions (nucleus-nucleus, proton-nucleus and proton-proton) seem to be well
described by viscous hydrodynamics. It is often argued that this agreement
implies either local thermal equilibrium or at least local isotropy. In this
note, I present arguments why this is not the case. Neither local
near-equilibrium nor near-isotropy are required in order for hydrodynamics to
offer a successful and accurate description of experimental results. However, I
predict the breakdown of hydrodynamics at momenta of order twenty times the
temperature, corresponding to a smallest possible QCD liquid drop size of 0.05
fm.
</p>
{{{{ARTICLE_PARSER}}}}<p>The beam energy dependence of correlation lengths (the Hanbury-Brown-Twiss
radii) is calculated by using a blast-wave model and the results are comparable
with those from RHIC-STAR beam energy scan data as well as the LHC-ALICE
measurements. A set of parameter for the blast-wave model as a function of beam
energy under study are obtained by fit to the HBT radii at each energy point.
The transverse momentum dependence of HBT radii is presented with the extracted
parameters for Au + Au collision at $\sqrt{s_{NN}} = $ 200 GeV and for Pb+Pb
collisions at 2.76 TeV. From our study one can learn that particle emission
duration can not be ignored while calculating the HBT radii with the same
parameters. And tuning kinetic freeze-out temperature in a range will result in
system lifetime changing in the reverse direction as it is found in RHIC-STAR
experiment measurements.
</p>
{{{{ARTICLE_PARSER}}}}<p>Extensions of nuclear physics to the strange sector are reviewed, covering
data and models of Lambda and other hypernuclei, multi-strange matter, and
anti-kaon bound states and condensation. Past achievements are highlighted,
present unresolved problems discussed, and future directions outlined.
</p>
{{{{ARTICLE_PARSER}}}}<p>The properties of $\isotope[12]{C}$, $\isotope[16]{O}$, and
$\isotope[20]{Ne}$ nuclei in strong magnetic fields $B\simeq 10^{17}\,$G are
studied in the context of strongly magnetized neutron stars and white dwarfs.
The SKY3D code is extended to incorporate the interaction of nucleons with the
magnetic field and is utilized to solve the time-independent Hartree-Fock
equations with a Skyrme interaction on a Cartesian three-dimensional grid. The
numerical solutions demonstrate a number of phenomena, which include a
splitting of the energy levels of spin-up and -down nucleons, spontaneous
rearrangment of energy levels in $\isotope[16]{O}$ at a critical field, which
leads to jump-like increases of magnetization and proton current in this
nucleus, and evolution of the intrinsically deformed $\isotope[20]{Ne}$ nucleus
towards a more spherical shape under increasing field strength. Many of the
numerical features can be understood within a simple analytical model based on
the occupation by the nucleons of the lowest states of the harmonic oscillator
in a magnetic field.
</p>
{{{{ARTICLE_PARSER}}}}<p>In certain circumstances, chiral (parity-violating) medium can be described
hydrodynamically as a chiral fluid with microscopic quantum anomalies. Possible
examples of such systems include strongly coupled quark-gluon plasma, liquid
helium 3He-A, neutron stars and the Early Universe. We study first-order
hydrodynamics of a chiral fluid on a vortex background and in an external
magnetic field. We show that there are two previously undiscovered modes
describing heat waves propagating along the vortex and magnetic field. We call
them the Thermal Chiral Vortical Wave and Thermal Chiral Magnetic Wave. We also
identify known gapless excitations of density (chiral vortical and chiral
magnetic waves) and transverse velocity (chiral Alfven wave). We demonstrate
that the velocity of the chiral vortical wave is zero, when the full
hydrodynamic framework is applied, and hence the wave is absent and the
excitation reduces to the charge diffusion mode. We also comment on the
frame-dependent contributions to the obtained propagation velocities.
</p>
{{{{ARTICLE_PARSER}}}}<p>QCD sum rules for decay constants of heavy mesons with $u$ or $d$ quark yield
for $B$ mesons much less isospin breaking than lattice QCD but good agreement
for $D$ mesons.
</p>
{{{{ARTICLE_PARSER}}}}<p>Actual solutions of the Bethe-Salpeter equation for a two-fermion bound
system are becoming available directly in Minkowski space, by virtue of a novel
technique, based on the so-called Nakanishi integral representation of the
Bethe-Salpeter amplitude and improved by expressing the relevant momenta
through light-front components, i.e. $k^\pm=k^0 \pm k^3$. We solve a crucial
problem that widens the applicability of the method to real situations by
providing an analytically exact treatment of the singularities plaguing the
two-fermion problem in Minkowski space, irrespective of the complexity of the
irreducible Bethe-Salpeter kernel. This paves the way for feasible numerical
investigations of relativistic composite systems, with any spin degrees of
freedom. We present a thorough comparison with existing numerical results,
evaluated in both Minkowski and Euclidean space, fully corroborating our
analytical treatment, as well as fresh light-front amplitudes illustrating the
potentiality of non perturbative calculations performed directly in Minkowski
space.
</p>
{{{{ARTICLE_PARSER}}}}<p>Tensor network states, and in particular projected entangled pair states,
play an important role in the description of strongly correlated quantum
lattice systems. They do not only serve as variational states in numerical
simulation methods, but also provide a framework for classifying phases of
quantum matter and capture notions of topological order in a stringent and
rigorous language. The rapid development in this field for spin models and
bosonic systems has not yet been mirrored by an analogous development for
fermionic models. In this work, we introduce a framework of tensor networks
having a fermionic component capable of capturing notions of topological order.
At the heart of the formalism are axioms of fermionic matrix product operator
injectivity, stable under concatenation. Building upon that, we formulate a
Grassmann number tensor network ansatz for the ground state of fermionic
twisted quantum double models. A specific focus is put on the paradigmatic
example of the fermionic toric code. This work shows that the program of
describing topologically ordered systems using tensor networks carries over to
fermionic models.
</p>
{{{{ARTICLE_PARSER}}}}<p>These notes give an introduction to the Strominger system of partial
differential equations, and are based on lectures given in September 2015 at
the GEOQUANT School, held at the Institute of Mathematical Sciences (ICMAT) in
Madrid. We describe the links with the theory of balanced metrics in hermitian
geometry, the Hermite-Yang-Mills equations, and its origins in physics, that we
illustrate with many examples. We also cover some recent developments in the
moduli problem and the interrelation of the Strominger system with generalized
geometry, via the cohomological notion of string class.
</p>
{{{{ARTICLE_PARSER}}}}<p>We consider the Schr\\"odinger equation with a time-independent weakly random
potential of a strength $\epsilon\ll 1$, with Gaussian statistics. We prove
that when the initial condition varies on a scale much larger than the
correlation length of the potential, the compensated wave function converges to
a deterministic limit on the time scale $t\sim\epsilon^{-2}$. This is shown
under the sharp assumption that the correlation function $R(x)$ of the random
potential decays slower than $1/|x|^2$, which ensures that the effective
potential is finite. When $R(x)$ decays slower than $1/|x|^2$ we establish an
anomalous diffusive behavior for the averaged wave function on a time scale
shorter than $\epsilon^{-2}$, as long as the initial condition is \"sufficiently
macroscopic\". We also consider the kinetic regime when the initial condition
varies on the same scale as the random potential and obtain the limit of the
averaged wave function for potentials with the correlation functions decaying
faster than $1/|x|^2$. We use random potentials of the Schonberg class which
allows us to bypass the oscillatory phase estimates.
</p>
{{{{ARTICLE_PARSER}}}}<p>It is shown that the unstable evolutions of the Hermite-Gauss-type stationary
solutions for the nonlocal nonlinear Schrodinger equation with the
exponential-decay response function can evolve into chaotic states. This new
kind of entities are referred to as chaoticons because they exhibit not only
chaotic properties (with positive Lyapunov exponents and spatial decoherence)
but also soliton-like properties (with invariant statistic width and
interaction of quasi-elastic collisions).
</p>
{{{{ARTICLE_PARSER}}}}<p>We prove a time scales version of the Noether's theorem relating group of
symmetries and conservation laws. Our result extends the continuous version of
the Noether's theorem as well as the discrete one and corrects a previous
statement of Bartosiewicz and Torres in \cite{BT}.
</p>
{{{{ARTICLE_PARSER}}}}<p>The Coleman-Mandula (CM) theorem states that the Poincar\'e and internal
symmetries of a Minkowski spacetime quantum field theory cannot combine
nontrivially in an extended symmetry group. We establish an analogous result
for quantum field theory in curved spacetimes, assuming local covariance, the
timeslice property, a local dynamical form of Lorentz invariance, and
additivity. Unlike the CM theorem, our result is valid in dimensions $n\ge 2$
and for free or interacting theories. It is formulated for theories defined on
a category of all globally hyperbolic spacetimes equipped with a global
coframe, on which the restricted Lorentz group acts, and makes use of a general
analysis of symmetries induced by the action of a group $G$ on the category of
spacetimes. Such symmetries are shown to be canonically associated with a
cohomology class in the second degree nonabelian cohomology of $G$ with
coefficients in the global gauge group of the theory. Our main result proves
that the cohomology class is trivial if $G$ is the universal cover $\cal S$ of
the restricted Lorentz group. Among other consequences, it follows that the
extended symmetry group is a direct product of the global gauge group and $\cal
S$, all fields transform in multiplets of $\cal S$, fields of different spin do
not mix under the extended group, and the occurrence of noninteger spin is
controlled by the centre of the global gauge group. The general analysis is
also applied to rigid scale covariance.
</p>
{{{{ARTICLE_PARSER}}}}<p>We investigate meandric systems with large number of connected components
using tools inspired by free probability. For any fixed integer $r$, we express
the generating function of meandric systems on $2n$ points with $n-r$ connected
components in terms of a finite (the size depends on $r$) subclass of
irreducible meanders, via the moment-cumulant formula from free probability
theory. We show that the generating function, after an appropriate change of
variable, is a rational function, and we bound its degree. Exact expressions
for the generating functions are obtained for $r \leq 6$, as well as the
asymptotic behavior of the meandric numbers for general $r$.
</p>
{{{{ARTICLE_PARSER}}}}<p>We formulate a theorem for the general profile of the Hausdorff and the
spectral dimension of multiscale geometries, assuming a smooth and slow change
of spacetime dimensionality at large scales. Agreement with various scenarios
of quantum gravity is found. In particular, we derive uniquely the multiscale
measure with log oscillations of theories of multifractional geometry.
Predictivity of this class of models and falsifiability of their abundant
phenomenology are thus established.
</p>
{{{{ARTICLE_PARSER}}}}<p>The Pfaffian structure of the boundary monomer correlation functions in the
dimer-covering planar graph models is rederived through a combinatorial /
topological argument. These functions are then extended into a larger family of
order-disorder correlation functions which are shown to exhibit Pfaffian
structure throughout the bulk. Key tools involve combinatorial switching
symmetries which are identified through the loop-gas representation of the
double dimer model, and topological implications of planarity.
</p>
{{{{ARTICLE_PARSER}}}}<p>The defect of a complex Hadamard matrix $H$ is an upper bound for the
dimension of a continuous Hadamard orbit stemming from $H$. We provide a new
interpretation of the defect as the dimension of the center subspace of a
gradient flow and apply the Center Manifold Theorem of dynamical systems theory
to study local structure in spaces of complex Hadamard matrices. Through
examples, we provide several applications of our methodology including the
construction of affine families of Hadamard matrices.
</p>
{{{{ARTICLE_PARSER}}}}<p>Inequalities for the eigenvalues of the (negative) Laplacian subject to mixed
boundary conditions on polyhedral and more general bounded domains are
established. The eigenvalues subject to a Dirichlet boundary condition on a
part of the boundary and a Neumann boundary condition on the remainder of the
boundary are estimated in terms of either Dirichlet or Neumann eigenvalues. The
results complement several classical inequalities between Dirichlet and Neumann
eigenvalues due to P\'{o}lya, Payne, Levine and Weinberger, Friedlander, and
others.
</p>
{{{{ARTICLE_PARSER}}}}<p>We construct three-dimensional families of small-amplitude gravity-driven
rotational steady water waves on finite depth. The solutions contain
counter-currents and multiple crests in each minimal period. Each such wave
generically is a combination of three different Fourier modes, giving rise to a
rich and complex variety of wave patterns. The bifurcation argument is based on
a blow-up technique, taking advantage of three parameters associated with the
vorticity distribution, the strength of the background stream, and the period
of the wave.
</p>
{{{{ARTICLE_PARSER}}}}<p>It is well known that the water-wave problem with weak surface tension has
small-amplitude line solitary-wave solutions which to leading order are
described by the nonlinear Schr\\"odinger equation. The present paper contains
an existence theory for three-dimensional periodically modulated solitary-wave
solutions which have a solitary-wave profile in the direction of propagation
and are periodic in the transverse direction; they emanate from the line
solitary waves in a dimension-breaking bifurcation. In addition, it is shown
that the line solitary waves are linearly unstable to long-wavelength
transverse perturbations. The key to these results is a formulation of the
water wave problem as an evolutionary system in which the transverse horizontal
variable plays the role of time, a careful study of the purely imaginary
spectrum of the operator obtained by linearising the evolutionary system at a
line solitary wave, and an application of an infinite-dimensional version of
the classical Lyapunov centre theorem.
</p>
{{{{ARTICLE_PARSER}}}}<p>We propose a background-independent formulation of cosmic inflation. The
inflation in this picture corresponds to a dynamical process to generate space
and time while the conventional inflation is simply an (exponential) expansion
of a preexisting spacetime owing to the vacuum energy carried by an inflaton
field. We observe that the cosmic inflation is triggered by the condensate of
Planck energy into vacuum responsible for the generation of spacetime and must
be a single event according to the exclusion principle of noncommutative
spacetime caused by the Planck energy condensate in vacuum. The emergent
spacetime picture admits a background-independent formulation so that the
inflation can be described by a conformal Hamiltonian system characterized by
an exponential phase space expansion without introducing any inflaton field as
well as an {\it ad hoc} inflation potential. This implies that the emergent
spacetime may incapacitate all the rationales to introduce the multiverse
hypothesis. In Part I we will focus on the physical foundation of cosmic
inflation from the emergent spacetime picture to highlight the main idea. Its
mathematical exposition will be addressed in Part II.
</p>
{{{{ARTICLE_PARSER}}}}<p>We consider the elliptic-elliptic, focussing Davey-Stewartson equations,
which have an explicit bright line soliton solution. The existence of a family
of periodic solitons, which have the profile of the line soliton in the
longitudinal spatial direction and are periodic in the transverse spatial
direction, is established using dynamical systems arguments. We also show that
the line soliton is linearly unstable with respect to perturbations in the
transverse direction.
</p>
{{{{ARTICLE_PARSER}}}}<p>The fundamental singularity theorem of FLRW cosmologies assumes that the
matter content in the cosmological model obeys the strong energy condition
along with a nonpositive cosmological constant which gives rise to an
irrotational geodesic singularity. In this paper, we show that the important
case of a spatially flat Friedmann-Lema\^{i}tre-Robertson-Walker universe with
barotropic matter obeying only the \emph{weak} energy condition with a
nonnegative cosmological constant also contains a past singularity. We
accomplish this using topological methods from dynamical systems theory. The
methods employed in this paper are sufficiently general that they could be
extended to other models to study the existence of past singularities.
</p>
{{{{ARTICLE_PARSER}}}}<p>We present a new algorithm to construct a purely four dimensional
representation of higher-order perturbative corrections to physical
cross-sections at next-to-leading order (NLO). The algorithm is based on the
loop-tree duality (LTD), and it is implemented by introducing a suitable
mapping between the external and loop momenta of the virtual scattering
amplitudes, and the external momenta of the real emission corrections. In this
way, the sum over degenerate infrared states is performed at integrand level
and the cancellation of infrared divergences occurs locally without introducing
subtraction counter-terms to deal with soft and final-state collinear
singularities. The dual representation of ultraviolet counter-terms is also
discussed in detail, in particular for self-energy contributions. The method is
first illustrated with the scalar three-point function, before proceeding with
the calculation of the physical cross-section for $\gamma^* \to q \bar{q}(g)$,
and its generalisation to multi-leg processes. The extension to
next-to-next-to-leading order (NNLO) is briefly commented.
</p>
{{{{ARTICLE_PARSER}}}}<p>A systematic method to derive the shallow water equations using the
conservation for energy and potential enstrophy is presented. The equations are
constructed using exterior differential forms and self-adjoint operators and
result in the sum of two Nambu brackets, one for the vortical flow and one for
the wave-mean flow interaction, and a Poisson bracket representing the
interaction between divergence and geostrophic imbalance. Different mechanisms,
such as vortical flows and emission of gravity waves, emerge from different
conservation laws (CLs) for total energy and potential enstrophy. The advantage
of this approach is the direct derivation of the Hamiltonian and Nambu forms.
The approach demonstrates that two CLs with three dynamical variables are
sufficient to setup the shallow water model.
</p>
{{{{ARTICLE_PARSER}}}}<p>The fermionic signature operator is constructed in Rindler space-time. It is
shown to be an unbounded self-adjoint operator on the Hilbert space of
solutions of the massive Dirac equation. In two-dimensional Rindler space-time,
we prove that the resulting fermionic projector state coincides with the
Fulling-Rindler vacuum. Moreover, the fermionic signature operator gives a
covariant construction of general thermal states, in particular of the Unruh
state. The fermionic signature operator is shown to be well-defined in
asymptotically Rindler space-times. In four-dimensional Rindler space-time, our
construction gives rise to new quantum states.
</p>
{{{{ARTICLE_PARSER}}}}<p>The high degree of symmetry renders the dynamics of cosmological as well as
some black hole spacetimes describable by a system of finite degrees of
freedom. These systems are generally known as minisuperspace models. One of
their important key features is the invariance of the corresponding reduced
actions under reparametrizations of the independent variable, a fact that can
be seen as the remnant of the general covariance of the full theory. In the
case of a system of $n$ degrees of freedom, described by a Lagrangian quadratic
in velocities, one can use the lapse by either gauge fixing it or letting it be
defined by the constraint and subsequently substitute into the rest of the
equations. In the first case, the system is solvable for $n$ accelerations and
the constraint becomes a restriction among constants. In the second case, the
system can only be solved for $n-1$ accelerations and the \"gauge\" freedom is
transferred to the choice of one of the scalar degrees of freedom. In this
paper, we take the second path and express all $n-1$ scalar degrees of freedom
in terms of the remaining one, say $q$. By considering these $n-1$ degrees of
freedom as arbitrary but given functions of $q$, we manage to extract a two
dimensional pure gauge system consisting of the lapse $N$ and the arbitrary
$q$: in a way, we decouple the reparametrization invariance from the rest of
the equations of motion. The solution of the corresponding quantum two
dimensional system is used for the definition of a generalized probability for
every configuration $f^i (q)$, be it classical or not. The main result is that,
interestingly enough, this probability attains its extrema on the classical
solution of the initial $n$-dimensional system.
</p>
{{{{ARTICLE_PARSER}}}}<p>A remarkable feature of Schur functions -- the common eigenfunctions of
cut-and-join operators from $W_\infty$ -- is that they factorize at the
peculiar two-parametric topological locus in the space of time-variables, what
is known as the hook formula for quantum dimensions of representations of
$U_q(SL_N)$ and plays a big role in various applications. This factorization
survives at the level of Macdonald polynomials. We look for its further
generalization to {\it generalized} Macdonald polynomials (GMP), associated in
the same way with the toroidal Ding-Iohara-Miki algebras, which play the
central role in modern studies in Seiberg-Witten-Nekrasov theory. In the
simplest case of the first-coproduct eigenfunctions, where GMP depend on just
two sets of time-variables, we discover a weak factorization -- on a
codimension-one slice of the topological locus, what is already a very
non-trivial property, calling for proof and better understanding.
</p>
{{{{ARTICLE_PARSER}}}}<p>We derive the full $\mathrm{U}(\infty)$-Ward-Takahashi Identities for random
colored tensor models. The strategy is to expand the free energy in boundary
graphs determined by the combinatorics of the sources. This is carried out for
arbitrary interactions of any rank $D$, with subsequent focus on
$\varphi^4$-theories, and organizes the correlation functions of generic
colored tensor models. We also prove that the boundary sector of melonic
quartic interactions is enough to generate all $D$-colored graphs. For the
rank-$3$ $\varphi^4$-theory we derive the exact integral-like equation for the
2-point function. Our results hold for some Group Field Theories as well.
Altogether, our non-perturbative approach trades graph theory for analytical
methods.
</p>
{{{{ARTICLE_PARSER}}}}<p>Tensor network states, and in particular projected entangled pair states,
play an important role in the description of strongly correlated quantum
lattice systems. They do not only serve as variational states in numerical
simulation methods, but also provide a framework for classifying phases of
quantum matter and capture notions of topological order in a stringent and
rigorous language. The rapid development in this field for spin models and
bosonic systems has not yet been mirrored by an analogous development for
fermionic models. In this work, we introduce a framework of tensor networks
having a fermionic component capable of capturing notions of topological order.
At the heart of the formalism are axioms of fermionic matrix product operator
injectivity, stable under concatenation. Building upon that, we formulate a
Grassmann number tensor network ansatz for the ground state of fermionic
twisted quantum double models. A specific focus is put on the paradigmatic
example of the fermionic toric code. This work shows that the program of
describing topologically ordered systems using tensor networks carries over to
fermionic models.
</p>
{{{{ARTICLE_PARSER}}}}<p>Wave functions are reproducible only when they represent long-lived
eigenstates in a bound system, or when a well-controlled preparation procedure
is available. If we admit that otherwise their precision is limited, we find
that the classical and the quantum mechanical description of macroscopic
systems can converge, with both of them including particle localization and
stochastic effects. This argument is developped using a finite-temperature gas
confined in a box as an example.
</p>
{{{{ARTICLE_PARSER}}}}<p>One of the most critical tasks at the very beginning of a quantum chemical
investigation is the choice of either a multi- or single-configurational
method. Naturally, many proposals exist to define a suitable diagnostic of the
multi-configurational character for various types of wave functions in order to
assist this crucial decision. Here, we present a new orbital-entanglement based
multi-configurational diagnostic termed $Z_{s(1)}$. The correspondence of
orbital entanglement and static (or nondynamic) electron correlation permits
the definition of such a diagnostic. We chose our diagnostic to meet important
requirements such as well-defined limits for pure single-configurational and
multi-configurational wave functions. The $Z_{s(1)}$ diagnostic can be
evaluated from a partially converged, but qualitatively correct, and therefore
inexpensive density matrix renormalization group wave function as in our
recently presented automated active orbital selection protocol. Its robustness
and the fact that it can be evaluated at low cost make this diagnostic a
practical tool for routine applications.
</p>
{{{{ARTICLE_PARSER}}}}<p>Measurement-device-independent quantum key distribution (MDI-QKD) is immune
to all security loopholes on detection. Previous experiments on MDI-QKD
required spatially separated signal lasers and complicated stabilization
systems. In this paper, we perform a proof-of-principle experimental
demonstration of plug-and-play MDI-QKD over an asymmetric channel setting with
a single signal laser, in which the whole system is automatically stabilized in
spectrum, polarization, arrival time and phase reference. Both the signal laser
and the single-photon detectors are in the possession of a common server. A
passive timing calibration technique is applied to ensure the precise and
stable overlap of signal pulses. The results pave the way for the realization
of a quantum network, in which the users only need the encoding devices.
</p>
{{{{ARTICLE_PARSER}}}}<p>Decoy state method could effectively enhance the performance of quantum key
distribution (QKD) with practical phase randomized weak coherent source.
Although active modulation of the source intensity is effective and has been
implemented in many experiments, passive preparation of decoy states is also an
important addition to the family of decoy state QKD protocols. In this paper,
following the theory of Curty \emph{et al.} [PRA, 81, 022310 (2010)], we
experimentally demonstrate the phase-encoding passive-decoy-state QKD with only
linear optical setups and threshold single photon detectors. In our experiment,
two homemade independent pulsed lasers, with visibility of Hong-Ou-Mandel
interference $0.53(\pm 0.003)$, have been implemented and used to passively
generate the different decoy states. Finally, secret key rate $1.5\times
10^{-5}$/pulse is obtained with 10km commercial fiber between Alice and Bob.
</p>
{{{{ARTICLE_PARSER}}}}<p>The quantum formalism can be completed by assuming that a density operator
can also represent a pure state. An 'extended Bloch representation' (EBR) then
results, in which not only states, but also the measurement-interactions can be
represented. The Born rule is obtained as an expression of the subjective lack
of knowledge about the measurement-interaction that is each time actualized.
Entanglement can also be consistently described in the EBR, as it remains
compatible with the principle according to which a composite entity exists only
if its components also exist, and therefore are in pure states.
</p>
{{{{ARTICLE_PARSER}}}}<p>We study mutually unbiased maximally entangled bases (MUMEB's) in bipartite
system $\mathbb{C}^d\otimes\mathbb{C}^d (d \geq 3)$. We generalize the method
to construct MUMEB's given in [16], by using any commutative ring $R$ with $d$
elements and generic character of $(R,+)$ instead of
$\mathbb{Z}_d=\mathbb{Z}/d\mathbb{Z}$. Particularly, if
$d=p_1^{a_1}p_2^{a_2}\ldots p_s^{a_s}$ where $p_1, \ldots, p_s$ are distinct
primes and $3\leq p_1^{a_1}\leq\cdots\leq p_s^{a_s}$, we present $p_1^{a_1}-1$
MUMEB's in $\mathbb{C}^d\otimes\mathbb{C}^d$ by taking
$R=\mathbb{F}_{p_1^{a_1}}\oplus\cdots\oplus\mathbb{F}_{p_s^{a_s}}$, direct sum
of finite fields (Theorem 3.3).
</p>
{{{{ARTICLE_PARSER}}}}<p>We demonstrate that important information about linear optical circuits can
be obtained through the phase shift induced by integrated optical resonators.
As a proof of principle, the phase of an unbalanced Mach-Zehnder interferometer
is determined. Then the method is applied to a complex optical circuit designed
for linear optical quantum computation. In this controlled-NOT gate with qubit
initialization and tomography stages, the relative phases are determined as
well as the coupling ratios of its directional couplers.
</p>
{{{{ARTICLE_PARSER}}}}<p>We present a random number generation scheme based on measuring the phase
fluctuations of a laser with a simple and compact experimental setup. A simple
model is established to analyze the randomness and the simulation result based
on this model fits well with the experiment data. After the analog to digital
sampling and suitable randomness extraction integrated in the field
programmable gate array, the final random bits are delivered to a PC, realizing
a 5.4 Gbps real time quantum random number generation. The final random bit
sequences have passed all the NIST and DIEHARD tests.
</p>
{{{{ARTICLE_PARSER}}}}<p>We present a state-interaction approach for matrix product state (MPS) wave
functions in a nonorthogonal molecular orbital basis. Our approach allows us to
calculate for example transition and spin-orbit coupling matrix elements
between arbitrary electronic states provided that they share the same
one-electron basis functions and active orbital space, respectively. The key
element is the transformation of the MPS wave functions of different states
from a nonorthogonal to a biorthonormal molecular orbital basis representation
exploiting a sequence of non-unitary transformations following a proposal by
Malmqvist (Int. J. Quantum Chem. 30, 479 (1986)). This is well-known for
traditional wave-function parametrizations but has not yet been exploited for
MPS wave functions.
</p>
{{{{ARTICLE_PARSER}}}}<p>It is well known that the energy flows from the hot (gain) system to the cold
(loss) one when they are coupled to each other. We present a counterintuitive
theory for the ground-state cooling of the mechanical resonator in
optomechanics via a gain cavity. Here, the energy flows first from the
mechanical resonator to the loss cavity, then to the gain cavity, and finally
localizes there. The energy localization in the gain cavity dramatically
enhances the cooling rate of the mechanical resonator. Moreover, we show that
unconventional optical spring effect, e.g., giant frequency shift and optically
induced damping of the mechanical resonator, can be realized. Those feature a
pre-cooling free ground-state cooling, i.e., the mechanical resonator can
directly be cooled to the ground state from the room temperature.
</p>
{{{{ARTICLE_PARSER}}}}<p>We demonstrate how quantum interference may lead to the appearance of robust
edge-like states of a single ultracold atom in a two-dimensional optical
ribbon. We show that these states can be engineered either within the manifold
of local ground states of the sites forming the ribbon, or of states carrying
one unit of angular momentum. In the former case, we show that the
implementation of edge-like states can be extended to other geometries, such as
tilted square lattices. In the latter case, we suggest to use the winding
number associated to the angular momentum as a synthetic dimension.
</p>
{{{{ARTICLE_PARSER}}}}<p>In the near future, a major challenge in quantum computing is to scale up
robust qubit prototypes to practical problem sizes and to implement
comprehensive error correction for computational precision. Due to inevitable
quantum uncertainties in resonant control pulses, increasing the precision of
quantum gates comes with the expense of increased energy consumption.
Consequently, the power dissipated in the vicinity of the processor in a
well-working large-scale quantum computer seems unacceptably large in typical
systems requiring low operation temperatures. Here, we introduce a method for
qubit driving and show that it serves to decrease the single-qubit gate error
without increasing the average power dissipated per gate. Previously,
single-qubit gate error induced by a bosonic drive mode has been considered to
be inversely proportional to the energy of the control pulse, but we circumvent
this bound by reusing and correcting itinerant control pulses. Thus our work
suggests that heat dissipation does not pose a fundamental limitation, but a
necessary practical challenge in future implementations of large-scale quantum
computers.
</p>
{{{{ARTICLE_PARSER}}}}<p>We show that resonant dipole-dipole interactions between Rydberg atoms in a
triangular lattice can give rise to artificial magnetic fields for spin
excitations. We consider the coherent dipole-dipole coupling between $np$ and
$ns$ Rydberg states and derive an effective spin-1/2 Hamiltonian for the $np$
excitations. By breaking time-reversal symmetry via external fields we engineer
complex hopping amplitudes for transitions between two rectangular
sub-lattices. The phase of these hopping amplitudes depends on the direction of
the hop. This gives rise to a staggered, artificial magnetic field which
induces non-trivial topological effects. We calculate the single-particle band
structure and investigate its Chern numbers as a function of the lattice
parameters and the detuning between the two sub-lattices. We identify extended
parameter regimes where the Chern number of the lowest band is $C=1$ or $C=2$.
</p>
{{{{ARTICLE_PARSER}}}}<p>The desire to have a source of single entangled photon pairs can be satisfied
using single quantum dots as emitters. However, we are not bound to pursue only
polarization entanglement, but can also exploit other degrees of freedom. In
this chapter we focus on the time degree of freedom, to achieve so-called
time-bin entanglement. This requires that we prepare the quantum dot coherently
into the biexciton state and also build special interferometers for analysis.
Finally this technique can be extended to achieve time-bin and polarization
hyper-entanglement from a suitable quantum dot.
</p>
{{{{ARTICLE_PARSER}}}}<p>We study a simple model describing superradiance in a system of two-level
atoms interacting with a single-mode bosonic field. The model permits a
continuous crossover between integrable and partially chaotic regimes and shows
a complex thermodynamic and quantum phase structure. Several types of
excited-state quantum phase transitions separate quantum phases that are
characterized by specific energy dependences of various observables and by
different atom-field and atom-atom entanglement properties. We observe an
approximate revival of some states from the weak atom-field coupling limit in
the strong coupling regime.
</p>
{{{{ARTICLE_PARSER}}}}<p>Long-baseline interferometry (LBI) is used to reconstruct the image of faint
thermal objects. The image quality, for a given exposure time, is in general
limited by a low signal-to-noise ratio (SNR). We show theoretically that a
significant increase of the SNR, in a LBI, is possible by adding or subtracting
photons to the thermal beam. At low photon counts, photon addition-subtraction
technology strongly enhances the image quality. We have experimentally realized
a nondeterministic physical protocol for photon subtraction. Our theoretical
predictions are supported by experimental results.
</p>
{{{{ARTICLE_PARSER}}}}<p>We propose an efficient procedure to confidently identify the subspace that
contains all the relevant information about a quantum state that lives in an
arbitrarily large-dimensional Hilbert space---its physical sector. This entails
only a few simple measurements and does not require performing a full
tomography or any additional \emph{ad hoc} assumption. We apply this approach
to both discrete- and continuous-variable systems. For the former, this turns
out to be a suitable deterministic dimension-testing protocol. For the latter,
we experimentally demonstrate the method without the need for ideal
photon-number-resolving detectors.
</p>
{{{{ARTICLE_PARSER}}}}<p>We describe a protocol by which an imaging system could be protected against
jamming by a malevolent party. Our protocol not only allows recognition of the
jamming, but also allows for the recovery of the true image from the jammed
one. We apply the method to jamming of quantum ghost imaging, for which the
jamming detection probability is increased when the imaging light is entangled.
The method can also be used to provide image recovery in general noisy
environments.
</p>
{{{{ARTICLE_PARSER}}}}<p>Photo-induced transition probabilities in graphene are studied theoretically
from the viewpoint of Floquet theory. Conduction band populations are computed
for a strongly, periodically driven graphene sheet under linear, circular, and
elliptic polarization. Features of the momentum spectrum of excited
quasi-particles can be directly related to the avoided crossing of the Floquet
quasi-energy levels. In particular, the impact of the ellipticity and the
strength of the laser excitation on the avoided crossing structure -- and on
the resulting transition probabilities -- is studied. It is shown that the
ellipticity provides an additional control parameter over the phenomenon of
coherent destruction of tunneling in graphene, allowing one to selectively
suppress multiphoton resonances.
</p>
{{{{ARTICLE_PARSER}}}}<p>We explore critical properties of two-dimensional lattices of spins
interacting via an anisotropic Heisenberg Hamiltonian and subject to incoherent
spin flips. We determine the steady-state solution of the master equation for
the density matrix via the corner-space renormalization method. We investigate
the finite-size scaling and critical exponent of the magnetic linear
susceptibility associated to a dissipative ferromagnetic transition. We show
that the Von Neumann entropy increases across the critical point, revealing a
strongly mixed character of the ferromagnetic phase. Entanglement is witnessed
by the quantum Fisher information which exhibits a critical behavior at the
transition point, showing that quantum correlations play a crucial role in the
transition even though the system is in a mixed state.
</p>
{{{{ARTICLE_PARSER}}}}<p>The entanglement and R\'{e}nyi entropies for spherical entangling surfaces in
CFTs with gravity duals can be explicitly calculated by mapping these entropies
first to the thermal entropy on hyperbolic space and then, using the AdS/CFT
correspondence, to the Wald entropy of topological black holes. Here we extend
this idea by taking into account corrections to the Wald entropy. Using the
method based on horizon symmetries and the asymptotic Cardy formula, we
calculate corrections to the Wald entropy and find that these corrections are
proportional to the logarithm of horizon area. With the corrected black hole
entropy expression, we then find corrections to the R\'{e}nyi entropies. We
calculate these corrections for both Einstein as well as Gauss-Bonnet gravity
duals. Corrections with logarithmic dependence on the area of the entangling
surface naturally occur at the order $G_{D}^0$ and it seems to be a general
feature of entanglement and R\'{e}nyi entropies for CFTs with gravity duals. In
particular, there is a logarithmic correction to the entropy in odd boundary
spacetime dimensions as well.
</p>
{{{{ARTICLE_PARSER}}}}<p>Solid-state quantum emitters have long been recognised as the ideal platform
to realize integrated quantum photonic technologies. We use a self-assembled
negatively charged QD in a low Q-factor photonic micropillar to demonstrate for
the first time a key figure of merit for deterministic switching and
spin-photon entanglement: a shift in phase of an input single photon of
$&gt;90^{\deg}$ with values of up to $2\pi/3$ ($120^{\deg}$) demonstrated. This
$&gt;\pi/2$ ($90^{\deg}$) measured value represents an important threshold: above
this value input photons interact with the emitter deterministically. A
deterministic photon-emitter interaction is the only viable scalable means to
achieve several vital functionalities not possible in linear optics such as
quantum switches and entanglement gates. Our experimentally determined value is
limited by mode mismatch between the input laser and the cavity, QD spectral
fluctuations and spin relaxation. We determine that up to $80\%$ of the
collected photons have interacted with the QD and undergone a phase shift of
$\pi$.
</p>
{{{{ARTICLE_PARSER}}}}<p>We theoretically investigate an ensemble of three-level room-temperature
atoms in a two-mode optical cavity, focusing on the case of counterpropagating
light fields. We find that in the limit of large detunings the problem admits
relatively simple and intuitive solutions. When a classical field drives one of
the transitions, the system becomes equivalent to an ensemble of two-level
atoms with suppressed Doppler broadening. In contrast, when the same transition
is driven with a single photon, the system collectively behaves like a single
two-level atom. This latter result is particularly relevant in the context of
quantum nonlinear optics.
</p>
{{{{ARTICLE_PARSER}}}}<p>We theoretically investigate the implementation of a quantum phase gate in a
system constituted by a single atom inside an optical cavity, based on the
electromagnetically induced transparency effect. Firstly we show that a probe
pulse can experience a $\pi$ phase shift due to the presence or absence of a
classical control field. Considering the interplay of the cavity-EIT effect and
the quantum memory process, we demonstrated a controlled phase gate between two
single photons. To this end, firstly one needs to store a (control) photon in
the ground atomic states. In the following, a second (target) photon must
impinge on the atom-cavity system. Depending on the atomic state, this second
photon will be either transmitted or reflected, acquiring different phase
shifts. This protocol can then be easily extended to multiphoton systems, i.e.,
keeping the control photon stored, it may induce phase shifts in several single
photons, thus enabling the generation of multipartite entangled states. We
explore the relevant parameter space in the atom-cavity system that allows the
implementation of quantum phase gates using the recent technologies. In
particular we have found a lower bound for the cooperativity of the atom-cavity
system which enables the implementation of phase shift on single photons. The
induced shift on the phase of a photonic qubit and the controlled phase gate
between single photons, combined with optical devices, enable to perform
universal quantum computation.
</p>
{{{{ARTICLE_PARSER}}}}<p>We study the hydrogen atom eigenstate energy and wave function in the Rindler
space. The probability distribution is tilted because the electric field of the
nucleus is no longer spherically symmetric. The hydrogen atom therefore cannot
be treated exactly in the same way as what it is in an inertial frame. We also
find that if the external force accelerates only the nucleus and then the
nucleus accelerates its surrounding electrons through electromagnetic force,
the electrons can tunnel through the local energy gap and split the hydrogen
atom into an ion. This is similar to what one expects from the Stark effect.
However, the critical acceleration is about $3\times 10^{22} m/s^2$. It is well
beyond the gravitational acceleration on a regular star surface.
</p>
{{{{ARTICLE_PARSER}}}}<p>We introduce the concept of fermionic matrix product operators, and show that
they provide a natural representation of fermionic fusion tensor categories.
This allows for the classification of two dimensional fermionic topological
phases in terms of matrix product operator algebras. Using this approach we
give a classification of fermionic symmetry protected topological phases with
respect to a group $G$ in terms of three cohomology groups: $H^1(G,Z_2)$,
describing which matrix product operators are of Majorana type, $H^2(G,Z_2)$,
describing the fermionic nature of the fusion tensors that arise when two
matrix product operators are multiplied, and the supercohomolgy group
$\bar{H}^3(G,U(1))$ which corresponds to the associator that changes the order
of fusion. We also generalize the tensor network description of the string-net
ground states to the fermionic setting, yielding simple representations of a
class that includes the fermionic toric code.
</p>
{{{{ARTICLE_PARSER}}}}<p>We revisit the old problem of which is the best single particle basis to
express a Hubbard-like lattice model. A rigorous variational solution of this
problem leads to equations in which the answer depends in a self-consistent
manner on the solution of the lattice model itself. Contrary to naive
expectations, for arbitrary small interactions, the optimized orbitals differ
from the non-interacting ones, leading also to substantial changes in the model
parameters as shown analytically and in an explicit numerical solution for a
simple double-well one-dimensional case. At strong coupling, we obtain the
direct exchange interaction with a very large renormalization with important
consequences for the explanation of ferromagnetism with model hamiltonians.
Moreover, in the case of two atoms and two fermions we show that the
optimization equations are closely related to reduced density matrix functional
theory thus establishing an unsuspected correspondence between continuum and
lattice approaches.
</p>
{{{{ARTICLE_PARSER}}}}<p>The insertion of a small polarizable particle in an arbitrarily large optical
cavity significantly alters the quantum-mechanical state of the electromagnetic
field in that the photon ground state of the empty cavity and that of the
cavity with the particle become mutually orthogonal and, thus, cannot be
connected adiabatically in the infinite limit. The photon problem can be mapped
exactly onto that of a many-body system of fermions, which is known to exhibit
an orthogonality catastrophe when a finite-range local potential is introduced.
We predict that the motion of polarizable objects inside a cavity, no matter
how slow, as well as their addition and removal from the cavity, will generate
a macroscopic, diverging number of low-energy photons. The significance of
these results in regard to the quantum measurement problem and the dynamical
Casimir effect are also discussed.
</p>
{{{{ARTICLE_PARSER}}}}<p>We present an open system interaction formalism for the Dirac equation.
Overcoming a complexity bottleneck of alternative formulations, our framework
enables efficient numerical simulations (utilizing a typical desktop) of
relativistic dynamics within the von Neumann density matrix and Wigner phase
space descriptions. Employing these instruments, we gain important insights
into the effect of quantum dephasing for relativistic systems in many branches
of physics. In particular, the conditions for robustness of Majorana spinors
against dephasing are established. Using the Klein paradox and tunneling as
examples, we show that quantum dephasing does not suppress negative energy
particle generation. Hence, the Klein dynamics is also robust to dephasing.
</p>
{{{{ARTICLE_PARSER}}}}<p>We theoretically show the negative refraction existing in M\\"{o}bius
molecules. The negative refractive index is induced by the non-trivial topology
of the molecules. With the M\\"{o}bius boundary condition, the effective
electromagnetic fields felt by the electron in a M\\"{o}bius ring is spatially
inhomogeneous. In this regard, the $D_{N}$ symmetry is broken in M\\"{o}bius
molecules and thus the magnetic response is induced through the effective
magnetic field. Our findings open up a new architecture for negative refractive
index materials based on the non-trivial topology of M\\"{o}bius molecules.
</p>
{{{{ARTICLE_PARSER}}}}<p>Randomness extractors, widely used in classical and quantum cryptography and
other fields of computer science, e.g., derandomization, are functions which
generate almost uniform randomness from weak sources of randomness. In the
quantum setting one must take into account the quantum side information held by
an adversary which might be used to break the security of the extractor. In the
case of seeded extractors the presence of quantum side information has been
extensively studied. For multi-source extractors one can easily see that high
conditional min-entropy is not sufficient to guarantee security against
arbitrary side information, even in the classical case. Hence, the interesting
question is under which models of (both quantum and classical) side information
multi-source extractors remain secure. In this work we suggest a natural model
of side information, which we call the Markov model, and prove that any
multi-source extractor remains secure in the presence of quantum side
information of this type (albeit with weaker parameters). This improves on
previous results in which more restricted models were considered and the
security of only some types of extractors was shown.
</p>
{{{{ARTICLE_PARSER}}}}<p>A conceptually simpler proof of the separability criterion for two-qubit
systems, which is referred to as \"Hefei inequality\" in literature, is
presented. This inequality gives a necessary and sufficient separability
criterion for any mixed two-qubit system unlike the Bell-CHSH inequality that
cannot test the mixed-states such as the Werner state when regarded as a
separability criterion. The original derivation of this inequality emphasized
the uncertainty relation of complementary observables, but we show that the
uncertainty relation does not play any role in the actual derivation and the
Peres-Hodrodecki condition is solely responsible for the inequality. Our
derivation, which contains technically novel aspects such as an analogy to the
Dirac equation, sheds light on this inequality and on the fundamental issue to
what extent the uncertainty relation can provide a test of entanglement. This
separability criterion is illustrated for an exact treatment of the Werner
state.
</p>
{{{{ARTICLE_PARSER}}}}<p>In communication complexity, a number of distant parties have the task of
calculating a distributed function of their inputs, while minimizing the amount
of communication between them. It is known that with quantum resources, such as
entanglement and quantum channels, one can obtain significant reductions in the
communication complexity of some tasks. In this work, we study the role of the
quantum superposition of the direction of communication as a resource for
communication complexity. We present a tripartite communication task for which
such a superposition allows for an exponential saving in communication,
compared to one-way quantum (or classical) communication; the advantage also
holds when we allow for protocols with bounded error probability.
</p>
{{{{ARTICLE_PARSER}}}}<p>We show that, regardless of the dimension of the Hilbert space, there exists
no set of rays revealing state-independent contextuality with less than 13
rays. This implies that the set proposed by Yu and Oh in dimension three [Phys.
Rev. Lett. 108, 030402 (2012)] is actually the minimal set in quantum theory.
This contrasts with the case of Kochen-Specker sets, where the smallest set
occurs in dimension four.
</p>
{{{{ARTICLE_PARSER}}}}<p>We investigate the non-equilibrium quantum dynamics of a canonical
light-matter system, namely the Dicke model, when the light-matter interaction
is ramped up and down through a cycle across the quantum phase transition. Our
calculations reveal a rich set of dynamical behaviors determined by the cycle
times, ranging from the slow, near adiabatic regime through to the fast, sudden
quench regime. As the cycle time decreases, we uncover a crossover from an
oscillatory exchange of quantum information between light and matter that
approaches a reversible adiabatic process, to a dispersive regime that
generates large values of light-matter entanglement. The phenomena uncovered in
this work have implications in quantum control, quantum interferometry, as well
as in quantum information theory.
</p>
{{{{ARTICLE_PARSER}}}}<p>In this article, we try to test the influence of the modification of the
scalar product, found in the problems of the energy-dependent potential, on the
physical properties of the harmonic oscillator in one dimension. For this, we
at first discuss the effect of this change on the thermodynamic properties of
this oscillator, and then on the parameter of Fisher, well known in the field
of quantum information. For the second problem, we are an obligation to
redefine this parameter. Finally, the uncertainly relation of Cramer-Rao is
well recovered in our problem in question.
</p>
{{{{ARTICLE_PARSER}}}}<p>We consider the 2D alternate quantum walk on a cylinder. We concentrate on
the study of the motion along the open dimension, in the spirit of looking at
the closed coordinate as a small or \"hidden\" extra dimension. If one starts
from localized initial conditions on the lattice, the dynamics of the quantum
walk that is obtained after tracing out the small dimension shows the
contribution of several components, which can be understood from the study of
the dispersion relations for this problem. In fact, these components originate
from the contribution of the possible values of the quasi-momentum in the
closed dimension. In the continuous space-time limit, the different components
manifest as a set of Dirac equations, with each quasi-momentum providing the
value of the corresponding mass. We briefly discuss the possible link of these
ideas to the simulation of high energy physical theories that include extra
dimensions. Finally, entanglement between the coin and spatial degrees of
freedom is studied, showing that the entanglement entropy clearly overcomes the
value reached with only one spatial dimension.
</p>
{{{{ARTICLE_PARSER}}}}<p>A stochastic representation of the dynamics of open quantum systems, suitable
for non-perturbative system-reservoir interaction, non-Markovian effects and
arbitrarily driven systems is presented. It includes the case of driving on
timescales comparable to or shorter than the reservoir correlation time, a
notoriously difficult but relevant case in the context of quantum information
processing and quantum thermodynamics. A previous stochastic approach is
re-formulated for the case of finite reservoir correlation and response times,
resulting in a numerical simulation strategy exceeding previous ones by orders
of magnitude in efficiency. Although the approach is based on a memory
formalism, the dynamical equations propagated in the simulations are
time-local. This leaves a wide range of choices in selecting the system to be
studied and the numerical method used for propagation. For a series of tests,
the dynamics of the spin-boson system is computed in various settings including
strong external driving and Landau-Zener transitions.
</p>
{{{{ARTICLE_PARSER}}}}<p>We have very little experience of the quantum dynamics of the ubiquitous
nonlinear waves. Observed phenomena in high energy physics are perturbations to
linear waves, and classical nonlinear waves, like solitons, are barely affected
by quantum effects. We know that solitons, immutable in classical physics,
exhibit collapse and revivals according to quantum mechanics. However this
effect is very weak and has never been observed experimentally. By predicting
black hole evaporation Hawking first introduced a distinctly quantum effect in
nonlinear gravitational physics.Here we show the existence of a general and
universal quantum process whereby a soliton emits quantum radiation with a
specific frequency content, and a temperature given by the number of quanta,
the soliton Schwarzschild radius, and the amount of nonlinearity, in a precise
and surprisingly simple way. This result may ultimately lead to the first
experimental evidence of genuine quantum black hole evaporation. In addition,
our results show that black hole radiation occurs in a fully quantised theory,
at variance with the common approach based on quantum field theory in a curved
background; this may provide insights into quantum gravity theories. Our
findings also have relevance to the entire field of nonlinear waves, including
cold atomic gases and extreme phenomena such as shocks and rogue-waves.
Finally, the predicted effect may potentially be exploited for novel tunable
quantum light sources.
</p>
{{{{ARTICLE_PARSER}}}}<p>The fast development of superconducting nanowire single photon detector
(SNSPD) in the past decade has enabled many advances in quantum information
technology. The best system detection efficiency (SDE) record at 1550 nm
wavelength was 93% obtained from SNSPD made of amorphous WSi which usually
operated at sub-kelvin temperatures. We first demonstrate SNSPD made of
polycrystalline NbN with SDE of 90.2% for 1550 nm wavelength at 2.1K,
accessible with a compact cryocooler. The SDE saturated to 92.1% when the
temperature was lowered to 1.8K. The results lighten the practical and high
performance SNSPD to quantum information and other high-end applications.
</p>
{{{{ARTICLE_PARSER}}}}<p>It is proven that the exact excited-state wavefunction and energy may be
obtained by minimizing the energy expectation value of a trial wave function
that is constrained only to have the correct nodes of the state of interest.
This excited-state nodal minimum principle has the advantage that it requires
neither minimization with the con- straint of wavefunction orthogonality to all
lower eigenstates nor the antisymmetry of the trial wavefunctions. It is also
found that the minimization over the entire space can be partitioned into
several in- terconnected minimizations within the individual nodal regions, and
the exact excited-state energy may be obtained by a minimization in just one or
several of these nodal regions. For the proofs of the the- orem, it is observed
that the many-electron eigenfunction, restricted to a nodal region, is
equivalent to a ground state wavefunction of one electron in a higher
dimensional space; and an explicit excited-state energy variational expression
is obtained by generalizing the Jacobi method of multiplicative variation.
</p>
{{{{ARTICLE_PARSER}}}}<p>We theoretically study a strongly-driven optomechanical system which consists
of a passive optical cavity and an active mechanical resonator. When the
optomechanical coupling strength is varied, phase transitions, which are
similar those observed in $\mathcal{PT}$-symmetric systems, are observed. We
show that the optical transmission can be controlled by changing the gain of
the mechanical resonator and loss of the optical cavity mode. Especially, we
find that: (i) for balanced gain and loss, optical amplification and absorption
can be tuned by changing the optomechanical coupling strength through a control
field; (ii) for unbalanced gain and loss, even with a tiny mechanical gain,
both optomechanically-induced transparency and anomalous dispersion can be
observed around a critical point, which exhibits an ultra-long group delay. The
time delay $\tau$ can be optimized by regulating the optomechanical coupling
strength through the control field and improved up to several orders of
magnitude ($\tau\sim2$ $\mathrm{ms}$) compared to that of conventional
optomechanical systems ($\tau\sim1$ $\mu\mathrm{s}$). The presence of
mechanical gain makes the group delay more robust to environmental
perturbations. Our proposal provides a powerful platform to control light
transport using a $\mathcal{PT}$-symmetric-like optomechanical system.
</p>
{{{{ARTICLE_PARSER}}}}<p>We study the computational complexity of sequences of projective varieties.
We define analogues of the complexity classes P and NP for these and prove the
NP-completeness of a sequence called the universal circuit resultant. This is
the first family of compact spaces shown to be NP-complete in a geometric
setting.
</p>
{{{{ARTICLE_PARSER}}}}<p>Traditional Scene Understanding problems such as Object Detection and
Semantic Segmentation have made breakthroughs in recent years due to the
adoption of deep learning. However, the former task is not able to localise
objects at a pixel level, and the latter task has no notion of different
instances of objects of the same class. We focus on the task of Instance
Segmentation which recognises and localises objects down to a pixel level. Our
model is based on a deep neural network trained for semantic segmentation. This
network incorporates a Conditional Random Field with end-to-end trainable
higher order potentials based on object detector outputs. This allows us to
reason about instances from an initial, category-level semantic segmentation.
Our simple method effectively leverages the great progress recently made in
semantic segmentation and object detection. The accurate instance-level
segmentations that our network produces is reflected by the considerable
improvements obtained over previous work.
</p>
{{{{ARTICLE_PARSER}}}}<p>Many AI applications rely on knowledge encoded in a locigal knowledge base
(KB). The most essential benefit of such logical KBs is the opportunity to
perform automatic reasoning which however requires a KB to meet some minimal
quality criteria such as consistency. Without adequate tool assistance, the
task of resolving such violated quality criteria in a KB can be extremely hard,
especially when the problematic KB is large and complex. To this end,
interactive KB debuggers have been introduced which ask a user queries whether
certain statements must or must not hold in the intended domain. The given
answers help to gradually restrict the search space for KB repairs.
</p>
<p>Existing interactive debuggers often rely on a pool-based strategy for query
computation. A pool of query candidates is precomputed, from which the best
candidate according to some query quality criterion is selected to be shown to
the user. This often leads to the generation of many unnecessary query
candidates and thus to a high number of expensive calls to logical reasoning
services. We tackle this issue by an in-depth mathematical analysis of diverse
real-valued active learning query selection measures in order to determine
qualitative criteria that make a query favorable. These criteria are the key to
devising efficient heuristic query search methods. The proposed methods enable
for the first time a completely reasoner-free query generation for interactive
KB debugging while at the same time guaranteeing optimality conditions, e.g.
minimal cardinality or best understandability for the user, of the generated
query that existing methods cannot realize.
</p>
<p>Further, we study different relations between active learning measures. The
obtained picture gives a hint about which measures are more favorable in which
situation or which measures always lead to the same outcomes, based on given
types of queries.
</p>
{{{{ARTICLE_PARSER}}}}<p>The predator/prey (capture) problem is a prototype of many network-related
applications. We study the capture process on complex networks by considering
multiple predators from multiple sources. In our model, some lions start from
multiple sources simultaneously to capture the lamb by biased random walks,
which are controlled with a free parameter $\alpha$. We derive the distribution
of the lamb's lifetime and the expected lifetime $\left\langle T\right\rangle
$. Through simulation, we find that the expected lifetime drops substantially
with the increasing number of lions. We also study how the underlying
topological structure affects the capture process, and obtain that locating on
small-degree nodes is better than large-degree nodes to prolong the lifetime of
the lamb. Moreover, dense or homogeneous network structures are against the
survival of the lamb.
</p>
{{{{ARTICLE_PARSER}}}}<p>In this paper, an incentive proactive cache mechanism in cache-enabled small
cell networks (SCNs) is proposed, in order to motivate the content providers
(CPs) to participate in the caching procedure. A network composed of a single
mobile network operator (MNO) and multiple CPs is considered. The MNO aims to
define the price it charges the CPs to maximize its revenue while the CPs
compete to determine the number of files they cache at the MNO's small base
stations (SBSs) to improve the quality of service (QoS) of their users. This
problem is formulated as a Stackelberg game where a single MNO is considered as
the leader and the multiple CPs willing to cache files are the followers. The
followers game is modeled as a non-cooperative game and both the existence and
uniqueness of a Nash equilibrium (NE) are proved. The closed-form expression of
the NE which corresponds to the amount of storage each CP requests from the MNO
is derived. An optimization problem is formulated at the MNO side to determine
the optimal price that the MNO should charge the CPs. Simulation results show
that at the equilibrium, the MNO and CPs can all achieve a utility that is up
to 50% higher than the cases in which the prices and storage quantities are
requested arbitrarily.
</p>
{{{{ARTICLE_PARSER}}}}<p>Different versions of peer-to-peer electronic cash exist as data represented
by separate blockchains. Payments between such systems cannot be sent directly
from one party to another without going through a financial institution.
Bitcoin provided part of the solution but its utility is limited to
intra-blockchain transactions. The benefits are lost if a trusted third party
is required to execute inter-blockchain transactions. We propose a solution to
the inter-blockchain transaction problem using the same fundamental principles
of Bitcoin. The protocol is described by the Uberledger framework, a
hierarchical meta-blockchain layer that encapsulates information regarding the
fidelity of peer-to-peer transaction facilitators.
</p>
{{{{ARTICLE_PARSER}}}}<p>A wireless sensor network is composed of many sensor nodes that have been
given out in a specific zone and each of them had an ability of collecting
information from the environment and sending collected data to the sink. The
most significant issues in wireless sensor networks despite the recent progress
is the trouble of the severe limitations of energy resources. Since that in
different applications of sensor nets we could throw a static or mobile sink
then all aspects of such networks should be planned with an awareness of
energy. One of the most significant topics related to these networks is
routing. One of the most widely used and efficient methods of routing is a
hierarchy (based on clustering) method. In The present study with the objective
of cutting down energy consumption and persistence of network coverage we have
offered a novel algorithm based on clustering algorithms and multi hop routing.
To achieve this goal first we layer the network environment based on the size
of the network. We will identify the optimal number of cluster heads and every
cluster head based on the mechanism of topology control will start to accept
members. Likewise we set the first layer as gate layer and subsequently
identifying the gate nodes we would turn away half of the sensors and then stop
using energy and the remaining nodes in this layer will join the gate nodes
because they hold a critical part in bettering the functioning of the system.
Cluster heads off following layers send the information to cluster heads in the
above layer until sent data will be sent to gate nodes and finally will be sent
to sink. We have tested the proposed algorithm in two situations 1) when the
sink is off and 2) when a sink is on and simulation data shows that proposed
algorithm has better performance in terms of the life span of a network than
LEACH and E LEACH protocols.
</p>
{{{{ARTICLE_PARSER}}}}<p>We consider the best-arm identification problem in multi-armed bandits, which
focuses purely on exploration. A player is given a fixed budget to explore a
finite set of arms, and the rewards of each arm are drawn independently from a
fixed, unknown distribution. The player aims to identify the arm with the
largest expected reward. We propose a general framework to unify sequential
elimination algorithms, where the arms are dismissed iteratively until a unique
arm is left. Our analysis reveals a novel performance measure expressed in
terms of the sampling mechanism and number of eliminated arms at each round.
Based on this result, we develop an algorithm that divides the budget according
to a nonlinear function of remaining arms at each round. We provide theoretical
guarantees for the algorithm, characterizing the suitable nonlinearity for
different problem environments. Matching the theoretical results, our
experiments show that the nonlinear algorithm outperforms the state-of-the-art.
We finally study the side-observation model, where pulling an arm reveals the
rewards of its related arms, and we establish improved theoretical guarantees
in the pure-exploration setting.
</p>
{{{{ARTICLE_PARSER}}}}<p>We capitalize on large amounts of unlabeled video in order to learn a model
of scene dynamics for both video recognition tasks (e.g. action classification)
and video generation tasks (e.g. future prediction). We propose a generative
adversarial network for video with a spatio-temporal convolutional architecture
that untangles the scene's foreground from the background. Experiments suggest
this model can generate tiny videos up to a second at full frame rate better
than simple baselines, and we show its utility at predicting plausible futures
of static images. Moreover, experiments and visualizations show the model
internally learns useful features for recognizing actions with minimal
supervision, suggesting scene dynamics are a promising signal for
representation learning. We believe generative video models can impact many
applications in video understanding and simulation.
</p>
{{{{ARTICLE_PARSER}}}}<p>Context: One of the black arts of data mining is learning the magic
parameters that control the learners. In software analytics, at least for
defect prediction, several methods, like grid search and differential
evolution(DE), have been proposed to learn those parameters. They've been
proved to be able to improve learner performance.
</p>
<p>Objective: We want to evaluate which method that can find better parameters
in terms of performance score and runtime. Methods: This paper compares grid
search to differential evolution, which is an evolutionary algorithm that makes
extensive use of stochastic jumps around the search space.
</p>
<p>Results: We find that the seemingly complete approach of grid search does no
better, and sometimes worse, than the stochastic search. Yet, when repeated 20
times to check for conclusion validity, DE was over 210 times faster (6.2 hours
vs 54 days for grid search when both tuning Random Forest over 17 test data
sets with F-measure as optimzation objective).
</p>
<p>Conclusions: These results are puzzling: why does a quick partial search be
just as effective as a much slower, and much more,extensive search? To answer
that question, we turned to the theoretical optimization literature. Bergstra
and Bengio conjecture that grid search is not more effective than more
randomized searchers if the underlying search space is inherently low
dimensional.This is significant since recent results show that defect
prediction exhibits very low intrinsic dimensionality-an observation that
explains why a fast method like DE may work as well as a seemingly more
thorough grid search. This suggests, as a future research direction, that it
might be possible to peek at data sets before doing any optimization in order
to match the optimization algorithm to the problem at hand.
</p>
{{{{ARTICLE_PARSER}}}}<p>In this paper, we present a geometric variational algorithm for optimizing
the gaits of kinematic locomoting systems. The dynamics of this algorithm are
analogous to the physics of a soap bubble, with the system's Lie bracket
supplying an \"inflation pressure\" that is balanced by a \"surface tension\" term
derived from a Riemannian metric on the system's shape space. We demonstrate
this optimizer on a variety of system geometries (including Purcell's swimmer)
and for optimization criteria that include maximizing displacement and
efficiency of motion for both translation and turning motions.
</p>
{{{{ARTICLE_PARSER}}}}<p>Recently developed information communication technologies, particularly the
Internet, have affected how we, both as individuals and as a society, create,
store, and recall information. Internet also provides us with a great
opportunity to study memory using transactional large scale data, in a
quantitative framework similar to the practice in statistical physics. In this
project, we make use of online data by analysing viewership statistics of
Wikipedia articles on aircraft crashes. We study the relation between recent
events and past events and particularly focus on understanding memory
triggering patterns. We devise a quantitative model that explains the flow of
viewership from a current event to past events based on similarity in time,
geography, topic, and the hyperlink structure of Wikipedia articles. We show
that on average the secondary flow of attention to past events generated by
such remembering processes is larger than the primary attention flow to the
current event. We are the first to report these cascading effects.
</p>
{{{{ARTICLE_PARSER}}}}<p>Most real-world social networks are inherently dynamic, composed of
communities that are constantly changing in membership. To track these evolving
communities, we need dynamic community detection techniques. This article
evaluates the performance of a set of game theoretic approaches for identifying
communities in dynamic networks. Our method, D-GT (Dynamic Game Theoretic
community detection), models each network node as a rational agent who
periodically plays a community membership game with its neighbors. During game
play, nodes seek to maximize their local utility by joining or leaving the
communities of network neighbors. The community structure emerges after the
game reaches a Nash equilibrium. Compared to the benchmark community detection
methods, D-GT more accurately predicts the number of communities and finds
community assignments with a higher normalized mutual information, while
retaining a good modularity.
</p>
{{{{ARTICLE_PARSER}}}}<p>This paper investigates the use of distributed processing on the problem of
emotion recognition from physiological sensors using a popular machine learning
library on distributed mode. Specifically, we run a random forests classifier
on the biosignal-data, which have been pre-processed to form exclusive groups
in an unsupervised fashion, on a Cloudera cluster using Mahout. The use of
distributed processing significantly reduces the time required for the offline
training of the classifier, enabling processing of large physiological datasets
through many iterations.
</p>
{{{{ARTICLE_PARSER}}}}<p>The paper preposes a new scheme to promote the robustness of 3D structure and
motion factorization from uncalibrated image sequences. First, an augmented
affine factorization algorithm is proposed to circumvent the difficulty in
image registration with imperfect data. Then, an alternative weighted
factorization algorithm is designed to handle the missing data and measurement
uncertainties in the tracking matrix. Finally, a robust structure and motion
factorization scheme is proposed to deal with outlying and missing data. The
novelty and main contribution of the paper are as follows: (i) The augmented
factorization algorithm is a new addition to previous affine factorization
family for both rigid and nonrigid objects; (ii) it is demonstrated that image
reprojection residuals are in general proportional to the error magnitude in
the tracking data, and thus, the outliers can be detected directly from the
distribution of image reprojection residuals, which are then used to estimate
the uncertainty of inlying measurement; (iii) the robust factorization scheme
is proved empirically to be more efficient and more accurate than other robust
algorithms; and (iv) the proposed approach can be directly applied to nonrigid
scenarios. Extensive experiments on synthetic data and real images demonstrate
the advantages of the proposed approach.
</p>
{{{{ARTICLE_PARSER}}}}<p>We consider capacitated vertex cover with hard capacity constraints (VC-HC)
on hypergraphs. In this problem we are given a hypergraph $G=(V,E)$ with a
maximum edge size $f$. Each edge is associated with a demand and each vertex is
associated with a weight (cost), a capacity, and an available multiplicity. The
objective is to find a minimum-weight vertex multiset such that the demands of
the edges can be covered by the capacities of the vertices and the multiplicity
of each vertex does not exceed its available multiplicity.
</p>
<p>In this paper we present an $O(f)$ bi-approximation for VC-HC that gives a
trade-off on the number of augmented multiplicity and the cost of the resulting
cover. In particular, we show that, by augmenting the available multiplicity by
a factor of $k \ge 2$, a~cover with a cost ratio of
$\Big(1+\frac{1}{k-1}\Big)(f-1)$ to the optimal cover for the original instance
can be obtained. This improves over a previous result, which has a cost ratio
of $f^2$ via augmenting the available multiplicity by a factor of $f$.
</p>
{{{{ARTICLE_PARSER}}}}<p>Role discovery in graphs is an emerging area that allows analysis of complex
graphs in an intuitive way. In contrast to other graph prob- lems such as
community discovery, which finds groups of highly connected nodes, the role
discovery problem finds groups of nodes that share similar graph topological
structure. However, existing work so far has two severe limitations that
prevent its use in some domains. Firstly, it is completely unsupervised which
is undesirable for a number of reasons. Secondly, most work is limited to a
single relational graph. We address both these lim- itations in an intuitive
and easy to implement alternating least squares framework. Our framework allows
convex constraints to be placed on the role discovery problem which can provide
useful supervision. In par- ticular we explore supervision to enforce i)
sparsity, ii) diversity and iii) alternativeness. We then show how to lift this
work for multi-relational graphs. A natural representation of a
multi-relational graph is an order 3 tensor (rather than a matrix) and that a
Tucker decomposition allows us to find complex interactions between collections
of entities (E-groups) and the roles they play for a combination of relations
(R-groups). Existing Tucker decomposition methods in tensor toolboxes are not
suited for our purpose, so we create our own algorithm that we demonstrate is
pragmatically useful.
</p>
{{{{ARTICLE_PARSER}}}}<p>In this paper, we study the problem of jointly retrieving the state of a
dynamical system, as well as the state of the sensors deployed to estimate it.
We assume that the sensors possess a simple computational unit that is capable
of performing simple operations, such as retaining the current state and model
of the system in its memory.
</p>
<p>We assume the system to be observable (given all the measurements of the
sensors), and we ask whether each sub-collection of sensors can retrieve the
state of the underlying physical system, as well as the state of the remaining
sensors. To this end, we consider communication between neighboring sensors,
whose adjacency is captured by a communication graph. We then propose a linear
update strategy that encodes the sensor measurements as states in an augmented
state space, with which we provide the solution to the problem of retrieving
the system and sensor states.
</p>
<p>The present paper contains three main contributions. First, we provide
necessary and sufficient conditions to ensure observability of the system and
sensor states from any sensor. Second, we address the problem of adding
communication between sensors when the necessary and sufficient conditions are
not satisfied, and devise a strategy to this end. Third, we extend the former
case to include different costs of communication between sensors. Finally, the
concepts defined and the method proposed are used to assess the state of an
example of approximate structural brain dynamics through linearized
measurements.
</p>
{{{{ARTICLE_PARSER}}}}<p>A set C of vertices of a graph is P_3-convex if every vertex outside C has at
most one neighbor in C. The convex hull \sigma(A) of a set A is the smallest
P_3-convex set that contains A. A set M is convexly independent if for every
vertex x \in M, x \notin \sigma(M-x). We show that the maximal number of
vertices that a convexly independent set in a permutation graph can have, can
be computed in polynomial time.
</p>
{{{{ARTICLE_PARSER}}}}<p>In this paper, we consider the channel estimation problem in Millimeter wave
(mmWave) wireless systems with large antenna arrays. By exploiting the inherent
sparse nature of the mmWave channel, we develop a novel rate-adaptive channel
estimation (RACE) algorithm, which can adaptively adjust the number of required
channel measurements based on an expected probability of estimation error
(PEE). To this end, we design a maximum likelihood (ML) estimator to optimally
extract the path information and the associated probability of error from the
increasing number of channel measurements. Based on the ML estimator, the
algorithm is able to measure the channel using a variable number of beam
patterns until the receiver believes that the estimated direction is correct.
This is in contrast to the existing mmWave channel estimation algorithms, in
which the number of measurements is typically fixed. Simulation results show
that the proposed algorithm can significantly reduce the number of channel
estimation measurements while still retaining a high level of accuracy,
compared to existing multi-stage channel estimation algorithms.
</p>
{{{{ARTICLE_PARSER}}}}<p>In multichannel sequential change detection, multiple sensors monitor an
environment and communicate their data to a fusion center; the latter is
responsible for detecting, as soon as possible, an abrupt change that affects
the observations in an unknown subset of sensors. In the Byzantine version of
this problem, which is the focus of this paper, this task is further
complicated by the fact that an unknown subset of sensors is compromised, in
the sense that their data, both before and after the change, are controlled by
an adversary. In this adversarial framework, we propose three robust, scalable,
multichannel sequential change-detection rules. The proposed procedures impose
different communication requirements and make different assumptions regarding
knowledge of the number of compromised and affected sensors. We characterize
their first-order asymptotic performance under a modification of Lorden's
criterion, in which conditional expected detection delay and expected time to
false alarm are both evaluated with respect to the worst-case scenario for the
data in the compromised sensors. Our theoretical findings are also corroborated
by a simulation study.
</p>
{{{{ARTICLE_PARSER}}}}<p>Machine learning is a thriving part of computer science. There are many
efficient approaches to machine learning that do not provide strong theoretical
guarantees, and a beautiful general learning theory. Unfortunately, machine
learning approaches that give strong theoretical guarantees have not been
efficient enough to be applicable. In this paper we introduce a logical
approach to machine learning. Models are represented by tuples of logical
formulas and inputs and outputs are logical structures. We present our
framework together with several applications where we evaluate it using SAT and
SMT solvers. We argue that this approach to machine learning is particularly
suited to bridge the gap between efficiency and theoretical soundness. We
exploit results from descriptive complexity theory to prove strong theoretical
guarantees for our approach. To show its applicability, we present experimental
results including learning complexity-theoretic reductions rules for board
games. We also explain how neural networks fit into our framework, although the
current implementation does not scale to provide guarantees for real-world
neural networks.
</p>
{{{{ARTICLE_PARSER}}}}<p>Return-Oriented Programming (ROP) is a software exploit for system
compromise. By chaining short instruction sequences from existing code pieces,
ROP can bypass static code-integrity checking approaches and non-executable
page protections. Existing defenses either require access to source code or
binary, a customized compiler or hardware modifications, or suffer from high
performance and storage overhead. In this work, we propose SIGDROP, a low-cost
approach for ROP detection which uses low-level properties inherent to ROP
attacks. Specifically, we observe special patterns of certain hardware events
when a ROP attack occurs during program execution. Such hardware event-based
patterns form signatures to flag ROP attacks at runtime. SIGDROP leverages
Hardware Performance Counters, which are already present in commodity
processors, to efficiently capture and extract the signatures. Our evaluation
demonstrates that SIGDROP can effectively detect ROP attacks with acceptable
performance overhead and negligible storage overhead.
</p>
{{{{ARTICLE_PARSER}}}}<p>We consider the setting of a sensor that consists of a speed-scalable
processor, a battery, and a solar cell that harvests energy from its
environment at a time-invariant recharge rate. The processor must process a
collection of jobs of various sizes. Jobs arrive at different times and have
different deadlines. The objective is to minimize the *recharge rate*, which is
the rate at which the device has to harvest energy in order to feasibly
schedule all jobs. The main result is a polynomial-time combinatorial algorithm
for processors with a natural set of discrete speed/power pairs.
</p>
{{{{ARTICLE_PARSER}}}}<p>Human behaviors exhibit ubiquitous correlations in many aspects, such as
individual and collective levels, temporal and spatial dimensions, content,
social and geographical layers. With rich Internet data of online behaviors
becoming available, it attracts academic interests to explore human mobility
similarity from the perspective of social network proximity. Existent analysis
shows a strong correlation between online social proximity and offline mobility
similari- ty, namely, mobile records between friends are significantly more
similar than between strangers, and those between friends with common neighbors
are even more similar. We argue the importance of the number and diversity of
com- mon friends, with a counter intuitive finding that the number of common
friends has no positive impact on mobility similarity while the diversity plays
a key role, disagreeing with previous studies. Our analysis provides a novel
view for better understanding the coupling between human online and offline
behaviors, and will help model and predict human behaviors based on social
proximity.
</p>
{{{{ARTICLE_PARSER}}}}<p>An important issue in public goods game is whether player's behaviour changes
over time, and if so, how significant it is. In this game players can be
classified into different groups according to the level of their participation
in the public good. This problem can be considered as a concept drift problem
by asking the amount of change that happens to the clusters of players over a
sequence of game rounds. In this study we present a method for measuring
changes in clusters with the same items over discrete time points using
external clustering validation indices and area under the curve. External
clustering indices were originally used to measure the difference between
suggested clusters in terms of clustering algorithms and ground truth labels
for items provided by experts. Instead of different cluster label comparison,
we use these indices to compare between clusters of any two consecutive time
points or between the first time point and the remaining time points to measure
the difference between clusters through time points. In theory, any external
clustering indices can be used to measure changes for any traditional
(non-temporal) clustering algorithm, due to the fact that any time point alone
is not carrying any temporal information. For the public goods game, our
results indicate that the players are changing over time but the change is
smooth and relatively constant between any two time points.
</p>
{{{{ARTICLE_PARSER}}}}<p>In a power distribution network, the network topology information is
essential for an efficient operation of the network. This information of
network connectivity is not accurately available, at the low voltage level, due
to uninformed changes that happen from time to time. In this paper, we propose
a novel data--driven approach to identify the underlying network topology
including the load phase connectivity from time series of energy measurements.
The proposed method involves the application of Principal Component Analysis
(PCA) and its graph-theoretic interpretation to infer the topology from smart
meter energy measurements. The method is demonstrated through simulation on
randomly generated networks and also on IEEE recognized Roy Billinton
distribution test system.
</p>
{{{{ARTICLE_PARSER}}}}<p>One of the most important issues in Wireless Sensor Networks (WSNs) is severe
energy restrictions. As the performance of Sensor Networks is strongly
dependence to the network lifetime, researchers seek a way to use node energy
supply effectively and increasing network lifetime. As a consequence, it is
crucial to use routing algorithms result in decrease energy consumption and
better bandwidth utilization. The purpose of this paper is to increase Wireless
Sensor Networks lifetime using LEACH-algorithm. So before clustering Network
environment, it is divided into two virtual layers (using distance between
sensor nodes and base station) and then regarding to sensors position in each
of two layers, residual energy of sensor and distance from base station is used
in clustering. In this article, we compare proposed algorithm with well-known
LEACH and ELEACH algorithms in homogeneous environment (with equal energy for
all sensors) and heterogeneous one (energy of half of sensors get doubled),
also for static and dynamic situation of base station. Results show that our
proposed algorithm delivers improved performance.
</p>
{{{{ARTICLE_PARSER}}}}<p>Layouts and sub-layouts constitute an important clue while searching a
document on the basis of its structure, or when textual content is
unknown/irrelevant. A sub-layout specifies the arrangement of document entities
within a smaller portion of the document. We propose an efficient graph-based
matching algorithm, integrated with hash-based indexing, to prune a possibly
large search space. A user can specify a combination of sub-layouts of interest
using sketch-based queries. The system supports partial matching for
unspecified layout entities. We handle cases of segmentation pre-processing
errors (for text/non-text blocks) with a symmetry maximization-based strategy,
and accounting for multiple domain-specific plausible segmentation hypotheses.
We show promising results of our system on a database of unstructured entities,
containing 4776 newspaper images.
</p>
{{{{ARTICLE_PARSER}}}}<p>This paper proposes the first implementation of a regular register by n
servers that is tolerant to both mobile Byzantine agents, and transient
failures (it is self-stabilizing) in a round-free synchronous model. We
consider the most difficult model for mobile Byzantine agents to date where the
message delay, $\delta$, and the speed of mobile Byzantine agents, $\Delta$,
are completely decoupled. Moreover, servers are not aware of their state
(infected or correct) after mobile Byzantine agents left them. The register is
maintained by n servers and our algorithm tolerates (i) any number of transient
failures , and (ii) up to f Mobile Byzantine agents. Our implementation uses
bounded timestamps from the $\mathbb{Z}_5$ domain, and is optimal with respect
to the number of tolerated mobile Byzantine agents. The convergence time of our
solution is upper bounded by $3\Delta + T\_{5write()}$ , where $T_{5write()}$
is the time needed to execute five complete write() operations.
</p>
{{{{ARTICLE_PARSER}}}}<p>The segmentation, seen as the association of a partition with an image, is a
difficult task. It can be decomposed in two steps: at first, a family of
contours associated with a series of nested partitions (or hierarchy) is
created and organized, then pertinent contours are extracted. A coarser
partition is obtained by merging adjacent regions of a finer partition. The
strength of a contour is then measured by the level of the hierarchy for which
its two adjacent regions merge. We present an automatic segmentation strategy
using a wide range of stochastic watershed hierarchies. For a given set of
homogeneous images, our approach selects automatically the best hierarchy and
cut level to perform image simplification given an evaluation score.
Experimental results illustrate the advantages of our approach on several
real-life images datasets.
</p>
{{{{ARTICLE_PARSER}}}}<p>The Minimum Sum Coloring Problem (MSCP) is derived from the Graph Coloring
Problem (GCP) by associating a weight to each color. The aim of MSCP is to find
a coloring solution of a graph such that the sum of color weights is minimum.
MSCP has important applications in fields such as scheduling and VLSI design.
We propose in this paper new upper bounds of the chromatic strength, i.e. the
minimum number of colors in an optimal solution of MSCP, based on an
abstraction of all possible colorings of a graph called motif. Experimental
results on standard benchmarks show that our new bounds are significantly
tighter than the previous bounds in general, allowing to reduce substantially
the search space when solving MSCP .
</p>
{{{{ARTICLE_PARSER}}}}<p>Online reviews have increasingly become a very important resource for
consumers when making purchases. Though it is becoming more and more difficult
for people to make well-informed buying decisions without being deceived by
fake reviews. Prior works on the opinion spam problem mostly considered
classifying fake reviews using behavioral user patterns. They focused on
prolific users who write more than a couple of reviews, discarding one-time
reviewers. The number of singleton reviewers however is expected to be high for
many review websites. While behavioral patterns are effective when dealing with
elite users, for one-time reviewers, the review text needs to be exploited. In
this paper we tackle the problem of detecting fake reviews written by the same
person using multiple names, posting each review under a different name. We
propose two methods to detect similar reviews and show the results generally
outperform the vectorial similarity measures used in prior works. The first
method extends the semantic similarity between words to the reviews level. The
second method is based on topic modeling and exploits the similarity of the
reviews topic distributions using two models: bag-of-words and
bag-of-opinion-phrases. The experiments were conducted on reviews from three
different datasets: Yelp (57K reviews), Trustpilot (9K reviews) and Ott dataset
(800 reviews).
</p>
{{{{ARTICLE_PARSER}}}}<p>The world's collective knowledge is evolving through research and new
scientific discoveries. It is becoming increasingly difficult to objectively
rank the impact research institutes have on global advancements. However, since
the funding, governmental support, staff and students quality all mirror the
projected quality of the institution, it becomes essential to measure the
affiliation's rating in a transparent and widely accepted way. We propose and
investigate several methods to rank affiliations based on the number of their
accepted papers at future academic conferences. We carry out our investigation
using publicly available datasets such as the Microsoft Academic Graph, a
heterogeneous graph which contains various information about academic papers.
We analyze several models, starting with a simple probabilities-based method
and then gradually expand our training dataset, engineer many more features and
use mixed models and gradient boosted decision trees models to improve our
predictions.
</p>
{{{{ARTICLE_PARSER}}}}<p>In this paper we present an interactive tool that can be used to quantify fat
infiltration in lumbar muscles, which is useful in studying fat infiltration
and lower back pain (LBP) in adults. Currently, a qualitative assessment by
visual grading via a 5-point scale is used to study fat infiltration in lumbar
muscles from an axial view of lumbar-spine MR Images. However, a quantitative
approach (on a continuous scale of 0-100\%) may provide a greater insight. In
this paper, we propose a method to precisely quantify the fat deposition /
infiltration in a user-defined region of the lumbar muscles, which may aid
better diagnosis and analysis. The key steps are interactively segmenting the
region of interest (ROI) from the lumbar muscles using the well known livewire
technique, identifying fatty regions in the segmented region based on
variable-selection of threshold and softness levels, automatically detecting
the center of the spinal column and fragmenting the lumbar muscles into smaller
regions with reference to the center of the spinal column, computing key
parameters [such as total and region-wise fat content percentage, total-cross
sectional area (TCSA) and functional cross-sectional area (FCSA)] and exporting
the computations and associated patient information from the MRI, into a
database. A standalone application using MATLAB R2014a was developed to perform
the required computations along with an intuitive graphical user interface
(GUI).
</p>
{{{{ARTICLE_PARSER}}}}<p>Opinion mining from customer reviews has become pervasive in recent years.
Sentences in reviews, however, are usually classified independently, even
though they form part of a review's argumentative structure. Intuitively,
sentences in a review build and elaborate upon each other; knowledge of the
review structure and sentential context should thus inform the classification
of each sentence. We demonstrate this hypothesis for the task of aspect-based
sentiment analysis by modeling the interdependencies of sentences in a review
with a hierarchical bidirectional LSTM. We show that the hierarchical model
outperforms two non-hierarchical baselines, obtains results competitive with
the state-of-the-art, and outperforms the state-of-the-art on five
multilingual, multi-domain datasets without any hand-engineered features or
external resources.
</p>
{{{{ARTICLE_PARSER}}}}<p>This paper describes our deep learning-based approach to sentiment analysis
in Twitter as part of SemEval-2016 Task 4. We use a convolutional neural
network to determine sentiment and participate in all subtasks, i.e. two-point,
three-point, and five-point scale sentiment classification and two-point and
five-point scale sentiment quantification. We achieve competitive results for
two-point scale sentiment classification and quantification, ranking fifth and
a close fourth (third and second by alternative metrics) respectively despite
using only pre-trained embeddings that contain no sentiment information. We
achieve good performance on three-point scale sentiment classification, ranking
eighth out of 35, while performing poorly on five-point scale sentiment
classification and quantification. An error analysis reveals that this is due
to low expressiveness of the model to capture negative sentiment as well as an
inability to take into account ordinal information. We propose improvements in
order to address these and other issues.
</p>
{{{{ARTICLE_PARSER}}}}<p>This paper describes our deep learning-based approach to multilingual
aspect-based sentiment analysis as part of SemEval 2016 Task 5. We use a
convolutional neural network (CNN) for both aspect extraction and aspect-based
sentiment analysis. We cast aspect extraction as a multi-label classification
problem, outputting probabilities over aspects parameterized by a threshold. To
determine the sentiment towards an aspect, we concatenate an aspect vector with
every word embedding and apply a convolution over it. Our constrained system
(unconstrained for English) achieves competitive results across all languages
and domains, placing first or second in 5 and 7 out of 11 language-domain pairs
for aspect category detection (slot 1) and sentiment polarity (slot 3)
respectively, thereby demonstrating the viability of a deep learning-based
approach for multilingual aspect-based sentiment analysis.
</p>
{{{{ARTICLE_PARSER}}}}<p>More and more people are regularly using mobile and battery-powered handsets,
such as smartphones and tablets. At the same time, thanks to the technological
innovation and to the high user demands, those devices are integrating
extensive functionalities and developers are writing battery-draining apps,
which results in a surge of energy consumption of these devices. This scenario
leads many people to often look for opportunities to charge their devices at
public charging stations: the presence of such stations is already prominent
around public areas such as hotels, shopping malls, airports, gyms and museums,
and is expected to significantly grow in the future. While most of the time the
power comes for free, there is no guarantee that the charging station is not
maliciously controlled by an adversary, with the intention to exfiltrate data
from the devices that are connected to it.
</p>
<p>In this paper, we illustrate for the first time how an adversary could
leverage a maliciously controlled charging station to exfiltrate data from the
smartphone via a USB charging cable (i.e., without using the data transfer
functionality), controlling a simple app running on the device, and without
requiring any permission to be granted by the user to send data out of the
device. We show the feasibility of the proposed attack through a prototype
implementation in Android, which is able to send out potentially sensitive
information, such as IMEI, contacts' phone number, and pictures.
</p>
{{{{ARTICLE_PARSER}}}}<p>We consider lambda-Y-calculus as a non-interpreted functional programming
language: the result of the execution of a program is its normal form that can
be seen as the tree of calls to built-in operations. Weak monadic second-order
logic (wMSOL) is well suited to express properties of such trees. We give a
type system for ensuring that the result of the execution of a lambda-Y-program
satisfies a given wMSOL property. In order to prove soundness and completeness
of the system we construct a denotational semantics of lambda-Y-calculus that
is capable of computing properties expressed in wMSOL.
</p>
{{{{ARTICLE_PARSER}}}}<p>In the past few years, the use of smartphones has increased exponentially,
and so have the capabilities of such devices. Together with an increase in raw
processing power, modern smartphones are equipped with a wide variety of
sensors and expose an extensive set of API (Accessible Programming Interface).
These capabilities allow us to extract a wide spectrum of data that ranges from
information about the environment (e.g., position, orientation) to user habits
(e.g., which apps she uses and when), as well as about the status of the
operating system itself (e.g., memory, network adapters). This data can be
extremely valuable in many research fields such as user authentication,
intrusion detection and detection of information leaks. For these reasons,
researchers need to use a solid and reliable logging tool to collect data from
mobile devices.
</p>
<p>In this paper, we first survey the existing logging tools available on the
Android platform, comparing the features offered by different tools and their
impact on the system, and highlighting some of their shortcomings. Then, we
present DELTA - Data Extraction and Logging Tool for Android, which improves
the existing Android logging solutions in terms of flexibility, fine-grained
tuning capabilities, extensibility, and available set of logging features. We
performed a full implementation of DELTA and we run a thorough evaluation on
its performance. The results show that our tool has low impact on the
performance of the system, on battery consumption, and on user experience.
Finally, we make the DELTA source code and toolset available to the research
community.
</p>
{{{{ARTICLE_PARSER}}}}<p>Within the field of image and video recognition, the traditional approach is
a dataset split into fixed training and test partitions. However, the labelling
of the training set is time-consuming, especially as datasets grow in size and
complexity. Furthermore, this approach is not applicable to the home user, who
wants to intuitively group their media without tirelessly labelling the
content. Our interactive approach is able to iteratively cluster classes of
images and video. Our approach is based around the concept of an image
signature which, unlike a standard bag of words model, can express
co-occurrence statistics as well as symbol frequency. We efficiently compute
metric distances between signatures despite their inherent high dimensionality
and provide discriminative feature selection, to allow common and distinctive
elements to be identified from a small set of user labelled examples. These
elements are then accentuated in the image signature to increase similarity
between examples and pull correct classes together. By repeating this process
in an online learning framework, the accuracy of similarity increases
dramatically despite labelling only a few training examples. To demonstrate
that the approach is agnostic to media type and features used, we evaluate on
three image datasets (15 scene, Caltech101 and FG-NET), a mixed text and image
dataset (ImageTag), a dataset used in active learning (Iris) and on three
action recognition datasets (UCF11, KTH and Hollywood2). On the UCF11 video
dataset, the accuracy is 86.7% despite using only 90 labelled examples from a
dataset of over 1200 videos, instead of the standard 1122 training videos. The
approach is both scalable and efficient, with a single iteration over the full
UCF11 dataset of around 1200 videos taking approximately 1 minute on a standard
desktop machine.
</p>
{{{{ARTICLE_PARSER}}}}<p>Image classification is one of the main research problems in computer vision
and machine learning. Since in most real-world image classification
applications there is no control over how the images are captured, it is
necessary to consider the possibility that these images might be affected by
noise (e.g. sensor noise in a low-quality surveillance camera). In this paper
we analyse the impact of three different types of noise on descriptors
extracted by two widely used feature extraction methods (LBP and HOG) and how
denoising the images can help to mitigate this problem. We carry out
experiments on two different datasets and consider several types of noise,
noise levels, and denoising methods. Our results show that noise can hinder
classification performance considerably and make classes harder to separate.
Although denoising methods were not able to reach the same performance of the
noise-free scenario, they improved classification results for noisy data.
</p>
{{{{ARTICLE_PARSER}}}}<p>This paper shows the capability the alternating direction method of
multipliers (ADMM) has to track, in a distributed manner, the optimal down-link
beam-forming solution in a multiple input multiple output (MISO) multi-cell
network given a dynamic channel. Each time the channel changes, ADMM is allowed
to perform one algorithm iteration. In order to implement the proposed scheme,
the base stations are not required to exchange channel state information (CSI),
but will require to exchange interference values once. We show ADMM's tracking
ability in terms of the algorithm's Lyapunov function given that the primal and
dual solutions to the convex optimization problem at hand can be understood as
a continuous mapping from the problem's parameters. We show that this holds
true even considering that the problem looses strong convexity when it is made
distributed. We then show that these requirements hold for the down-link, and
consequently up-link, beam-forming case. Numerical examples corroborating the
theoretical findings are also provided.
</p>
{{{{ARTICLE_PARSER}}}}<p>Appearance of Bitcoin raise up evolution in currency. Blockchain database
also raise up possibilities to share important data between untrusted peers. In
this paper, we propose Arachneum, a decentralized, distributed, and
model-view-controller-based web service using blockchain and new privileges
model. Therefore, we can enjoy the freedom against censorship of government or
organizations, keep transparency of our web services, fork our web services,
and create/read/update/delete(CRUD) all model-view-controller(MVC) components
dynamically.
</p>
{{{{ARTICLE_PARSER}}}}<p>As an environment-friendly substitute for conventional fuel-powered vehicles,
electric vehicles (EVs) and their components have been widely developed and
deployed worldwide. The large-scale integration of EVs into power grid brings
both challenges and opportunities to the system performance. On one hand, the
load demand from EV charging imposes large impact on the stability and
efficiency of power grid. On the other hand, EVs could potentially act as
mobile energy storage systems to improve the power network performance, such as
load flattening, fast frequency control, and facilitating renewable energy
integration. Evidently, uncontrolled EV charging could lead to inefficient
power network operation or even security issues. This spurs enormous research
interests in designing charging coordination mechanisms. A key design challenge
here lies in the lack of complete knowledge of events that occur in the future.
Indeed, the amount of knowledge of future events significantly impacts the
design of efficient charging control algorithms. This article focuses on
introducing online EV charging scheduling techniques that deal with different
degrees of uncertainty and randomness of future knowledge. Besides, we
highlight the promising future research directions for EV charging control.
</p>
{{{{ARTICLE_PARSER}}}}<p>The assignment problem is one of the most well-studied settings in social
choice, matching, and discrete allocation. We consider the problem with the
additional feature that agents' preferences involve uncertainty. The setting
with uncertainty leads to a number of interesting questions including the
following ones. How to compute an assignment with the highest probability of
being Pareto optimal? What is the complexity of computing the probability that
a given assignment is Pareto optimal? Does there exist an assignment that is
Pareto optimal with probability one? We consider these problems under two
natural uncertainty models: (1) the lottery model in which each agent has an
independent probability distribution over linear orders and (2) the joint
probability model that involves a joint probability distribution over
preference profiles. For both of the models, we present a number of algorithmic
and complexity results.
</p>
{{{{ARTICLE_PARSER}}}}<p>The security infrastructure is ill-equipped to detect and deter the smuggling
of non-explosive devices that enable terror attacks such as those recently
perpetrated in western Europe. The detection of so-called \"small metallic
threats\" (SMTs) in cargo containers currently relies on statistical risk
analysis, intelligence reports, and visual inspection of X-ray images by
security officers. The latter is very slow and unreliable due to the difficulty
of the task: objects potentially spanning less than 50 pixels have to be
detected in images containing more than 2 million pixels against very complex
and cluttered backgrounds. In this contribution, we demonstrate for the first
time the use of Convolutional Neural Networks (CNNs), a type of Deep Learning,
to automate the detection of SMTs in fullsize X-ray images of cargo containers.
Novel approaches for dataset augmentation allowed to train CNNs from-scratch
despite the scarcity of data available. We report fewer than 6% false alarms
when detecting 90% SMTs synthetically concealed in stream-of-commerce images,
which corresponds to an improvement of over an order of magnitude over
conventional approaches such as Bag-of-Words (BoWs). The proposed scheme offers
potentially super-human performance for a fraction of the time it would take
for a security officers to carry out visual inspection (processing time is
approximately 3.5s per container image).
</p>
{{{{ARTICLE_PARSER}}}}<p>Online harassment has been a problem to a greater or lesser extent since the
early days of the internet. Previous work has applied anti-spam techniques like
machine-learning based text classification (Reynolds, 2011) to detecting
harassing messages. However, existing public datasets are limited in size, with
labels of varying quality. The #HackHarassment initiative (an alliance of 1
tech companies and NGOs devoted to fighting bullying on the internet) has begun
to address this issue by creating a new dataset superior to its predecssors in
terms of both size and quality. As we (#HackHarassment) complete further rounds
of labelling, later iterations of this dataset will increase the available
samples by at least an order of magnitude, enabling corresponding improvements
in the quality of machine learning models for harassment detection. In this
paper, we introduce the first models built on the #HackHarassment dataset v1.0
(a new open dataset, which we are delighted to share with any interested
researcherss) as a benchmark for future research.
</p>
{{{{ARTICLE_PARSER}}}}<p>Last year, at least 30,000 scientific papers used the Kohn-Sham scheme of
density functional theory to solve electronic structure problems in a wide
variety of scientific fields, ranging from materials science to biochemistry to
astrophysics. Machine learning holds the promise of learning the kinetic energy
functional via examples, by-passing the need to solve these equations. This
should yield substantial savings in computer time, allowing either larger
systems or longer time-scales to be tackled. Attempts to machine-learn this
functional have been limited by the need to find its derivative. The present
work overcomes this difficulty, by learning the density-potential map directly.
Both the improved accuracy and lower computational cost is demonstrated on DFT
calculations of small molecules.
</p>
{{{{ARTICLE_PARSER}}}}<p>Tracking Facial Points in unconstrained videos is challenging due to the
non-rigid deformation that changes over time. In this paper, we propose to
exploit incremental learning for person-specific alignment in wild conditions.
Our approach takes advantage of part-based representation and cascade
regression for robust and efficient alignment on each frame. Unlike existing
methods that usually rely on models trained offline, we incrementally update
the representation subspace and the cascade of regressors in a unified
framework to achieve personalized modeling on the fly. To alleviate the
drifting issue, the fitting results are evaluated using a deep neural network,
where well-aligned faces are picked out to incrementally update the
representation and fitting models. Both image and video datasets are employed
to valid the proposed method. The results demonstrate the superior performance
of our approach compared with existing approaches in terms of fitting accuracy
and efficiency.
</p>
{{{{ARTICLE_PARSER}}}}<p>Scientists are drawn to synchrotrons and accelerator based light sources
because of their brightness, coherence and flux. The rate of improvement in
brightness and detector technology has outpaced Moore's law growth seen for
computers, networks, and storage, and is enabling novel observations and
discoveries with faster frame rates, larger fields of view, higher resolution,
and higher dimensionality. Here we present an integrated software/algorithmic
framework designed to capitalize on high throughput experiments, and describe
the streamlined processing pipeline of ptychography data analysis. The pipeline
provides throughput, compression, and resolution as well as rapid feedback to
the microscope operators.
</p>
{{{{ARTICLE_PARSER}}}}<p>Energy efficiency is a key requirement for the Internet of Things, as many
sensors are expected to be completely stand-alone and able to run for years
between battery replacements. Data compression aims at saving some energy by
reducing the volume of data sent over the network, but also affects the quality
of the received information. In this work, we formulate an optimization problem
to jointly optimize the source coding and transmission strategies for
time-varying channels and sources, with the twofold goal of extending the
network lifetime and granting low distortion levels. We propose an offline
optimal policy that allocates both energy and transmission parameters (i.e.,
times and powers) in a scalable network with a dynamic Time Division Multiple
Access (TDMA)-based access scheme.
</p>
{{{{ARTICLE_PARSER}}}}<p>If you were to open your own cafe, would you not want to effortlessly
identify the most suitable location to set up your shop? Choosing an optimal
physical location is a critical decision for numerous businesses, as many
factors contribute to the final choice of the location. In this paper, we seek
to address the issue by investigating the use of publicly available Facebook
Pages data---which include user check-ins, types of business, and business
locations---to evaluate a user-selected physical location with respect to a
type of business. Using a dataset of 20,877 food businesses in Singapore, we
conduct analysis of several key factors including business categories,
locations, and neighboring businesses. From these factors, we extract a set of
relevant features and develop a robust predictive model to estimate the
popularity of a business location. Our experiments have shown that the
popularity of neighboring business contributes the key features to perform
accurate prediction. We finally illustrate the practical usage of our proposed
approach via an interactive web application system.
</p>
{{{{ARTICLE_PARSER}}}}<p>In the undersampled phase retrieval problem, the goal is to recover an
$N$-dimensional complex signal $\mathbf{x}$ from only $M&lt;N$ noisy intensity
measurements without phase information. This problem has drawn a lot of
attention to reduce the number of required measurements since a recent theory
established that $M\approx4N$ intensity measurements are necessary and
sufficient to recover a generic signal $\mathbf{x}$. In this paper, we propose
to exploit the sparsity in the original signal and develop low-complexity
algorithms with superior performance based on the majorization-minimization
(MM) framework. The proposed algorithms are preferred to existing benchmark
methods since at each iteration a simple surrogate problem is solved with a
closed-form solution that monotonically decreases the original objective
function. Experimental results validate that our algorithms outperform existing
up-to-date methods in terms of recovery probability and accuracy, under the
same settings.
</p>
{{{{ARTICLE_PARSER}}}}<p>This work addresses decentralized online optimization in non-stationary
environments. A network of agents aim to track the minimizer of a global
time-varying convex function. The minimizer evolves according to a known
dynamics corrupted by an unknown, unstructured noise. At each time, the global
function can be cast as a sum of a finite number of local functions, each of
which is assigned to one agent in the network. Moreover, the local functions
become available to agents sequentially, and agents do not have a prior
knowledge of the future cost functions. Therefore, agents must communicate with
each other to build an online approximation of the global function. We propose
a decentralized variation of the celebrated Mirror Descent, developed by
Nemirovksi and Yudin. Using the notion of Bregman divergence in lieu of
Euclidean distance for projection, Mirror Descent has been shown to be a
powerful tool in large-scale optimization. Our algorithm builds on Mirror
Descent, while ensuring that agents perform a consensus step to follow the
global function and take into account the dynamics of the global minimizer. To
measure the performance of the proposed online algorithm, we compare it to its
offline counterpart, where the global functions are available a priori. The gap
between the two is called dynamic regret. We establish a regret bound that
scales inversely in the spectral gap of the network, and more notably it
represents the deviation of minimizer sequence with respect to the given
dynamics. We then show that our results subsume a number of results in
distributed optimization. We demonstrate the application of our method to
decentralized tracking of dynamic parameters and verify the results via
numerical experiments.
</p>
{{{{ARTICLE_PARSER}}}}<p>Spoken dialogue systems allow humans to interact with machines using natural
speech. As such, they have many benefits. By using speech as the primary
communication medium, a computer interface can facilitate swift, human-like
acquisition of information. In recent years, speech interfaces have become ever
more popular, as is evident from the rise of personal assistants such as Siri,
Google Now, Cortana and Amazon Alexa. Recently, data-driven machine learning
methods have been applied to dialogue modelling and the results achieved for
limited-domain applications are comparable to or outperform traditional
approaches. Methods based on Gaussian processes are particularly effective as
they enable good models to be estimated from limited training data.
Furthermore, they provide an explicit estimate of the uncertainty which is
particularly useful for reinforcement learning. This article explores the
additional steps that are necessary to extend these methods to model multiple
dialogue domains. We show that Gaussian process reinforcement learning is an
elegant framework that naturally supports a range of methods, including prior
knowledge, Bayesian committee machines and multi-agent learning, for
facilitating extensible and adaptable dialogue systems.
</p>
{{{{ARTICLE_PARSER}}}}<p>We describe a new quantifier elimination algorithm for real closed fields
based on Thom encoding and sign determination. The complexity of this algorithm
is elementary recursive and its proof of correctness is completely algebraic.
In particular, the notion of connected components of semialgebraic sets is not
used.
</p>
{{{{ARTICLE_PARSER}}}}<p>In both query and communication complexity, we give separations between the
class NISZK, containing those problems with non-interactive statistical zero
knowledge proof systems, and the class UPP, containing those problems with
randomized algorithms with unbounded error. These results significantly improve
on earlier query separations of Vereschagin [Ver95] and Aaronson [Aar12] and
earlier communication complexity separations of Klauck [Kla11] and Razborov and
Sherstov [RS10]. In addition, our results imply an oracle relative to which the
class NISZK is not contained in PP. Equivalently, postselected quantum
computers cannot break SZK or NISZK in a black-box manner. This answers an open
question of Watrous from 2002 [Aar].
</p>
<p>The technical core of our result is a stronger hardness amplification theorem
for approximate degree, which roughly says that composing the gapped-majority
function with any function of high approximate degree yields a function with
high threshold degree. Using our techniques, we additionally prove an oracle
separation between perfect zero knowledge (PZK) and its complement (coPZK). We
also show an oracle relative to which NISZK (or SZK) is not contained in PZK.
</p>
<p>We prove a number of implications of these results, which may be of
independent interest. Specifically, our oracle separation implies that certain
parameters of the Polarization Lemma of Sahai and Vadhan [SV03] cannot be much
improved in a black-box manner. Additionally, it implies new lower bounds for
property testing algorithms with error probability arbitrarily close to 1/2.
Finally, our results have implications for delegating computation; they imply
that two-message protocols in the streaming interactive proofs model of Cormode
et al. [CTY11] are surprisingly powerful in the sense that, with just
logarithmic cost, they can compute functions outside of UPP^CC.
</p>
{{{{ARTICLE_PARSER}}}}<p>We present an efficient variational integrator for multibody systems.
Variational integrators reformulate the equations of motion for multibody
systems as discrete Euler-Lagrange (DEL) equations, transforming forward
integration into a root-finding problem for the DEL equations. Variational
integrators have been shown to be more robust and accurate in preserving
fundamental properties of systems, such as momentum and energy, than many
frequently used numerical integrators. However, state-of-the-art algorithms
suffer from $O(n^3)$ complexity, which is prohibitive for articulated multibody
systems with a large number of degrees of freedom, $n$, in generalized
coordinates. Our key contribution is to derive a recursive algorithm that
evaluates DEL equations in $O(n)$, which scales up well for complex multibody
systems such as humanoid robots. Inspired by recursive Newton-Euler algorithm,
our key insight is to formulate DEL equation individually for each body rather
than for the entire system. Furthermore, we introduce a new quasi-Newton method
that exploits the impulse-based dynamics algorithm, which is also $O(n)$, to
avoid the expensive Jacobian inversion in solving DEL equations. We demonstrate
scalability and efficiency, as well as extensibility to holonomic constraints
through several case studies.
</p>
{{{{ARTICLE_PARSER}}}}<p>We introduce a Markov chain for sampling from the uniform distribution on a
Riemannian manifold $\mathcal{M}$, which we call the $\textit{geodesic walk}$.
We prove that the mixing time of this walk on any manifold with positive
sectional curvature $C_{x}(u,v)$ bounded both above and below by $0 &lt;
\mathfrak{m}_{2} \leq C_{x}(u,v) \leq \mathfrak{M}_2 &lt; \infty$ is
$\mathcal{O}^*\left(\frac{\mathfrak{M}_2}{\mathfrak{m}_2}\right)$. In
particular, this bound on the mixing time does not depend explicitly on the
dimension of the manifold. In the special case that $\mathcal{M}$ is the
boundary of a convex body, we give an explicit and computationally tractable
algorithm for approximating the exact geodesic walk. As a consequence, we
obtain an algorithm for sampling uniformly from the surface of a convex body
that has running time bounded solely in terms of the curvature of the body.
</p>
{{{{ARTICLE_PARSER}}}}<p>Spectral methods are popular in detecting global structures in the given data
that can be represented as a matrix. However when the data matrix is sparse or
noisy, classic spectral methods usually fail to work, due to localization of
eigenvectors (or singular vectors) induced by the sparsity or noise. In this
work, we propose a general method to solve the localization problem by learning
a regularization matrix from the localized eigenvectors. Using matrix
perturbation analysis, we demonstrate that the learned regularizations suppress
down the eigenvalues associated with localized eigenvectors and enable us to
recover the informative eigenvectors representing the global structure. We show
applications of our method in several inference problems: community detection
in networks, clustering from pairwise similarities, rank estimation and matrix
completion problems. Using extensive experiments, we illustrate that our method
solves the localization problem and works down to the theoretical detectability
limits in different kinds of synthetic data. This is in contrast with existing
spectral algorithms based on data matrix, non-backtracking matrix, Laplacians
and those with rank-one regularizations, which perform poorly in the sparse
case with noise.
</p>
{{{{ARTICLE_PARSER}}}}<p>We present a scalable approach for semi-supervised learning on
graph-structured data that is based on an efficient variant of convolutional
neural networks which operate directly on graphs. We motivate the choice of our
convolutional architecture via a localized first-order approximation of
spectral graph convolutions. Our model scales linearly in the number of graph
edges and learns hidden layer representations that encode both local graph
structure and features of nodes. In a number of experiments on citation
networks and on a knowledge graph dataset we demonstrate that our approach
outperforms related methods by a significant margin.
</p>
{{{{ARTICLE_PARSER}}}}<p>In this letter, we give a concise, closed-form expression for the
differential entropy of the sum of two independent, non-identically-distributed
exponential random variables. The derivation is straightforward, but such a
concise entropy has not been previously given in the literature. The usefulness
of the expression is demonstrated with examples.
</p>
{{{{ARTICLE_PARSER}}}}<p>We give an explicit definition of decentralization and show you that
decentralization is almost impossible for the current stage and Bitcoin is the
first truly noncentralized currency in the currency history. We propose a new
framework of noncentralized cryptocurrency system with an assumption of the
existence of a weak adversary for a bank alliance. It abandons the mining
process and blockchain, and removes history transactions from data
synchronization. We propose a consensus algorithm named Converged Consensus for
a noncentralized cryptocurrency system.
</p>
{{{{ARTICLE_PARSER}}}}<p>A word $w$ of letters on edges of underlying graph of deterministic finite
automaton (DFA) is called a synchronizing word if $w$ sends all states of the
automaton to a unique state.
</p>
<p>C. L. Liu and A. E. Laemmel in 1963, J. \v{C}erny in 1964 discovered a
sequence of $n$-state complete DFA possessing a minimal synchronizing word of
length $(n-1)^2$.
</p>
<p>The \v{C}erny conjecture claims that it is also the upper bound on the length
of such a word for a complete DFA. The problem has motivated great and
constantly growing number of investigations and generalizations and together
with the Road Coloring problem this simple-looking conjecture is arguably the
most fascinating and longstanding open problem in the combinatorial theory of
finite automata.
</p>
<p>The best upper bound for the length of the minimal synchronizing word
$(n^3-n)/6$ was not changed since 1982.
</p>
<p>Some properties of synchronization are found. An effort to prove the
\v{C}erny conjecture is presented.
</p>
{{{{ARTICLE_PARSER}}}}<p>Schelling's model of segregation, first described in 1969, has become one of
the best known models of self-organising behaviour. While Schelling's explicit
concern was to understand the mechanisms underlying racial segregation in large
cities from a game theoretic perspective, the model should be seen as one of a
family, arising in fields as diverse as statistical mechanics, neural networks
and the social sciences, and which are concerned with interacting populations
situated on network structures. Despite extensive study, however, the
(unperturbed) Schelling model has largely resisted rigorous analysis, prior
results in the literature generally pertaining to variants of the model in
which noise is introduced into the dynamics of the system, the resulting model
then being amenable to standard techniques from statistical mechanics or
stochastic evolutionary game theory. A series of recent papers (one by Brandt,
Immorlica, Kamath, and Kleinberg, and two by the authors), has seen the first
rigorous analysis of the one dimensional version of the unperturbed model. Here
we provide the first rigorous analysis of the two and three dimensional
unperturbed models, establishing most of the phase diagram, and answering a
challenge from a recent paper by Brandt, Immorlica, Kamath, and Kleinberg.
</p>
{{{{ARTICLE_PARSER}}}}<p>$k$-submodular functions, introduced by Huber and Kolmogorov, are functions
defined on $\{0, 1, 2, \dots, k\}^n$ satisfying certain submodular-type
inequalities. $k$-submodular functions typically arise as relaxations of
NP-hard problems, and the relaxations by $k$-submodular functions play key
roles in design of efficient, approximation, or fixed-parameter tractable
algorithms. Motivated by this, we consider the following problem: Given a
function $f : \{1, 2, \dots, k\}^n \rightarrow \mathbb{R} \cup \{\infty\}$,
determine whether $f$ is extended to a $k$-submodular function $g : \{0, 1, 2,
\dots, k\}^n \rightarrow \mathbb{R} \cup \{\infty\}$, where $g$ is called a
$k$-submodular relaxation of $f$.
</p>
<p>We give a polymorphic characterization of those functions which admit a
$k$-submodular relaxation, and also give a combinatorial $O((k^n)^2)$-time
algorithm to find a $k$-submodular relaxation or establish that a
$k$-submodular relaxation does not exist. Our algorithm has interesting
properties: (1) If the input function is integer valued, then our algorithm
outputs a half-integral relaxation, and (2) if the input function is binary,
then our algorithm outputs the unique optimal relaxation. We present
applications of our algorithm to valued constraint satisfaction problems.
</p>
{{{{ARTICLE_PARSER}}}}<p>Given a static reference string $R$ and a source string $S$, a relative
compression of $S$ with respect to $R$ is an encoding of $S$ as a sequence of
references to substrings of $R$. Relative compression schemes are a classic
model of compression and have recently proved very successful for compressing
highly-repetitive massive data sets such as genomes and web-data. We initiate
the study of relative compression in a dynamic setting where the compressed
source string $S$ is subject to edit operations. The goal is to maintain the
compressed representation compactly, while supporting edits and allowing
efficient random access to the (uncompressed) source string. We present new
data structures that achieve optimal time for updates and queries while using
space linear in the size of the optimal relative compression, for nearly all
combinations of parameters. We also present solutions for restricted and
extended sets of updates. To achieve these results, we revisit the dynamic
partial sums problem and the substring concatenation problem. We present new
optimal or near optimal bounds for these problems. Plugging in our new results
we also immediately obtain new bounds for the string indexing for patterns with
wildcards problem and the dynamic text and static pattern matching problem.
</p>
{{{{ARTICLE_PARSER}}}}<p>Unlike many complex networks studied in the literature, social networks
rarely exhibit unanimous behavior, or consensus. This requires a development of
mathematical models that are sufficiently simple to be examined and capture, at
the same time, the complex behavior of real social groups, where opinions and
actions related to them may form clusters of different size. One such model,
proposed by Friedkin and Johnsen, extends the idea of conventional consensus
algorithm (also referred to as the iterative opinion pooling) to take into
account the actors' prejudices, caused by some exogenous factors and leading to
disagreement in the final opinions.
</p>
<p>In this paper, we offer a novel multidimensional extension, describing the
evolution of the agents' opinions on several topics. Unlike the existing
models, these topics are interdependent, and hence the opinions being formed on
these topics are also mutually dependent. We rigorous examine stability
properties of the proposed model, in particular, convergence of the agents'
opinions. Although our model assumes synchronous communication among the
agents, we show that the same final opinions may be reached \"on average\" via
asynchronous gossip-based protocols.
</p>
{{{{ARTICLE_PARSER}}}}<p>Policy gradient methods are an appealing approach in reinforcement learning
because they directly optimize the cumulative reward and can straightforwardly
be used with nonlinear function approximators such as neural networks. The two
main challenges are the large number of samples typically required, and the
difficulty of obtaining stable and steady improvement despite the
nonstationarity of the incoming data. We address the first challenge by using
value functions to substantially reduce the variance of policy gradient
estimates at the cost of some bias, with an exponentially-weighted estimator of
the advantage function that is analogous to TD(lambda). We address the second
challenge by using trust region optimization procedure for both the policy and
the value function, which are represented by neural networks.
</p>
<p>Our approach yields strong empirical results on highly challenging 3D
locomotion tasks, learning running gaits for bipedal and quadrupedal simulated
robots, and learning a policy for getting the biped to stand up from starting
out lying on the ground. In contrast to a body of prior work that uses
hand-crafted policy representations, our neural network policies map directly
from raw kinematics to joint torques. Our algorithm is fully model-free, and
the amount of simulated experience required for the learning tasks on 3D bipeds
corresponds to 1-2 weeks of real time.
</p>
{{{{ARTICLE_PARSER}}}}<p>The mutual information between two jointly distributed random variables $X$
and $Y$ is a functional of the joint distribution $P_{XY},$ which is sometimes
difficult to handle or estimate. A coarser description of the statistical
behavior of $(X,Y)$ is given by the marginal distributions $P_X, P_Y$ and the
adjacency relation induced by the joint distribution, where $x$ and $y$ are
adjacent if $P(x,y)&gt;0$. We derive a lower bound on the mutual information in
terms of these entities. The bound is obtained by viewing the channel from $X$
to $Y$ as a probability distribution on a set of possible actions, where an
action determines the output for any possible input, and is independently
drawn. We also provide an alternative proof based on convex optimization, that
yields a generally tighter bound. Finally, we derive an upper bound on the
mutual information in terms of adjacency events between the action and the pair
$(X,Y)$, where in this case an action $a$ and a pair $(x,y)$ are adjacent if
$y=a(x)$. As an example, we apply our bounds to the binary deletion channel and
show that for the special case of an i.i.d. input distribution and a range of
deletion probabilities, our lower and upper bounds both outperform the best
known bounds for the mutual information.
</p>
{{{{ARTICLE_PARSER}}}}<p>Randomness extractors, widely used in classical and quantum cryptography and
other fields of computer science, e.g., derandomization, are functions which
generate almost uniform randomness from weak sources of randomness. In the
quantum setting one must take into account the quantum side information held by
an adversary which might be used to break the security of the extractor. In the
case of seeded extractors the presence of quantum side information has been
extensively studied. For multi-source extractors one can easily see that high
conditional min-entropy is not sufficient to guarantee security against
arbitrary side information, even in the classical case. Hence, the interesting
question is under which models of (both quantum and classical) side information
multi-source extractors remain secure. In this work we suggest a natural model
of side information, which we call the Markov model, and prove that any
multi-source extractor remains secure in the presence of quantum side
information of this type (albeit with weaker parameters). This improves on
previous results in which more restricted models were considered and the
security of only some types of extractors was shown.
</p>
{{{{ARTICLE_PARSER}}}}<p>Many recent algorithms for approximate model counting are based on a
reduction to combinatorial searches over random subsets of the space defined by
parity or XOR constraints. Long parity constraints (involving many variables)
provide strong theoretical guarantees but are computationally difficult. Short
parity constraints are easier to solve but have weaker statistical properties.
It is currently not known how long these parity constraints need to be. We
close the gap by providing matching necessary and sufficient conditions on the
required asymptotic length of the parity constraints. Further, we provide a new
family of lower bounds and the first non-trivial upper bounds on the model
count that are valid for arbitrarily short XORs. We empirically demonstrate the
effectiveness of these bounds on model counting benchmarks and in a
Satisfiability Modulo Theory (SMT) application motivated by the analysis of
contingency tables in statistics.
</p>
{{{{ARTICLE_PARSER}}}}<p>Hierarchical temporal memory (HTM) is an emerging machine learning algorithm,
with the potential to provide a means to perform predictions on spatiotemporal
data. The algorithm, inspired by the neocortex, currently does not have a
comprehensive mathematical framework. This work brings together all aspects of
the spatial pooler (SP), a critical learning component in HTM, under a single
unifying framework. The primary learning mechanism is explored, where a maximum
likelihood estimator for determining the degree of permanence update is
proposed. The boosting mechanisms are studied and found to be only relevant
during the initial few iterations of the network. Observations are made
relating HTM to well-known algorithms such as competitive learning and
attribute bagging. Methods are provided for using the SP for classification as
well as dimensionality reduction. Empirical evidence verifies that given the
proper parameterizations, the SP may be used for feature learning.
</p>
{{{{ARTICLE_PARSER}}}}<p>This paper addresses the correspondence between linear inequalities of
Shannon entropy and differential entropy for sums of independent group-valued
random variables. We show that any balanced (with the sum of coefficients being
zero) linear inequality of Shannon entropy holds if and only if its
differential entropy counterpart also holds; moreover, any linear inequality
for differential entropy must be balanced. In particular, our result shows that
recently proved differential entropy inequalities by Kontoyiannis and Madiman
\cite{KM14} can be deduced from their discrete counterparts due to Tao
\cite{Tao10} in a unified manner. Generalizations to certain abelian groups are
also obtained.
</p>
<p>Our proof of extending inequalities of Shannon entropy to differential
entropy relies on a result of R\'enyi \cite{Renyi59} which relates the Shannon
entropy of a finely discretized random variable to its differential entropy and
also helps in establishing the entropy of the sum of quantized random variables
is asymptotically equal to that of the quantized sum; the converse uses the
asymptotics of the differential entropy of convolutions with weak additive
noise.
</p>
{{{{ARTICLE_PARSER}}}}<p>In this paper we presented a lattice Boltzmann with square grid for
compressible flow problems. Triple level velocity is considered for each cell.
Migration step use discrete velocity but continuous parameters are utilized to
calculate density, velocity, and energy. So, we called this semi-discrete
method. To evaluate the performance of the method the well-known shock tube
problem is solved, using 1-D and 2-D version of the lattice Boltzmann method.
The results of these versions are compared with each other and with the results
of the analytical solution.
</p>
{{{{ARTICLE_PARSER}}}}<p>The cylindrically converging shock wave was numerically simulated by solving
the Euler equations in cylindrical coordinates with TVD scheme and MUSCL
approach, using Roe's approximate Riemann solver and super-bee nonlinear
limiter. The present study used the in house code developed for this purpose.
The behavior of the solution in the vicinity of axis is investigated and the
results of the numerical solution are compared with the computed data given by
Payne, Lapidus, Abarbanel, and Goldberg, Sod, and Leutioff et al.
</p>
{{{{ARTICLE_PARSER}}}}<p>We consider the task of dimensional emotion recognition on video data using
deep learning. While several previous methods have shown the benefits of
training temporal neural network models such as recurrent neural networks
(RNNs) on hand-crafted features, few works have considered combining
convolutional neural networks (CNNs) with RNNs. In this work, we present a
system that performs emotion recognition on video data using both CNNs and
RNNs, and we also analyze how much each neural network component contributes to
the system's overall performance. We present our findings on videos from the
Audio/Visual+Emotion Challenge (AV+EC2015). In our experiments, we analyze the
effects of several hyperparameters on overall performance while also achieving
superior performance to the baseline and other competing methods.
</p>
{{{{ARTICLE_PARSER}}}}<p>\emph{Security games} have been found to be useful and widely considered by
the major security agencies. These games include two players - a defender, an
attacker, and a set of targets. The key practical elements are that (i) the
attacker can simultaneously attack multiple targets, and (ii) different targets
exhibits various types of dependency, which depends on the applications being
protected (e.g., protection of critical infrastructure IT and supply chain
network security, etc.). However, previous models and algorithms fail to scale
up and little is known of the computational complexity of these problem,
especially when there exist dependencies between targets. In this paper, we
investigate a general security game where the utility function is defined on a
collection of subsets of all targets, and we provide a novel theoretical
framework to show how to compactly represent such game, efficiently compute the
optimal (minimax) strategies and characterize the complexity of this problem.
We apply our theoretical framework to the \emph{network security game}. In some
settings, we provide a polynomial-time algorithm for computing optimal
strategies; in other settings, we prove that the problem is NP-hard.
</p>
{{{{ARTICLE_PARSER}}}}<p>We study two-player games played on the infinite graph of sentential forms
induced by a context-free grammar (that comes with an ownership partitioning of
the non-terminals). The winning condition is inclusion of the derived terminal
word in the language of a finite automaton. Our contribution is a new algorithm
to decide the winning player and to compute her strategy. It is based on a
novel representation of all plays starting in a non-terminal. The
representation uses the domain of Boolean formulas over the transition monoid
of the target automaton. The elements of the monoid are essentially procedure
summaries, and our approach can be seen as the first summary-based algorithm
for the synthesis of recursive programs. We show that our algorithm has optimal
(doubly exponential) time complexity, that it is compatible with recent
antichain optimizations, and that it admits a lazy evaluation strategy. Our
preliminary experiments indeed show encouraging results, indicating a speed up
of three orders of magnitude over a competitor.
</p>
{{{{ARTICLE_PARSER}}}}<p>In this paper, we initiate a principled study of how the generalization
properties of approximate differential privacy can be used to perform adaptive
hypothesis testing, while giving statistically valid $p$-value corrections. We
do this by observing that the guarantees of algorithms with bounded approximate
max-information are sufficient to correct the $p$-values of adaptively chosen
hypotheses, and then by proving that algorithms that satisfy
$(\epsilon,\delta)$-differential privacy have bounded approximate max
information when their inputs are drawn from a product distribution. This
substantially extends the known connection between differential privacy and
max-information, which previously was only known to hold for (pure)
$(\epsilon,0)$-differential privacy. It also extends our understanding of
max-information as a partially unifying measure controlling the generalization
properties of adaptive data analyses. We also show a lower bound, proving that
(despite the strong composition properties of max-information), when data is
drawn from a product distribution, $(\epsilon,\delta)$-differentially private
algorithms can come first in a composition with other algorithms satisfying
max-information bounds, but not necessarily second if the composition is
required to itself satisfy a nontrivial max-information bound. This, in
particular, implies that the connection between
$(\epsilon,\delta)$-differential privacy and max-information holds only for
inputs drawn from product distributions, unlike the connection between
$(\epsilon,0)$-differential privacy and max-information.
</p>
{{{{ARTICLE_PARSER}}}}<p>Local covariant feature detection, namely the problem of extracting viewpoint
invariant features from images, has so far largely resisted the application of
machine learning techniques. In this paper, we propose the first fully general
formulation for learning local covariant feature detectors. We propose to cast
detection as a regression problem, enabling the use of powerful regressors such
as deep neural networks. We then derive a covariance constraint that can be
used to automatically learn which visual structures provide stable anchors for
local feature detection. We support these ideas theoretically, proposing a
novel analysis of local features in term of geometric transformations, and we
show that all common and many uncommon detectors can be derived in this
framework. Finally, we present empirical results on translation and rotation
covariant detectors on standard feature benchmarks, showing the power and
flexibility of the framework.
</p>
{{{{ARTICLE_PARSER}}}}<p>The alternating direction method of multipliers (ADMM) is a versatile tool
for solving a wide range of constrained optimization problems, with
differentiable or non-differentiable objective functions. Unfortunately, its
performance is highly sensitive to a penalty parameter, which makes ADMM often
unreliable and hard to automate for a non-expert user. We tackle this weakness
of ADMM by proposing a method to adaptively tune the penalty parameters to
achieve fast convergence. The resulting adaptive ADMM (AADMM) algorithm,
inspired by the successful Barzilai-Borwein spectral method for gradient
descent, yields fast convergence and relative insensitivity to the initial
stepsize and problem scaling.
</p>
{{{{ARTICLE_PARSER}}}}<p>In this paper, we propose Intention from Motion, a new paradigm for action
prediction where, without using any contextual information, we can predict
human intentions all originating from the same motor act, non specific of the
following performed action. To investigate such novel problem, we designed a
proof of concept consisting in a new multi-modal dataset of motion capture
marker 3D data and 2D video sequences where, by only analysing very similar
movements in both training and test phases, we are able to predict the
underlying intention, i.e., the future, never observed, action. Through an
extended baseline assessment, we evaluate the proposed dataset employing
state-of-the-art 3D and 2D action recognition techniques, while using fusion
methods to fully exploit its multi-modal nature. We also report comparative
benchmarking tests using existing action prediction pipelines, showing that
such algorithms can not deal well with the proposed intention prediction
problem. In the end, we demonstrate that intentions can be predicted in a
reliable way, ultimately devising a novel classification technique to infer the
intention from kinematic information only.
</p>
{{{{ARTICLE_PARSER}}}}<p>In this study, we report on techniques and analyses that enable us to capture
Internet-wide activity at individual IP address-level granularity by relying on
server logs of a large commercial content delivery network (CDN) that serves
close to 3 trillion HTTP requests on a daily basis. Across the whole of 2015,
these logs recorded client activity involving 1.2 billion unique IPv4
addresses, the highest ever measured, in agreement with recent estimates.
Monthly client IPv4 address counts showed constant growth for years prior, but
since 2014, the IPv4 count has stagnated while IPv6 counts have grown. Thus, it
seems we have entered an era marked by increased complexity, one in which the
sole enumeration of active IPv4 addresses is of little use to characterize
recent growth of the Internet as a whole.
</p>
<p>With this observation in mind, we consider new points of view in the study of
global IPv4 address activity. Our analysis shows significant churn in active
IPv4 addresses: the set of active IPv4 addresses varies by as much as 25% over
the course of a year. Second, by looking across the active addresses in a
prefix, we are able to identify and attribute activity patterns to network
restructurings, user behaviors, and, in particular, various address assignment
practices. Third, by combining spatio-temporal measures of address utilization
with measures of traffic volume, and sampling-based estimates of relative host
counts, we present novel perspectives on worldwide IPv4 address activity,
including empirical observation of under-utilization in some areas, and
complete utilization, or exhaustion, in others.
</p>
{{{{ARTICLE_PARSER}}}}<p>As alignment links are not given between English sentences and Abstract
Meaning Representation (AMR) graphs in the AMR annotation, automatic alignment
becomes indispensable for training an AMR parser. Previous studies formalize it
as a string-to-string problem, and solve it in an unsupervised way. In this
paper, we formalize it as a syntax-based alignment problem, and solve it in a
supervised manner based on the syntax trees. Experiments verify the
effectiveness of the proposed method.
</p>
{{{{ARTICLE_PARSER}}}}<p>Interactive theorem provers, like Isabelle, include various automatic tools
for finding proofs under certain conditions. However, for each conjecture,
knowing which automation to use, and how to tweak its parameters, is currently
labour intensive. We have developed a language, PSL, designed to capture high
level proof strategies. PSL offloads the construction of human-readable
fast-to-replay proof scripts to automatic search, making use of search-time
information about each conjecture. Our preliminary evaluations show that PSL
reduces the labour cost of interactive theorem proving.
</p>
{{{{ARTICLE_PARSER}}}}<p>Distributed Denial-of-Service (DDoS) attacks are usually launched through the
$botnet$, an \"army\" of compromised nodes hidden in the network. Inferential
tools for DDoS mitigation should accordingly enable an early and reliable
discrimination of the normal users from the compromised ones. Unfortunately,
the recent emergence of attacks performed at the application layer has
multiplied the number of possibilities that a botnet can exploit to conceal its
malicious activities. New challenges arise, which cannot be addressed by simply
borrowing the tools that have been successfully applied so far to earlier DDoS
paradigms. In this work, we offer basically three contributions: $i)$ we
introduce an abstract model for the aforementioned class of attacks, where the
botnet emulates normal traffic by continually learning admissible patterns from
the environment; $ii)$ we devise an inference algorithm that is shown to
provide a consistent (i.e., converging to the true solution as time progresses)
estimate of the botnet possibly hidden in the network; and $iii)$ we verify the
validity of the proposed inferential strategy over $real$ network traces.
</p>
{{{{ARTICLE_PARSER}}}}<p>Non-intrusive inspection systems based on X-ray radiography techniques are
routinely used at transport hubs to ensure the conformity of cargo content with
the supplied shipping manifest. As trade volumes increase and regulations
become more stringent, manual inspection by trained operators is less and less
viable due to low throughput. Machine vision techniques can assist operators in
their task by automating parts of the inspection workflow. Since cars are
routinely involved in trafficking, export fraud, and tax evasion schemes, they
represent an attractive target for automated detection and flagging for
subsequent inspection by operators. In this contribution, we describe a method
for the detection of cars in X-ray cargo images based on trained-from-scratch
Convolutional Neural Networks. By introducing an oversampling scheme that
suitably addresses the low number of car images available for training, we
achieved 100% car image classification rate for a false positive rate of
1-in-454. Cars that were partially or completely obscured by other goods, a
modus operandi frequently adopted by criminals, were correctly detected. We
believe that this level of performance suggests that the method is suitable for
deployment in the field. It is expected that the generic object detection
workflow described can be extended to other object classes given the
availability of suitable training data.
</p>
{{{{ARTICLE_PARSER}}}}<p>Most recent garment capturing techniques rely on acquiring multiple views of
clothing, which may not always be readily available, especially in the case of
pre-existing photographs from the web. As an alternative, we pro- pose a method
that is able to compute a rich and realistic 3D model of a human body and its
outfits from a single photograph with little human in- teraction. Our algorithm
is not only able to capture the global shape and geometry of the clothing, it
can also extract small but important details of cloth, such as occluded
wrinkles and folds. Unlike previous methods using full 3D information (i.e.
depth, multi-view images, or sampled 3D geom- etry), our approach achieves
detailed garment recovery from a single-view image by using statistical,
geometric, and physical priors and a combina- tion of parameter estimation,
semantic parsing, shape recovery, and physics- based cloth simulation. We
demonstrate the effectiveness of our algorithm by re-purposing the
reconstructed garments for virtual try-on and garment transfer applications, as
well as cloth animation for digital characters.
</p>
{{{{ARTICLE_PARSER}}}}<p>Nowhere dense classes of graphs are very general classes of uniformly sparse
graphs with several seemingly unrelated characterisations. From an algorithmic
perspective, a characterisation of these classes in terms of uniform
quasi-wideness, a concept originating in finite model theory, has proved to be
particularly useful. Uniform quasi-wideness is used in many fpt-algorithms on
nowhere dense classes. However, the existing constructions showing the
equivalence of nowhere denseness and uniform quasi-wideness imply a
non-elementary blow up in the parameter dependence of the fpt-algorithms,
making them infeasible in practice.
</p>
<p>As a first main result of this paper, we use tools from logic, in particular
from a subfield of model theory known as stability theory, to establish
polynomial bounds for the equivalence of nowhere denseness and uniform
quasi-wideness.
</p>
<p>A powerful method in parameterized complexity theory is to compute a problem
kernel in a pre-computation step, that is, to reduce the input instance in
polynomial time to a sub-instance of size bounded in the parameter only
(independently of the input graph size). Our new tools allow us to obtain for
every fixed value of $r$ a polynomial kernel for the distance-$r$ dominating
set problem on nowhere dense classes of graphs. This result is particularly
interesting, as it implies that for every class $\mathcal{C}$ of graphs which
is closed under subgraphs, the distance-$r$ dominating set problem admits a
kernel on $\mathcal{C}$ for every value of $r$ if, and only if, it admits a
polynomial kernel for every value of $r$ (under the standard assumption of
parameterized complexity theory that $\mathrm{FPT} \neq W[2]$).
</p>
{{{{ARTICLE_PARSER}}}}<p>We develop an efficient alternating framework for learning Factorization
Machine (FM) on steaming data with provable guarantees. When the feature is
$d$-dimension and the target second order coefficient matrix in FM is of rank
$k$, our algorithm converges linearly, achieves $O(\epsilon)$ recovery error
after retrieving $O(k^{3}d\log(1/\epsilon))$ training instances, consumes
$O(kd)$ memory in one-pass of dataset and only requires matrix-vector product
operations in each iteration. The key ingredient of our framework is a
construction of an estimation sequence endowed with a so-called Conditionally
Independent RIP condition. As special cases of FM, our framework can be applied
to symmetric or asymmetric rank-one matrix sensing problems, such as inductive
matrix completion and phase retrieval.
</p>
{{{{ARTICLE_PARSER}}}}<p>A pair of pants is a genus zero orientable surface with three boundary
components. A pants decomposition of a surface is a finite collection of
unordered pairwise disjoint simple closed curves embedded in the surface that
decompose the surface into pants. In this paper we present two Morse theory
based algorithms for pants decomposition of a surface mesh. Both algorithms
operates on a choice of an appropriate Morse function on the surface. The first
algorithm uses this Morse function to identify handles that are glued
systematically to obtain a pant decomposition. The second algorithm uses the
Reeb graph of the Morse function to obtain a pant decomposition. Both
algorithms work for surfaces with or without boundaries. Our preliminary
implementation of the two algorithms shows that both algorithms run in much
less time than an existing state-of-the-art method, and the Reeb graph based
algorithm achieves the best time efficiency. Finally, we demonstrate the
robustness of our algorithms against noise.
</p>
{{{{ARTICLE_PARSER}}}}<p>A fundamental component of modern trackers is an online learned tracking
model, which is typically modeled either globally or locally. The two kinds of
models perform differently in terms of effectiveness and robustness under
different challenging situations. This work exploits the advantages of both
models. A subspace model, from a global perspective, is learned from previously
obtained targets via rank-minimization to address the tracking, and a
pixel-level local observation is leveraged si- multaneously, from a local point
of view, to augment the subspace model. A matrix completion method is employed
to integrate the two models. Unlike previous tracking methods, which locate the
target among all fully observed target candidates, the proposed approach first
estimates an expected target via the matrix completion through partially
observed target candidates, and then, identifies the target according to the
estimation accuracy with respect to the target candidates. Specifically, the
tracking is formulated as a problem of target appearance estimation. Extensive
experiments on various challenging video sequences verify the effectiveness of
the proposed approach and demonstrate that the proposed tracker outperforms
other popular state-of-the-art trackers.
</p>
{{{{ARTICLE_PARSER}}}}<p>Correlation filtering based tracking model has received lots of attention and
achieved great success in real-time tracking, however, the lost function in
current correlation filtering paradigm could not reliably response to the
appearance changes caused by occlusion and illumination variations. This study
intends to promote the robustness of the correlation filter learning. By
exploiting the anisotropy of the filter response, three sparsity related loss
functions are proposed to alleviate the overfitting issue of previous methods
and improve the overall tracking performance. As a result, three real-time
trackers are implemented. Extensive experiments in various challenging
situations demonstrate that the robustness of the learned correlation filter
has been greatly improved via the designed loss functions. In addition, the
study reveals, from an experimental perspective, how different loss functions
essentially influence the tracking performance. An important conclusion is that
the sensitivity of the peak values of the filter in successive frames is
consistent with the tracking performance. This is a useful reference criterion
in designing a robust correlation filter for visual tracking.
</p>
{{{{ARTICLE_PARSER}}}}<p>NodeTrix representations are a popular way to visualize clustered graphs;
they represent clusters as adjacency matrices and inter-cluster edges as curves
connecting the matrix boundaries. We study the complexity of constructing
NodeTrix representations focusing on planarity testing problems, and we show
several NP-completeness results and some polynomial-time algorithms. Building
on such algorithms we develop a JavaScript library for NodeTrix representations
aimed at reducing the crossings between edges incident to the same matrix.
</p>
{{{{ARTICLE_PARSER}}}}<p>Deep neural networks have shown striking progress and obtained
state-of-the-art results in many AI research fields in the recent years.
However, it is often unsatisfying to not know why they predict what they do. In
this paper, we address the problem of interpreting Visual Question Answering
(VQA) models. Specifically, we are interested in finding what part of the input
(pixels in images or words in questions) the VQA model focuses on while
answering the question. To tackle this problem, we use two visualization
techniques -- guided backpropagation and occlusion -- to find important words
in the question and important regions in the image. We then present qualitative
and quantitative analyses of these importance maps. We found that even without
explicit attention mechanisms, VQA models may sometimes be implicitly attending
to relevant regions in the image, and often to appropriate words in the
question.
</p>
{{{{ARTICLE_PARSER}}}}<p>Despite significant developments in Proof Theory, surprisingly little
attention has been devoted to the concept of proof verifier. In particular, the
mathematical community may be interested in studying different types of proof
verifiers (people, programs, oracles, communities, superintelligences) as
mathematical objects. Such an effort could reveal their properties, their
powers and limitations (particularly in human mathematicians), minimum and
maximum complexity, as well as self-verification and self-reference issues. We
propose an initial classification system for verifiers and provide some
rudimentary analysis of solved and open problems in this important domain. Our
main contribution is a formal introduction of the notion of unverifiability,
for which the paper could serve as a general citation in domains of theorem
proving, as well as software and AI verification.
</p>
{{{{ARTICLE_PARSER}}}}<p>With increasing game size, a problem of computational complexity arises. This
is especially true in real world problems such as in social systems, where
there is a significant population of players involved in the game, and the
complexity problem is critical. Previous studies in algorithmic game theory
propose succinct games that enable small descriptions of payoff matrices and
reduction of complexities. However, some of the suggested compromises lose
generality with strict assumptions such as symmetries in utility functions and
cannot be applied to the full range of real world problems that may be
presented. Graphical games are relatively promising, with a good balance
between complexity and generality. However, they assume a given graph structure
of players' interactions and cannot be applied to games without such known
graphs. This study proposes a method to identify an interaction graph between
players and subsequently decompose games into smaller components by cutting out
weak interactions for the purpose of reducing complexity. At the beginning,
players' mutual dependencies on their utilities are quantified as
variance-covariance matrices among players. Then, the interaction graphs among
players are identified by solving eigenvalue problems. Players' interactions
are further decomposed into linear combinations of games. This helps to find a
consistent equilibrium, which is a Nash equilibrium specified by the
decomposition, with reduced computational complexity. Finally, experiments on
simple example games are shown to verify the proposed method.
</p>
{{{{ARTICLE_PARSER}}}}<p>We characterize the information-theoretic limits of the additive white
Gaussian noise (AWGN) channel and the Gaussian multiple access channel (MAC)
when variable-length feedback is available at the encoder and a non-vanishing
error probability is permitted. For the AWGN channel, we establish the
$\varepsilon$-capacity (for $0&lt;\varepsilon&lt;1$) and show that it is larger than
the corresponding $\varepsilon$-capacity when fixed-length feedback is
available. Due to the continuous nature of the channel and the presence of
expected power constraints, we need to develop new achievability and converse
techniques. In addition, we show that a variable-length feedback with
termination (VLFT) code outperforms a stop-feedback code in terms of the
second-order asymptotic behavior. Finally, we extend out analyses to the
Gaussian MAC with the two types of variable-length feedback where we establish
the $\varepsilon$-capacity region. Due to the multi-terminal nature of the
channel model, we are faced with the need to bound the asymptotic behavior of
the expected value of the maximum of several stopping times. We do so by
leveraging tools from renewal theory developed by Lai and Siegmund.
</p>
{{{{ARTICLE_PARSER}}}}<p>Accurately determining dependency structure is critical to discovering a
system's causal organization. We recently showed that the transfer entropy
fails in a key aspect of this---measuring information flow---due to its
conflation of dyadic and polyadic relationships. We extend this observation to
demonstrate that this is true of all such Shannon information measures when
used to analyze multivariate dependencies. This has broad implications,
particularly when employing information to express the organization and
mechanisms embedded in complex systems, including the burgeoning efforts to
combine complex network theory with information theory. Here, we do not suggest
that any aspect of information theory is wrong. Rather, the vast majority of
its informational measures are simply inadequate for determining the meaningful
dependency structure within joint probability distributions. Therefore, such
information measures are inadequate for discovering intrinsic causal relations.
We close by demonstrating that such distributions exist across an arbitrary set
of variables.
</p>
{{{{ARTICLE_PARSER}}}}<p>Although commercial and open-source software exist to reconstruct a static
object from a sequence recorded with an RGB-D sensor, there is a lack of tools
that build rigged models of articulated objects that deform realistically and
can be used for tracking or animation. In this work, we fill this gap and
propose a method that creates a fully rigged model of an articulated object
from depth data of a single sensor. To this end, we combine deformable mesh
tracking, motion segmentation based on spectral clustering and skeletonization
based on mean curvature flow. The fully rigged model then consists of a
watertight mesh, embedded skeleton, and skinning weights.
</p>
{{{{ARTICLE_PARSER}}}}<p>Distributed compressive sensing is a framework considering jointly sparsity
within signal ensembles along with multiple measurement vectors (MMVs). The
current theoretical bound of performance for MMVs, however, is derived to be
the same with that for single MV (SMV) because no assumption about signal
ensembles is made.
</p>
<p>In this work, we propose a new concept of inducing the factor called
\"Euclidean distances between signals\" for the performance analysis of MMVs. The
novelty is that the size of signal ensembles will be taken into consideration
in our analysis to theoretically show that MMVs indeed exhibit better
performance than SMV. Although our concept can be broadly applied to CS
algorithms with MMVs, the case study conducted on a well-known greedy solver
called simultaneous orthogonal matching pursuit (SOMP) will be explored in this
paper. We show that the performance of SOMP, when incorporated with our concept
by modifying the steps of support detection and signal estimations, will be
improved remarkably, especially when the Euclidean distances between signals
are short. The performance of modified SOMP is verified to meet our theoretical
prediction.
</p>
{{{{ARTICLE_PARSER}}}}<p>Traditional dehazing techniques, as a well studied topic in image processing,
are now widely used to eliminate the haze effects from individual images.
However, even the state-of-the-art dehazing algorithms may not provide
sufficient support to video analytics, as a crucial pre-processing step for
video-based decision making systems (e.g., robot navigation), due to the
limitations of these algorithms on poor result coherence and low processing
efficiency. This paper presents a new framework, particularly designed for
video dehazing, to output coherent results in real time, with two novel
techniques. Firstly, we decompose the dehazing algorithms into three generic
components, namely transmission map estimator, atmospheric light estimator and
haze-free image generator. They can be simultaneously processed by multiple
threads in the distributed system, such that the processing efficiency is
optimized by automatic CPU resource allocation based on the workloads.
Secondly, a cross-frame normalization scheme is proposed to enhance the
coherence among consecutive frames, by sharing the parameters of atmospheric
light from consecutive frames in the distributed computation platform. The
combination of these techniques enables our framework to generate highly
consistent and accurate dehazing results in real-time, by using only 3 PCs
connected by Ethernet.
</p>
{{{{ARTICLE_PARSER}}}}<p>In a variety of application domains the content to be recommended to users is
associated with text. This includes research papers, movies with associated
plot summaries, news articles, blog posts, etc. Recommendation approaches based
on latent factor models can be extended naturally to leverage text by employing
an explicit mapping from text to factors. This enables recommendations for new,
unseen content, and may generalize better, since the factors for all items are
produced by a compactly-parametrized model. Previous work has used topic models
or averages of word embeddings for this mapping. In this paper we present a
method leveraging deep recurrent neural networks to encode the text sequence
into a latent vector, specifically gated recurrent units (GRUs) trained
end-to-end on the collaborative filtering task. For the task of scientific
paper recommendation, this yields models with significantly higher accuracy. In
cold-start scenarios, we beat the previous state-of-the-art, all of which
ignore word order. Performance is further improved by multi-task learning,
where the text encoder network is trained for a combination of content
recommendation and item metadata prediction. This regularizes the collaborative
filtering model, ameliorating the problem of sparsity of the observed rating
matrix.
</p>
{{{{ARTICLE_PARSER}}}}<p>Degrees of freedom (DoF) is studied in the downlink of a heterogenous
wireless network modeled as a two-layered interference network. The first layer
of the interference network is the backhaul layer between macro base stations
(MB) and small cell base stations (SB), which is modeled as a Wyner type linear
network. The second layer is the transmission layer between SBs and mobile
terminals (MTs), which is modeled as a linear Wyner $L_T$ network, i.e., each
MT is connected to $L_T+1$ SBs. The SBs are assumed to be half-duplex, thus
restricting the per user degrees of freedom (puDoF) in the system to $1/2$. The
puDoF can be further restricted by the number of antennas at the MB. For $L_T
\in \{1,2\}$, the optimal puDoF can be achieved by using simple interference
avoidance schemes. The increase in the connectivity of transmission layer
beyond $L_T=2$ limits the achievable puDoF using only zero-forcing schemes to
less than 1/2, even in the presence of large number of antennas at each MB but
the optimal puDoF can be achieved by making each message available at multiple
SBs. This is done by sending an appropriate linear combination to the SB to
zero-force interference at the intended user. The maximum per user DoF of 1/2
can be achieved in the linear network with sufficient number of antennas using
only interference avoidance schemes. These results are also extended to a more
realistic hexagonal cellular model as well.
</p>
{{{{ARTICLE_PARSER}}}}<p>We present an end-to-end machine-human image annotation system where each
component can be attached in a plug-and-play fashion. These components include
Feature Extraction, Machine Classifier, Task Sampling and Crowd Consensus.
</p>
{{{{ARTICLE_PARSER}}}}<p>Robotic commands in natural language usually contain various spatial
descriptions that are semantically similar but syntactically different. Mapping
such syntactic variants into semantic concepts that can be understood by robots
is challenging due to the high flexibility of natural language expressions. To
tackle this problem, we collect robotic commands for navigation and
manipulation tasks using crowdsourcing. We further define a robot language and
use a generative machine translation model to translate robotic commands from
natural language to robot language. The main purpose of this paper is to
simulate the interaction process between human and robots using crowdsourcing
platforms, and investigate the possibility of translating natural language to
robot language with paraphrases.
</p>
{{{{ARTICLE_PARSER}}}}<p>This paper considers the distributed sampled-data control problem of a group
of mobile robots connected via distance-induced proximity networks. A dwell
time is assumed in order to avoid chattering in the neighbor relations that may
be caused by abrupt changes of positions when updating information from
neighbors. Distributed sampled-data control laws are designed based on nearest
neighbour rules, which in conjunction with continuous-time dynamics results in
hybrid closed-loop systems. For uniformly and independently initial states, a
sufficient condition is provided to guarantee synchronization for the system
without leaders. In order to steer all robots to move with the desired
orientation and speed, we then introduce a number of leaders into the system,
and quantitatively establish the proportion of leaders needed to track either
constant or time-varying signals. All these conditions depend only on the
neighborhood radius, the maximum initial moving speed and the dwell time,
without assuming a prior properties of the neighbor graphs as are used in most
of the existing literature.
</p>
{{{{ARTICLE_PARSER}}}}</div>
<div style="visibility:hidden; display: none;" id="links">http://arxiv.org/pdf/1609.02555{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02556{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02557{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02559{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02561{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02563{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02566{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02567{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02569{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02570{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02571{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02576{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02579{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02602{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02604{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02607{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02619{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02625{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02632{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02635{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02671{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02689{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02693{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02706{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02710{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02713{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02731{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02735{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02742{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02759{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02760{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02767{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02777{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02785{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02796{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02817{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02822{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02841{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02859{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02864{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02881{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02887{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02908{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1508.07410{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1511.07799{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1512.01312{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1602.02456{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1603.08955{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1605.08355{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1606.01480{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1606.06751{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1607.01782{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1607.04398{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1607.07874{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1608.02133{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1608.02149{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1608.02995{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1608.03149{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1608.05415{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1608.05854{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1608.06540{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.00437{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.01153{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.01505{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.01851{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02497{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02518{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1512.05604{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1608.00469{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02406{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02568{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02595{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02792{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02820{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02862{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02894{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1602.01564{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1605.00557{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02568{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02572{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02580{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02590{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02595{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02608{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02628{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02675{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02708{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02766{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02778{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02816{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02820{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1602.01564{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1605.00557{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1607.04398{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.00024{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02382{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.00868{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02574{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02615{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02623{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02673{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02698{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02705{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02756{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02776{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02824{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02829{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02890{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1311.0036{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1411.2475{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1503.00712{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1504.01644{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1602.02456{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1604.06699{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1606.03355{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1606.03882{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1606.05116{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1607.00615{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1608.08134{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02574{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02587{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02617{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02648{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02653{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02658{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02674{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02676{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02681{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02684{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02722{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02729{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02732{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02736{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02754{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02758{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02780{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02797{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02808{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02821{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02848{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02850{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02851{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02876{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02877{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02878{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02897{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02904{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02910{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1409.1247{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1501.05729{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1510.06743{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1604.03282{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1605.07372{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1606.01848{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1606.08823{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1607.02123{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1607.08191{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1608.03438{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1608.04905{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.00429{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02241{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02299{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02562{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02583{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02584{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02593{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02596{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02598{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02603{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02606{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02612{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02613{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02620{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02621{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02622{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02631{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02638{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02640{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02646{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02651{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02657{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02660{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02661{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02664{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02667{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02668{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02669{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02672{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02678{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02682{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02687{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02694{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02715{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02726{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02727{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02728{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02744{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02745{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02746{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02748{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02750{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02753{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02769{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02770{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02781{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02784{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02789{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02791{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02795{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02805{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02809{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02815{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02825{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02831{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02835{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02839{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02842{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02845{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02846{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02879{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02888{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02898{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02901{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02906{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02907{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02911{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1404.4275{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1405.2435{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1504.03809{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1504.07830{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1504.07851{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1505.04920{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1506.02438{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1507.06296{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1510.06743{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1512.08863{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1601.06116{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1601.07498{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1602.02675{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1602.02680{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1602.07377{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1603.00749{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1603.07256{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1604.03924{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1605.01224{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1605.07246{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1605.09526{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1606.00360{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1606.02126{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1606.02941{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1606.03986{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1606.08078{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1608.01250{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1608.05637{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1608.05995{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1608.06368{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1608.08171{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1608.08173{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1608.08952{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1608.08974{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.00331{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.00481{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.00594{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.01233{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.01371{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.01899{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02035{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02116{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02117{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02271{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02549{{{{ARTICLE_PARSER}}}}http://arxiv.org/pdf/1609.02174{{{{ARTICLE_PARSER}}}}</div>

</body>
</html>
